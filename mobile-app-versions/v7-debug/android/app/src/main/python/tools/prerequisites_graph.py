#!/usr/bin/env python3
"""
Prerequisites Graph - –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–µ–¥ –¥—Ä—É–≥–∏–º–∏

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: –≥—Ä–∞—Ñ–∞–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∫—É—Ä—Å–æ–≤ –≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö

–ê–ª–≥–æ—Ä–∏—Ç–º—ã:
- Topological Sort (Kahn's algorithm) - –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è
- Tarjan's algorithm - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ü–∏–∫–ª–æ–≤ –∏ SCC (Strongly Connected Components)
- Critical Path - longest path –≤ DAG
- Curriculum Builder - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —É—á–µ–±–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤
"""

from pathlib import Path
import yaml
import re
from collections import defaultdict, deque
import json
import argparse
from typing import List, Dict, Set, Tuple, Optional
from datetime import datetime


class TopologicalSorter:
    """Topological Sort using Kahn's algorithm"""

    def __init__(self, graph: Dict[str, List[str]]):
        """
        graph: dict mapping node -> list of nodes it depends on
        """
        self.graph = graph
        self.reverse_graph = defaultdict(list)

        # Build reverse graph (node -> nodes that depend on it)
        for node, dependencies in graph.items():
            for dep in dependencies:
                self.reverse_graph[dep].append(node)

    def sort(self) -> Tuple[List[str], List[str]]:
        """
        Returns (sorted_nodes, nodes_in_cycle)

        Kahn's algorithm:
        1. Find all nodes with in-degree 0
        2. Remove node and its edges
        3. Repeat until no more nodes or cycle detected
        """
        in_degree = {node: len(deps) for node, deps in self.graph.items()}

        # Add nodes that are only in reverse_graph
        for node in self.reverse_graph:
            if node not in in_degree:
                in_degree[node] = 0

        # Find all nodes with in-degree 0
        queue = deque([node for node, degree in in_degree.items() if degree == 0])
        sorted_nodes = []

        while queue:
            node = queue.popleft()
            sorted_nodes.append(node)

            # Reduce in-degree for neighbors
            for neighbor in self.reverse_graph.get(node, []):
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)

        # Check for cycles
        nodes_in_cycle = [node for node, degree in in_degree.items() if degree > 0]

        return sorted_nodes, nodes_in_cycle


class CycleDetector:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ü–∏–∫–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ using Tarjan's algorithm"""

    def __init__(self, graph: Dict[str, List[str]]):
        self.graph = graph
        self.index = 0
        self.stack = []
        self.indices = {}
        self.lowlinks = {}
        self.on_stack = set()
        self.sccs = []  # Strongly Connected Components

    def find_sccs(self) -> List[List[str]]:
        """
        Tarjan's algorithm –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è SCC (Strongly Connected Components)

        SCC - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–µ—Ä—à–∏–Ω, –≥–¥–µ –∫–∞–∂–¥–∞—è –¥–æ—Å—Ç–∏–∂–∏–º–∞ –∏–∑ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π
        –¶–∏–∫–ª = SCC —Å —Ä–∞–∑–º–µ—Ä–æ–º > 1
        """
        for node in self.graph:
            if node not in self.indices:
                self._strongconnect(node)

        return self.sccs

    def _strongconnect(self, v: str):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —á–∞—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞ Tarjan"""
        self.indices[v] = self.index
        self.lowlinks[v] = self.index
        self.index += 1
        self.stack.append(v)
        self.on_stack.add(v)

        # –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–æ—Å–µ–¥–µ–π
        for w in self.graph.get(v, []):
            if w not in self.indices:
                # Successor w –Ω–µ –±—ã–ª –ø–æ—Å–µ—â—ë–Ω; —Ä–µ–∫—É—Ä—Å–∏—è
                self._strongconnect(w)
                self.lowlinks[v] = min(self.lowlinks[v], self.lowlinks[w])
            elif w in self.on_stack:
                # Successor w –≤ —Å—Ç–µ–∫–µ –∏ —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤ —Ç–µ–∫—É—â–µ–º SCC
                self.lowlinks[v] = min(self.lowlinks[v], self.indices[w])

        # –ï—Å–ª–∏ v - –∫–æ—Ä–µ–Ω—å SCC, —Å–æ–∑–¥–∞—Ç—å SCC
        if self.lowlinks[v] == self.indices[v]:
            scc = []
            while True:
                w = self.stack.pop()
                self.on_stack.remove(w)
                scc.append(w)
                if w == v:
                    break
            self.sccs.append(scc)

    def find_cycles(self) -> List[List[str]]:
        """–ù–∞–π—Ç–∏ –≤—Å–µ —Ü–∏–∫–ª—ã (SCC —Å —Ä–∞–∑–º–µ—Ä–æ–º > 1)"""
        sccs = self.find_sccs()
        return [scc for scc in sccs if len(scc) > 1]


class CriticalPathAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏ (longest path in DAG)"""

    def __init__(self, graph: Dict[str, List[str]], weights: Optional[Dict[str, float]] = None):
        """
        graph: dict mapping node -> list of dependencies
        weights: optional dict mapping node -> weight (e.g., estimated study time)
        """
        self.graph = graph
        self.weights = weights or {node: 1.0 for node in graph}

    def find_critical_path(self) -> Tuple[List[str], float]:
        """
        –ù–∞–π—Ç–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å (longest path) –∏—Å–ø–æ–ª—å–∑—É—è topological sort

        Returns: (path, total_weight)
        """
        # Topological sort
        sorter = TopologicalSorter(self.graph)
        topo_order, cycles = sorter.sort()

        if cycles:
            raise ValueError(f"–ì—Ä–∞—Ñ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏–∫–ª—ã: {cycles}")

        # Calculate longest path to each node
        dist = {node: float('-inf') for node in self.graph}
        predecessor = {node: None for node in self.graph}

        # Initialize nodes with no dependencies
        for node in topo_order:
            if not self.graph.get(node, []):
                dist[node] = self.weights.get(node, 1.0)

        # Relax edges in topological order
        for node in topo_order:
            if dist[node] == float('-inf'):
                dist[node] = self.weights.get(node, 1.0)

            # Update successors
            reverse_graph = defaultdict(list)
            for n, deps in self.graph.items():
                for dep in deps:
                    reverse_graph[dep].append(n)

            for successor in reverse_graph.get(node, []):
                new_dist = dist[node] + self.weights.get(successor, 1.0)
                if new_dist > dist[successor]:
                    dist[successor] = new_dist
                    predecessor[successor] = node

        # Find node with maximum distance
        max_node = max(dist, key=dist.get)
        max_dist = dist[max_node]

        # Reconstruct path
        path = []
        current = max_node
        while current is not None:
            path.append(current)
            current = predecessor[current]

        path.reverse()

        return path, max_dist


class CurriculumBuilder:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å —É—á–µ–±–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤"""

    def __init__(self, graph: Dict[str, List[str]], articles_info: Dict[str, Dict]):
        self.graph = graph
        self.articles_info = articles_info

    def build_curriculum(self, target_article: str, max_depth: Optional[int] = None) -> List[Dict]:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è target_article

        Returns: —Å–ø–∏—Å–æ–∫ —É—Ä–æ–∫–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–∂–¥–æ–º
        """
        # Find all prerequisites recursively
        visited = set()
        curriculum = []

        def collect_prerequisites(article: str, depth: int = 0):
            if article in visited:
                return
            if max_depth is not None and depth > max_depth:
                return

            visited.add(article)

            # First, collect all prerequisites
            for prereq in self.graph.get(article, []):
                collect_prerequisites(prereq, depth + 1)

            # Then add this article
            info = self.articles_info.get(article, {})
            curriculum.append({
                'article': article,
                'title': info.get('title', article),
                'difficulty': info.get('difficulty', '—Å—Ä–µ–¥–Ω–∏–π'),
                'depth': depth,
                'order': len(curriculum) + 1
            })

        collect_prerequisites(target_article)

        return curriculum

    def build_progressive_curriculum(self, difficulty_order: List[str] = None) -> List[List[str]]:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

        Returns: —Å–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π, –∫–∞–∂–¥—ã–π —É—Ä–æ–≤–µ–Ω—å - —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
        """
        if difficulty_order is None:
            difficulty_order = ['–Ω–∞—á–∞–ª—å–Ω—ã–π', '—Å—Ä–µ–¥–Ω–∏–π', '–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π', '—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π']

        # Topological sort
        sorter = TopologicalSorter(self.graph)
        topo_order, _ = sorter.sort()

        # Group by depth first, then by difficulty
        depth_groups = defaultdict(list)

        for article in topo_order:
            depth = self._calculate_depth(article)
            difficulty = self.articles_info.get(article, {}).get('difficulty', '—Å—Ä–µ–¥–Ω–∏–π')
            diff_level = difficulty_order.index(difficulty) if difficulty in difficulty_order else 1

            depth_groups[depth].append((diff_level, article))

        # Sort each depth level by difficulty
        curriculum_levels = []
        for depth in sorted(depth_groups.keys()):
            level = [article for _, article in sorted(depth_groups[depth])]
            curriculum_levels.append(level)

        return curriculum_levels

    def _calculate_depth(self, article: str) -> int:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≥–ª—É–±–∏–Ω—É —Å—Ç–∞—Ç—å–∏"""
        visited = set()

        def dfs(node: str) -> int:
            if node in visited:
                return 0
            visited.add(node)

            if not self.graph.get(node, []):
                return 0

            return 1 + max(dfs(dep) for dep in self.graph[node])

        return dfs(article)


class PrerequisitesGraph:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –≥—Ä–∞—Ñ–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.prerequisites = defaultdict(lambda: {'requires': [], 'required_by': []})
        self.articles = {}

        # –ö—ç—à –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        self._depth_cache = {}
        self._cycles_cache = None

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def build_graph(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        print("üîó –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\n")

        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏
        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            frontmatter, content = self.extract_frontmatter_and_content(md_file)

            if not content:
                continue

            article_path = str(md_file.relative_to(self.root_dir))

            self.articles[article_path] = {
                'title': frontmatter.get('title', md_file.stem) if frontmatter else md_file.stem,
                'difficulty': frontmatter.get('difficulty', '—Å—Ä–µ–¥–Ω–∏–π') if frontmatter else '—Å—Ä–µ–¥–Ω–∏–π',
                'tags': frontmatter.get('tags', []) if frontmatter else []
            }

            # –ò–∑–≤–ª–µ—á—å prerequisites –∏–∑ frontmatter
            if frontmatter and 'prerequisites' in frontmatter:
                prereqs = frontmatter['prerequisites']
                if isinstance(prereqs, list):
                    for prereq in prereqs:
                        try:
                            target = (md_file.parent / prereq).resolve()

                            if target.exists() and target.is_relative_to(self.root_dir):
                                target_path = str(target.relative_to(self.root_dir))

                                # –î–æ–±–∞–≤–∏—Ç—å –≤ –≥—Ä–∞—Ñ
                                if target_path not in self.prerequisites[article_path]['requires']:
                                    self.prerequisites[article_path]['requires'].append(target_path)

                                if article_path not in self.prerequisites[target_path]['required_by']:
                                    self.prerequisites[target_path]['required_by'].append(article_path)
                        except:
                            pass

            # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ "–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –∑–Ω–∞–Ω–∏–µ"
            prereq_patterns = [
                r'–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –∑–Ω–∞–Ω–∏–µ \[([^\]]+)\]\(([^)]+)\)',
                r'—Ç—Ä–µ–±—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è \[([^\]]+)\]\(([^)]+)\)',
                r'–æ—Å–Ω–æ–≤—ã–≤–∞–µ—Ç—Å—è –Ω–∞ \[([^\]]+)\]\(([^)]+)\)',
                r'—Å–º\. —Å–Ω–∞—á–∞–ª–∞ \[([^\]]+)\]\(([^)]+)\)'
            ]

            for pattern in prereq_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for text, link in matches:
                    if link.startswith('http'):
                        continue

                    try:
                        target = (md_file.parent / link.split('#')[0]).resolve()

                        if target.exists() and target.is_relative_to(self.root_dir):
                            target_path = str(target.relative_to(self.root_dir))

                            if target_path not in self.prerequisites[article_path]['requires']:
                                self.prerequisites[article_path]['requires'].append(target_path)

                            if article_path not in self.prerequisites[target_path]['required_by']:
                                self.prerequisites[target_path]['required_by'].append(article_path)
                    except:
                        pass

        print(f"   –°—Ç–∞—Ç–µ–π –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {len(self.articles)}")
        print(f"   –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–∞–π–¥–µ–Ω–æ: {sum(len(p['requires']) for p in self.prerequisites.values())}\n")

    def find_learning_path(self, target_article):
        """–ù–∞–π—Ç–∏ –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞—Ç—å–∏"""
        visited = set()
        path = []

        def dfs(article):
            if article in visited:
                return

            visited.add(article)

            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            for prereq in self.prerequisites[article]['requires']:
                dfs(prereq)

            path.append(article)

        dfs(target_article)
        return path

    def calculate_depth(self, article_path):
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≥–ª—É–±–∏–Ω—É —Å—Ç–∞—Ç—å–∏ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏ –¥–æ –Ω–µ—ë)"""
        if article_path in self._depth_cache:
            return self._depth_cache[article_path]

        visited = set()

        def dfs(article):
            if article in visited:
                return 0

            visited.add(article)

            if not self.prerequisites[article]['requires']:
                return 0

            max_depth = 0
            for prereq in self.prerequisites[article]['requires']:
                depth = dfs(prereq)
                max_depth = max(max_depth, depth + 1)

            return max_depth

        depth = dfs(article_path)
        self._depth_cache[article_path] = depth
        return depth

    def detect_cycles(self) -> List[List[str]]:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"""
        if self._cycles_cache is not None:
            return self._cycles_cache

        graph = {article: prereqs['requires'] for article, prereqs in self.prerequisites.items()}
        detector = CycleDetector(graph)
        cycles = detector.find_cycles()

        self._cycles_cache = cycles
        return cycles

    def topological_sort(self) -> Tuple[List[str], List[str]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è (topological sort)

        Returns: (sorted_articles, articles_in_cycles)
        """
        graph = {article: prereqs['requires'] for article, prereqs in self.prerequisites.items()}
        sorter = TopologicalSorter(graph)
        return sorter.sort()

    def find_critical_path(self) -> Tuple[List[str], int]:
        """
        –ù–∞–π—Ç–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å - —Å–∞–º—É—é –¥–ª–∏–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

        Returns: (path, length)
        """
        graph = {article: prereqs['requires'] for article, prereqs in self.prerequisites.items()}

        # Use article count as weight
        analyzer = CriticalPathAnalyzer(graph)

        try:
            path, length = analyzer.find_critical_path()
            return path, int(length)
        except ValueError:
            # Graph has cycles
            return [], 0

    def build_curriculum_for(self, target_article: str) -> List[Dict]:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏"""
        graph = {article: prereqs['requires'] for article, prereqs in self.prerequisites.items()}
        builder = CurriculumBuilder(graph, self.articles)
        return builder.build_curriculum(target_article)

    def calculate_graph_metrics(self) -> Dict:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞"""
        num_articles = len(self.articles)
        num_edges = sum(len(prereqs['requires']) for prereqs in self.prerequisites.values())

        # Maximum possible edges in directed graph
        max_edges = num_articles * (num_articles - 1)

        # Density: actual_edges / max_possible_edges
        density = num_edges / max_edges if max_edges > 0 else 0

        # Average in-degree and out-degree
        avg_in_degree = num_edges / num_articles if num_articles > 0 else 0
        avg_out_degree = avg_in_degree  # Same in directed graph

        # Find max depth (diameter approximation)
        max_depth = max((self.calculate_depth(article) for article in self.articles), default=0)

        cycles = self.detect_cycles()

        return {
            'num_articles': num_articles,
            'num_dependencies': num_edges,
            'density': round(density, 4),
            'avg_prerequisites_per_article': round(avg_in_degree, 2),
            'max_depth': max_depth,
            'num_cycles': len(cycles),
            'is_dag': len(cycles) == 0
        }

    def find_entry_points(self):
        """–ù–∞–π—Ç–∏ —Å—Ç–∞—Ç—å–∏-—Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)"""
        entry_points = []

        for article in self.articles:
            if not self.prerequisites[article]['requires']:
                entry_points.append(article)

        return entry_points

    def find_advanced_topics(self):
        """–ù–∞–π—Ç–∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ–º—ã (–º–Ω–æ–≥–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)"""
        advanced = []

        for article, prereqs in self.prerequisites.items():
            if len(prereqs['requires']) >= 2:
                advanced.append((article, len(prereqs['requires'])))

        advanced.sort(key=lambda x: -x[1])
        return advanced

    def export_to_dot(self, output_file: Path = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –≤ DOT format (Graphviz)

        –ú–æ–∂–Ω–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: dot -Tpng graph.dot -o graph.png
        """
        if output_file is None:
            output_file = self.root_dir / "prerequisites_graph.dot"

        lines = []
        lines.append("digraph PrerequisitesGraph {\n")
        lines.append("  rankdir=LR;\n")
        lines.append("  node [shape=box, style=rounded];\n\n")

        # Add nodes with attributes
        for article, info in self.articles.items():
            difficulty = info.get('difficulty', '—Å—Ä–µ–¥–Ω–∏–π')
            depth = self.calculate_depth(article)

            # Color by difficulty
            color_map = {
                '–Ω–∞—á–∞–ª—å–Ω—ã–π': 'lightgreen',
                '—Å—Ä–µ–¥–Ω–∏–π': 'lightblue',
                '–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π': 'orange',
                '—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π': 'red'
            }
            color = color_map.get(difficulty, 'lightgray')

            label = info['title'].replace('"', '\\"')
            lines.append(f'  "{article}" [label="{label}", fillcolor={color}, style="rounded,filled"];\n')

        lines.append("\n")

        # Add edges
        for article, prereqs in self.prerequisites.items():
            for prereq in prereqs['requires']:
                lines.append(f'  "{prereq}" -> "{article}";\n')

        lines.append("}\n")

        dot_content = ''.join(lines)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(dot_content)

        print(f"‚úÖ DOT —Ñ–∞–π–ª: {output_file}")
        print(f"   –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: dot -Tpng {output_file.name} -o graph.png")

        return dot_content

    def generate_html_visualization(self, output_file: Path = None) -> str:
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å vis.js"""
        if output_file is None:
            output_file = self.root_dir / "prerequisites_graph.html"

        # Prepare data for vis.js
        nodes = []
        for i, (article, info) in enumerate(self.articles.items()):
            difficulty = info.get('difficulty', '—Å—Ä–µ–¥–Ω–∏–π')
            depth = self.calculate_depth(article)

            # Color by difficulty
            color_map = {
                '–Ω–∞—á–∞–ª—å–Ω—ã–π': '#90EE90',
                '—Å—Ä–µ–¥–Ω–∏–π': '#ADD8E6',
                '–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π': '#FFA500',
                '—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π': '#FF6B6B'
            }
            color = color_map.get(difficulty, '#CCCCCC')

            nodes.append({
                'id': i,
                'label': info['title'],
                'title': f"{article}<br>Difficulty: {difficulty}<br>Depth: {depth}",
                'color': color,
                'article_path': article,
                'difficulty': difficulty,
                'depth': depth
            })

        # Build article to id mapping
        article_to_id = {article: i for i, article in enumerate(self.articles.keys())}

        edges = []
        for article, prereqs in self.prerequisites.items():
            if article in article_to_id:
                target_id = article_to_id[article]
                for prereq in prereqs['requires']:
                    if prereq in article_to_id:
                        source_id = article_to_id[prereq]
                        edges.append({
                            'from': source_id,
                            'to': target_id,
                            'arrows': 'to'
                        })

        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>Prerequisites Graph</title>
    <script type="text/javascript" src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 0; padding: 20px; }}
        #mynetwork {{ width: 100%; height: 800px; border: 1px solid #ddd; }}
        .info {{ margin-bottom: 20px; padding: 15px; background: #f5f5f5; border-radius: 5px; }}
        .legend {{ display: flex; gap: 20px; margin-top: 10px; }}
        .legend-item {{ display: flex; align-items: center; gap: 5px; }}
        .legend-color {{ width: 20px; height: 20px; border-radius: 3px; }}
    </style>
</head>
<body>
    <h1>üîó Prerequisites Graph</h1>

    <div class="info">
        <h3>–ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å—Ç–∞—Ç–µ–π</h3>
        <p>–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è. –°—Ç—Ä–µ–ª–∫–∞ A ‚Üí B –æ–∑–Ω–∞—á–∞–µ—Ç "B —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞–Ω–∏—è A".</p>
        <div class="legend">
            <div class="legend-item">
                <div class="legend-color" style="background: #90EE90;"></div>
                <span>–ù–∞—á–∞–ª—å–Ω—ã–π</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: #ADD8E6;"></div>
                <span>–°—Ä–µ–¥–Ω–∏–π</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: #FFA500;"></div>
                <span>–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: #FF6B6B;"></div>
                <span>–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π</span>
            </div>
        </div>
    </div>

    <div id="mynetwork"></div>

    <script type="text/javascript">
        var nodes = new vis.DataSet({json.dumps(nodes, ensure_ascii=False)});
        var edges = new vis.DataSet({json.dumps(edges, ensure_ascii=False)});

        var container = document.getElementById('mynetwork');
        var data = {{
            nodes: nodes,
            edges: edges
        }};

        var options = {{
            layout: {{
                hierarchical: {{
                    enabled: true,
                    direction: 'LR',
                    sortMethod: 'directed',
                    levelSeparation: 200,
                    nodeSpacing: 150
                }}
            }},
            physics: {{
                enabled: false
            }},
            nodes: {{
                shape: 'box',
                margin: 10,
                font: {{
                    size: 14
                }}
            }},
            edges: {{
                smooth: {{
                    type: 'cubicBezier',
                    forceDirection: 'horizontal'
                }},
                arrows: {{
                    to: {{
                        enabled: true,
                        scaleFactor: 0.5
                    }}
                }}
            }}
        }};

        var network = new vis.Network(container, data, options);

        network.on('click', function(params) {{
            if (params.nodes.length > 0) {{
                var nodeId = params.nodes[0];
                var node = nodes.get(nodeId);
                alert('Article: ' + node.article_path + '\\nTitle: ' + node.label + '\\nDifficulty: ' + node.difficulty + '\\nDepth: ' + node.depth);
            }}
        }});
    </script>
</body>
</html>"""

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"‚úÖ HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {output_file}")

        return html_content

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç"""
        lines = []
        lines.append("# üîó –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n\n")
        lines.append("> –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞\n\n")

        # –ú–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞
        metrics = self.calculate_graph_metrics()

        lines.append("## –ú–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞\n\n")
        lines.append(f"- **–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π**: {metrics['num_articles']}\n")
        lines.append(f"- **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π**: {metrics['num_dependencies']}\n")
        lines.append(f"- **–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≥—Ä–∞—Ñ–∞**: {metrics['density']:.4f}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω–µ prereq/—Å—Ç–∞—Ç—å—è**: {metrics['avg_prerequisites_per_article']:.2f}\n")
        lines.append(f"- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞**: {metrics['max_depth']}\n")
        lines.append(f"- **–¶–∏–∫–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ**: {metrics['num_cycles']}\n")
        lines.append(f"- **–Ø–≤–ª—è–µ—Ç—Å—è DAG**: {'‚úÖ –î–∞' if metrics['is_dag'] else '‚ùå –ù–µ—Ç (–µ—Å—Ç—å —Ü–∏–∫–ª—ã)'}\n\n")

        # –¶–∏–∫–ª—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        cycles = self.detect_cycles()
        if cycles:
            lines.append("## ‚ö†Ô∏è –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n\n")
            lines.append("> –≠—Ç–∏ —Å—Ç–∞—Ç—å–∏ –æ–±—Ä–∞–∑—É—é—Ç —Ü–∏–∫–ª—ã - –Ω—É–∂–Ω–æ —Ä–∞–∑–æ—Ä–≤–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏!\n\n")
            for i, cycle in enumerate(cycles, 1):
                lines.append(f"### –¶–∏–∫–ª {i}\n\n")
                for article in cycle:
                    title = self.articles.get(article, {}).get('title', article)
                    lines.append(f"- [{title}]({article})\n")
                lines.append("\n")

        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å
        critical_path, length = self.find_critical_path()
        if critical_path:
            lines.append("## üéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å\n\n")
            lines.append(f"> –°–∞–º–∞—è –¥–ª–∏–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π ({length} —Å—Ç–∞—Ç–µ–π)\n\n")
            for i, article in enumerate(critical_path, 1):
                title = self.articles.get(article, {}).get('title', article)
                lines.append(f"{i}. [{title}]({article})\n")
            lines.append("\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        entry_points = self.find_entry_points()
        advanced_topics = self.find_advanced_topics()

        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞** (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π): {len(entry_points)}\n")
        lines.append(f"- **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ–º—ã** (2+ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏): {len(advanced_topics)}\n\n")

        # –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞
        lines.append("## –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ (–Ω–∞—á–Ω–∏—Ç–µ –∑–¥–µ—Å—å)\n\n")
        lines.append("> –≠—Ç–∏ —Å—Ç–∞—Ç—å–∏ –º–æ–∂–Ω–æ —á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—ã–º–∏\n\n")

        for article in entry_points[:10]:
            title = self.articles[article]['title']
            difficulty = self.articles[article]['difficulty']
            lines.append(f"### {title}\n\n")
            lines.append(f"- **–§–∞–π–ª**: [{article}]({article})\n")
            lines.append(f"- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: {difficulty}\n")

            if self.prerequisites[article]['required_by']:
                lines.append(f"- **–û—Ç–∫—Ä—ã–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø –∫**: {len(self.prerequisites[article]['required_by'])} —Å—Ç–∞—Ç—å—è–º\n")

            lines.append("\n")

        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ–º—ã
        if advanced_topics:
            lines.append("\n## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ–º—ã\n\n")
            lines.append("> –¢—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è\n\n")

            for article, prereq_count in advanced_topics[:10]:
                title = self.articles[article]['title']
                depth = self.calculate_depth(article)

                lines.append(f"### {title}\n\n")
                lines.append(f"- **–§–∞–π–ª**: [{article}]({article})\n")
                lines.append(f"- **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π**: {prereq_count}\n")
                lines.append(f"- **–ì–ª—É–±–∏–Ω–∞**: {depth} —É—Ä–æ–≤–µ–Ω—å\n")

                # –ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
                if self.prerequisites[article]['requires']:
                    lines.append("\n**–¢—Ä–µ–±—É–µ—Ç –∑–Ω–∞–Ω–∏—è:**\n")
                    for prereq in self.prerequisites[article]['requires']:
                        prereq_title = self.articles.get(prereq, {}).get('title', prereq)
                        lines.append(f"- [{prereq_title}]({prereq})\n")

                # –ü—É—Ç—å –æ–±—É—á–µ–Ω–∏—è
                learning_path = self.find_learning_path(article)
                if len(learning_path) > 1:
                    lines.append("\n**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è:**\n")
                    for i, step in enumerate(learning_path, 1):
                        step_title = self.articles.get(step, {}).get('title', step)
                        lines.append(f"{i}. [{step_title}]({step})\n")

                lines.append("\n")

        output_file = self.root_dir / "PREREQUISITES_GRAPH.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –û—Ç—á—ë—Ç: {output_file}")

    def save_json(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ –≤ JSON"""
        metrics = self.calculate_graph_metrics()
        cycles = self.detect_cycles()
        critical_path, path_length = self.find_critical_path()
        topo_order, nodes_in_cycles = self.topological_sort()

        data = {
            'metadata': {
                'generated': datetime.now().isoformat(),
                'num_articles': len(self.articles),
                'num_dependencies': sum(len(p['requires']) for p in self.prerequisites.values())
            },
            'metrics': metrics,
            'articles': self.articles,
            'graph': {
                article: {
                    'requires': prereqs['requires'],
                    'required_by': prereqs['required_by'],
                    'depth': self.calculate_depth(article)
                }
                for article, prereqs in self.prerequisites.items()
            },
            'analysis': {
                'entry_points': self.find_entry_points(),
                'advanced_topics': [
                    {'article': article, 'prerequisites': count}
                    for article, count in self.find_advanced_topics()
                ],
                'cycles': cycles,
                'critical_path': {
                    'path': critical_path,
                    'length': path_length
                },
                'topological_order': topo_order,
                'nodes_in_cycles': nodes_in_cycles
            }
        }

        output_file = self.root_dir / "prerequisites_graph.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON –≥—Ä–∞—Ñ: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description='Prerequisites Graph - –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s                                    # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
  %(prog)s --cycles                           # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–∏–∫–ª–æ–≤
  %(prog)s --critical-path                    # –ü–æ–∫–∞–∑–∞—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å
  %(prog)s --curriculum "article.md"          # –£—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è —Å—Ç–∞—Ç—å–∏
  %(prog)s --topo-sort                        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è
  %(prog)s --export dot                       # –≠–∫—Å–ø–æ—Ä—Ç –≤ Graphviz DOT
  %(prog)s --export html                      # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
  %(prog)s --metrics                          # –ú–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞
        """
    )

    parser.add_argument(
        '--cycles',
        action='store_true',
        help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π'
    )

    parser.add_argument(
        '--critical-path',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å (longest path)'
    )

    parser.add_argument(
        '--curriculum',
        metavar='ARTICLE',
        help='–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏'
    )

    parser.add_argument(
        '--topo-sort',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è (topological sort)'
    )

    parser.add_argument(
        '--export',
        choices=['dot', 'html', 'json'],
        help='–≠–∫—Å–ø–æ—Ä—Ç –≥—Ä–∞—Ñ–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ'
    )

    parser.add_argument(
        '--metrics',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞'
    )

    parser.add_argument(
        '--report',
        action='store_true',
        help='–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)'
    )

    args = parser.parse_args()

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    graph = PrerequisitesGraph(root_dir)
    graph.build_graph()

    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ñ–ª–∞–≥–æ–≤, –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    if not any([args.cycles, args.critical_path, args.curriculum, args.topo_sort,
                args.export, args.metrics]):
        args.report = True

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
    if args.cycles:
        print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\n")
        cycles = graph.detect_cycles()

        if cycles:
            print(f"‚ùå –ù–∞–π–¥–µ–Ω–æ {len(cycles)} —Ü–∏–∫–ª–æ–≤:\n")
            for i, cycle in enumerate(cycles, 1):
                print(f"–¶–∏–∫–ª {i}:")
                for article in cycle:
                    title = graph.articles.get(article, {}).get('title', article)
                    print(f"  - {title} ({article})")
                print()
        else:
            print("‚úÖ –¶–∏–∫–ª–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. –ì—Ä–∞—Ñ —è–≤–ª—è–µ—Ç—Å—è DAG (Directed Acyclic Graph).\n")

    if args.critical_path:
        print("\nüéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å (longest path):\n")
        critical_path, length = graph.find_critical_path()

        if critical_path:
            print(f"–î–ª–∏–Ω–∞: {length} —Å—Ç–∞—Ç–µ–π\n")
            for i, article in enumerate(critical_path, 1):
                title = graph.articles.get(article, {}).get('title', article)
                depth = graph.calculate_depth(article)
                print(f"{i}. {title}")
                print(f"   –§–∞–π–ª: {article}")
                print(f"   –ì–ª—É–±–∏–Ω–∞: {depth}\n")
        else:
            print("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å (–≥—Ä–∞—Ñ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏–∫–ª—ã)\n")

    if args.curriculum:
        print(f"\nüìö –£—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è: {args.curriculum}\n")
        curriculum = graph.build_curriculum_for(args.curriculum)

        if curriculum:
            print(f"–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è: {len(curriculum)}\n")
            print("–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è:\n")
            for lesson in curriculum:
                print(f"{lesson['order']}. {lesson['title']}")
                print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {lesson['difficulty']}")
                print(f"   –ì–ª—É–±–∏–Ω–∞: {lesson['depth']}")
                print(f"   –§–∞–π–ª: {lesson['article']}\n")
        else:
            print(f"‚ùå –°—Ç–∞—Ç—å—è '{args.curriculum}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\n")

    if args.topo_sort:
        print("\nüìã –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è (Topological Sort):\n")
        topo_order, nodes_in_cycles = graph.topological_sort()

        if nodes_in_cycles:
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: {len(nodes_in_cycles)} —Å—Ç–∞—Ç–µ–π –≤ —Ü–∏–∫–ª–∞—Ö (–Ω–µ –≤–∫–ª—é—á–µ–Ω—ã –≤ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É)\n")

        print(f"–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(topo_order)}\n")
        for i, article in enumerate(topo_order[:20], 1):  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 20
            title = graph.articles.get(article, {}).get('title', article)
            depth = graph.calculate_depth(article)
            print(f"{i}. {title} (–≥–ª—É–±–∏–Ω–∞: {depth})")

        if len(topo_order) > 20:
            print(f"\n... –∏ –µ—â—ë {len(topo_order) - 20} —Å—Ç–∞—Ç–µ–π")

        print()

    if args.metrics:
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –≥—Ä–∞—Ñ–∞:\n")
        metrics = graph.calculate_graph_metrics()

        print(f"–°—Ç–∞—Ç–µ–π: {metrics['num_articles']}")
        print(f"–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {metrics['num_dependencies']}")
        print(f"–ü–ª–æ—Ç–Ω–æ—Å—Ç—å: {metrics['density']:.4f}")
        print(f"–°—Ä–µ–¥–Ω–µ prereq/—Å—Ç–∞—Ç—å—è: {metrics['avg_prerequisites_per_article']:.2f}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞: {metrics['max_depth']}")
        print(f"–¶–∏–∫–ª–æ–≤: {metrics['num_cycles']}")
        print(f"–Ø–≤–ª—è–µ—Ç—Å—è DAG: {'‚úÖ –î–∞' if metrics['is_dag'] else '‚ùå –ù–µ—Ç'}\n")

    if args.export:
        print(f"\nüì§ –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–æ—Ä–º–∞—Ç: {args.export}\n")

        if args.export == 'dot':
            graph.export_to_dot()
        elif args.export == 'html':
            graph.generate_html_visualization()
        elif args.export == 'json':
            graph.save_json()

        print()

    if args.report:
        print()
        graph.generate_report()
        graph.save_json()
        graph.generate_html_visualization()
        graph.export_to_dot()
        print()


if __name__ == "__main__":
    main()
