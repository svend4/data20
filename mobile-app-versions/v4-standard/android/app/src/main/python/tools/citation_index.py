#!/usr/bin/env python3
"""
Citation Index - –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç, –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ —Ü–∏—Ç–∏—Ä—É—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: Science Citation Index (Eugene Garfield, 1964)

–ú–µ—Ç—Ä–∏–∫–∏:
- h-index: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ h, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –µ—Å—Ç—å h —Å—Ç–∞—Ç–µ–π —Å h+ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏
- i10-index: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π —Å 10+ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏
- Impact Factor: —Å—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é
- Co-citation: —Å—Ç–∞—Ç—å–∏ —Ü–∏—Ç–∏—Ä—É–µ–º—ã–µ –≤–º–µ—Å—Ç–µ
- Bibliographic Coupling: —Å—Ç–∞—Ç—å–∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ –æ–¥–Ω–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
"""

from pathlib import Path
import yaml
import re
from collections import defaultdict, Counter
import json
import argparse
from typing import List, Dict, Tuple, Set
from datetime import datetime
import math


class CitationIndexer:
    """–ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        self.citations = defaultdict(lambda: {'cited_by': [], 'cites': [], 'citation_count': 0})

        # –í—Å–µ —Å—Ç–∞—Ç—å–∏
        self.articles = {}

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def extract_citations(self, content, source_file):
        """–ò–∑–≤–ª–µ—á—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"""
        citations = []

        # Markdown —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥—Ä—É–≥–∏–µ —Å—Ç–∞—Ç—å–∏
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)

        for text, link in links:
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏
            if link.startswith('http'):
                continue

            # –†–∞–∑—Ä–µ—à–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
            try:
                target = (Path(source_file).parent / link).resolve()

                # –£–±—Ä–∞—Ç—å —è–∫–æ—Ä—å –µ—Å–ª–∏ –µ—Å—Ç—å
                if '#' in str(target):
                    target = Path(str(target).split('#')[0])

                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if target.exists() and target.is_relative_to(self.root_dir):
                    target_path = str(target.relative_to(self.root_dir))
                    citations.append({
                        'target': target_path,
                        'context': text,
                        'type': 'link'
                    })
            except:
                pass

        # –°—Å—ã–ª–∫–∏ –∏–∑ frontmatter (related)
        frontmatter, _ = self.extract_frontmatter_and_content(source_file)

        if frontmatter and 'related' in frontmatter:
            related = frontmatter['related']
            if isinstance(related, list):
                for link in related:
                    try:
                        target = (Path(source_file).parent / link).resolve()

                        if target.exists() and target.is_relative_to(self.root_dir):
                            target_path = str(target.relative_to(self.root_dir))
                            citations.append({
                                'target': target_path,
                                'context': 'Related article',
                                'type': 'frontmatter'
                            })
                    except:
                        pass

        return citations

    def build_index(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
        print("üìö –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π...\n")

        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏
        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            frontmatter, content = self.extract_frontmatter_and_content(md_file)

            if not content:
                continue

            article_path = str(md_file.relative_to(self.root_dir))

            self.articles[article_path] = {
                'title': frontmatter.get('title', md_file.stem) if frontmatter else md_file.stem,
                'date': frontmatter.get('date', '') if frontmatter else '',
                'author': frontmatter.get('author', frontmatter.get('source', '')) if frontmatter else ''
            }

        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            article_path = str(md_file.relative_to(self.root_dir))
            _, content = self.extract_frontmatter_and_content(md_file)

            if not content:
                continue

            # –ò–∑–≤–ª–µ—á—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            citations = self.extract_citations(content, md_file)

            for citation in citations:
                target = citation['target']

                # –î–æ–±–∞–≤–∏—Ç—å –≤ –≥—Ä–∞—Ñ
                if target not in self.citations[article_path]['cites']:
                    self.citations[article_path]['cites'].append({
                        'article': target,
                        'context': citation['context'],
                        'type': citation['type']
                    })

                if article_path not in [c['article'] for c in self.citations[target]['cited_by']]:
                    self.citations[target]['cited_by'].append({
                        'article': article_path,
                        'context': citation['context'],
                        'type': citation['type']
                    })

                # –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫
                self.citations[target]['citation_count'] += 1

        print(f"   –°—Ç–∞—Ç–µ–π –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {len(self.articles)}")
        print(f"   –°–≤—è–∑–µ–π –Ω–∞–π–¥–µ–Ω–æ: {sum(len(c['cites']) for c in self.citations.values())}\n")

    def calculate_h_index(self, article_path):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å h-index –¥–ª—è —Å—Ç–∞—Ç—å–∏
        h-index = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ h, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º —Å—Ç–∞—Ç—å—è –∏–º–µ–µ—Ç h —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        –æ—Ç —Å—Ç–∞—Ç–µ–π, —É –∫–æ—Ç–æ—Ä—ã—Ö —Ç–æ–∂–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã h —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        """
        citation_counts = []

        for citing in self.citations[article_path]['cited_by']:
            citing_article = citing['article']
            citing_count = self.citations[citing_article]['citation_count']
            citation_counts.append(citing_count)

        citation_counts.sort(reverse=True)

        h = 0
        for i, count in enumerate(citation_counts, 1):
            if count >= i:
                h = i
            else:
                break

        return h

    def calculate_i10_index(self, article_path):
        """
        i10-index: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π —Å 10+ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏
        """
        count = 0
        for citing in self.citations[article_path]['cited_by']:
            citing_article = citing['article']
            citing_count = self.citations[citing_article]['citation_count']
            if citing_count >= 10:
                count += 1
        return count

    def calculate_impact_factor(self) -> float:
        """Impact Factor: —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é"""
        total_cites = sum(data['citation_count'] for data in self.citations.values())
        return total_cites / len(self.articles) if self.articles else 0.0

    def find_cocitations(self, article_path: str, min_cocitations: int = 2) -> List[Tuple[str, int]]:
        """
        Co-citation analysis: –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ü–∏—Ç–∏—Ä—É—é—Ç—Å—è –≤–º–µ—Å—Ç–µ

        –ï—Å–ª–∏ A –∏ B —Ü–∏—Ç–∏—Ä—É—é—Ç—Å—è –≤–º–µ—Å—Ç–µ –≤ —Å—Ç–∞—Ç—å–µ C, —ç—Ç–æ co-citation
        """
        cocitations = Counter()

        # –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä–∞—è —Ü–∏—Ç–∏—Ä—É–µ—Ç –Ω–∞—à—É
        for citing in self.citations[article_path]['cited_by']:
            citing_article = citing['article']

            # –ù–∞–π—Ç–∏ –¥—Ä—É–≥–∏–µ —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∞ —Ç–æ–∂–µ —Ü–∏—Ç–∏—Ä—É–µ—Ç
            for cited in self.citations[citing_article]['cites']:
                cited_article = cited['article']
                if cited_article != article_path:
                    cocitations[cited_article] += 1

        # –í–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º co-citations
        return [(article, count) for article, count in cocitations.most_common()
                if count >= min_cocitations]

    def find_bibliographic_coupling(self, article_path: str, min_coupling: int = 2) -> List[Tuple[str, int]]:
        """
        Bibliographic Coupling: —Å—Ç–∞—Ç—å–∏, —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ç–µ –∂–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

        –ï—Å–ª–∏ A –∏ B —Ü–∏—Ç–∏—Ä—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å—Ç–∞—Ç—å–∏, —ç—Ç–æ coupling
        """
        coupling = Counter()

        # –°—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ü–∏—Ç–∏—Ä—É–µ—Ç –Ω–∞—à–∞ —Å—Ç–∞—Ç—å—è
        our_cites = set(c['article'] for c in self.citations[article_path]['cites'])

        # –î–ª—è –∫–∞–∂–¥–æ–π –¥—Ä—É–≥–æ–π —Å—Ç–∞—Ç—å–∏
        for other_article in self.articles:
            if other_article == article_path:
                continue

            # –ù–∞–π—Ç–∏ –æ–±—â–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            other_cites = set(c['article'] for c in self.citations[other_article]['cites'])
            common = our_cites & other_cites

            if len(common) >= min_coupling:
                coupling[other_article] = len(common)

        return coupling.most_common()

    def calculate_citation_network_metrics(self) -> Dict:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
        # –ì—Ä–∞—Ñ –∫–∞–∫ adjacency dict
        graph = defaultdict(set)
        for article, data in self.citations.items():
            for cited in data['cites']:
                graph[article].add(cited['article'])

        # Nodes and edges
        nodes = set(self.articles.keys())
        edges = sum(len(neighbors) for neighbors in graph.values())

        # Density: actual edges / possible edges
        n = len(nodes)
        max_edges = n * (n - 1)  # Directed graph
        density = edges / max_edges if max_edges > 0 else 0

        # Average degree
        avg_out_degree = edges / n if n > 0 else 0

        # Find isolated nodes
        isolated = [node for node in nodes
                   if not graph[node] and not self.citations[node]['cited_by']]

        return {
            'nodes': n,
            'edges': edges,
            'density': round(density, 4),
            'avg_out_degree': round(avg_out_degree, 2),
            'isolated_nodes': len(isolated)
        }

    def get_most_cited(self, limit=10):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–∞–º—ã–µ —Ü–∏—Ç–∏—Ä—É–µ–º—ã–µ —Å—Ç–∞—Ç—å–∏"""
        cited = [(article, data['citation_count'])
                 for article, data in self.citations.items()
                 if data['citation_count'] > 0]

        cited.sort(key=lambda x: -x[1])

        return cited[:limit]

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –ø–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º"""
        lines = []
        lines.append("# üìö –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π\n\n")
        lines.append("> Science Citation Index style (Eugene Garfield, 1964)\n\n")
        lines.append(f"_–°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_citations = sum(data['citation_count'] for data in self.citations.values())
        articles_cited = len([a for a, d in self.citations.items() if d['citation_count'] > 0])
        impact_factor = self.calculate_impact_factor()
        network_metrics = self.calculate_citation_network_metrics()

        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π**: {len(self.articles)}\n")
        lines.append(f"- **–°—Ç–∞—Ç–µ–π —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏**: {articles_cited}\n")
        lines.append(f"- **–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π**: {total_citations}\n")
        lines.append(f"- **Impact Factor**: {impact_factor:.2f}\n\n")

        lines.append("### –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏\n\n")
        lines.append(f"- **–£–∑–ª–æ–≤**: {network_metrics['nodes']}\n")
        lines.append(f"- **–†—ë–±–µ—Ä**: {network_metrics['edges']}\n")
        lines.append(f"- **–ü–ª–æ—Ç–Ω–æ—Å—Ç—å**: {network_metrics['density']:.4f}\n")
        lines.append(f"- **Avg out-degree**: {network_metrics['avg_out_degree']:.2f}\n")
        lines.append(f"- **–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤**: {network_metrics['isolated_nodes']}\n\n")

        # –¢–æ–ø —Ü–∏—Ç–∏—Ä—É–µ–º—ã—Ö
        lines.append("## –¢–æ–ø-10 —Å–∞–º—ã—Ö —Ü–∏—Ç–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π\n\n")

        most_cited = self.get_most_cited(10)

        for i, (article, count) in enumerate(most_cited, 1):
            title = self.articles.get(article, {}).get('title', article)
            h_index = self.calculate_h_index(article)
            i10_index = self.calculate_i10_index(article)

            lines.append(f"### {i}. {title}\n\n")
            lines.append(f"- **–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π**: {count}\n")
            lines.append(f"- **h-index**: {h_index}\n")
            lines.append(f"- **i10-index**: {i10_index}\n")
            lines.append(f"- **–§–∞–π–ª**: `{article}`\n\n")

            # –ö—Ç–æ —Ü–∏—Ç–∏—Ä—É–µ—Ç
            if self.citations[article]['cited_by']:
                lines.append("**–¶–∏—Ç–∏—Ä—É—é—Ç:**\n")
                for citing in self.citations[article]['cited_by'][:5]:
                    citing_title = self.articles.get(citing['article'], {}).get('title', citing['article'])
                    lines.append(f"- [{citing_title}]({citing['article']}) ‚Äî \"{citing['context']}\"\n")

                if len(self.citations[article]['cited_by']) > 5:
                    lines.append(f"\n...–∏ –µ—â—ë {len(self.citations[article]['cited_by']) - 5}\n")

                lines.append("\n")

        # –°—Ç–∞—Ç—å–∏ –±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        uncited = [a for a, d in self.citations.items() if d['citation_count'] == 0]

        lines.append(f"\n## –°—Ç–∞—Ç—å–∏ –±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π ({len(uncited)})\n\n")

        if uncited:
            for article in sorted(uncited)[:10]:
                title = self.articles.get(article, {}).get('title', article)
                lines.append(f"- [{title}]({article})\n")

            if len(uncited) > 10:
                lines.append(f"\n...–∏ –µ—â—ë {len(uncited) - 10}\n")
        else:
            lines.append("–í—Å–µ —Å—Ç–∞—Ç—å–∏ –∏–º–µ—é—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è! üéâ\n")

        output_file = self.root_dir / "CITATION_INDEX.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π: {output_file}")

    def save_json(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å –≤ JSON"""
        articles_serializable = {}
        for path, info in self.articles.items():
            articles_serializable[path] = {
                'title': info['title'],
                'date': str(info['date']) if info['date'] else '',
                'author': info['author']
            }

        data = {
            'metadata': {
                'generated': datetime.now().isoformat(),
                'impact_factor': self.calculate_impact_factor()
            },
            'network_metrics': self.calculate_citation_network_metrics(),
            'articles': articles_serializable,
            'citations': {
                article: {
                    'citation_count': data['citation_count'],
                    'h_index': self.calculate_h_index(article),
                    'i10_index': self.calculate_i10_index(article),
                    'cited_by': data['cited_by'],
                    'cites': data['cites']
                }
                for article, data in self.citations.items()
            }
        }

        output_file = self.root_dir / "citation_index.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON –∏–Ω–¥–µ–∫—Å: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description='Citation Index - –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  %(prog)s                        # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
  %(prog)s --metrics              # –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏
  %(prog)s --cocite article.md    # Co-citation analysis
  %(prog)s --coupling article.md  # Bibliographic coupling
        """
    )

    parser.add_argument('--metrics', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π')
    parser.add_argument('--cocite', metavar='ARTICLE',
                       help='Co-citation analysis –¥–ª—è —Å—Ç–∞—Ç—å–∏')
    parser.add_argument('--coupling', metavar='ARTICLE',
                       help='Bibliographic coupling –¥–ª—è —Å—Ç–∞—Ç—å–∏')
    parser.add_argument('--top', type=int, default=10,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Å—Ç–∞—Ç–µ–π (default: 10)')

    args = parser.parse_args()

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    indexer = CitationIndexer(root_dir)
    indexer.build_index()

    if args.metrics:
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π:\n")
        metrics = indexer.calculate_citation_network_metrics()
        impact = indexer.calculate_impact_factor()

        print(f"Impact Factor: {impact:.2f}")
        print(f"–£–∑–ª–æ–≤: {metrics['nodes']}")
        print(f"–†—ë–±–µ—Ä: {metrics['edges']}")
        print(f"–ü–ª–æ—Ç–Ω–æ—Å—Ç—å: {metrics['density']:.4f}")
        print(f"Avg out-degree: {metrics['avg_out_degree']:.2f}")
        print(f"–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {metrics['isolated_nodes']}\n")

    elif args.cocite:
        article_path = f"knowledge/{args.cocite}"
        print(f"\nüîó Co-citation analysis: {args.cocite}\n")
        cocites = indexer.find_cocitations(article_path)

        if cocites:
            for article, count in cocites[:5]:
                title = indexer.articles.get(article, {}).get('title', article)
                print(f"{count} co-citations: {title}")
        else:
            print("No co-citations found")
        print()

    elif args.coupling:
        article_path = f"knowledge/{args.coupling}"
        print(f"\nüìö Bibliographic coupling: {args.coupling}\n")
        coupling = indexer.find_bibliographic_coupling(article_path)

        if coupling:
            for article, count in coupling[:5]:
                title = indexer.articles.get(article, {}).get('title', article)
                print(f"{count} common citations: {title}")
        else:
            print("No bibliographic coupling found")
        print()

    else:
        indexer.generate_report()
        indexer.save_json()


if __name__ == "__main__":
    main()
