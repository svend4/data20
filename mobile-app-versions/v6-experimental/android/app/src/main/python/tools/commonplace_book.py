#!/usr/bin/env python3
"""
Commonplace Book - –ö–Ω–∏–≥–∞ –≤—ã–ø–∏—Å–æ–∫
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ü–∏—Ç–∞—Ç—ã, –≤–∞–∂–Ω—ã–µ –º—ã—Å–ª–∏ –∏ –ø–∞–º—è—Ç–Ω—ã–µ –æ—Ç—Ä—ã–≤–∫–∏

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: Renaissance commonplace books (15-17 –≤–µ–∫–∞)
–¢—Ä–∞–¥–∏—Ü–∏—è: John Locke, Marcus Aurelius, Thomas Jefferson

Features:
- Smart pattern matching –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
- Sentiment analysis (positive/negative/neutral)
- Ranking –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
- Spaced repetition –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
- HTML visualization
"""

from pathlib import Path
import yaml
import re
from collections import defaultdict, Counter
import json
import argparse
from typing import List, Dict, Tuple
from datetime import datetime, timedelta
import hashlib


class SentimentAnalyzer:
    """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""

    POSITIVE_WORDS = {'—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '—É—Å–ø–µ—à–Ω–æ', '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ', '–ø–æ–ª–µ–∑–Ω–æ',
                      '–≤–∞–∂–Ω–æ', '—Ü–µ–Ω–Ω–æ', '–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ', '—É–ª—É—á—à–µ–Ω–∏–µ', '—Ä–∞–∑–≤–∏—Ç–∏–µ'}
    NEGATIVE_WORDS = {'–ø–ª–æ—Ö–æ', '–æ—à–∏–±–∫–∞', '–ø—Ä–æ–±–ª–µ–º–∞', '–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫', '—Å–ª–æ–∂–Ω–æ—Å—Ç—å', '—Ä–∏—Å–∫',
                      '–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '—É–≥—Ä–æ–∑–∞', '—Å–ª–∞–±–æ—Å—Ç—å', '–Ω–µ–¥–æ—á—ë—Ç'}

    @staticmethod
    def analyze(text: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
        Returns: 'positive', 'negative', 'neutral'
        """
        words = set(text.lower().split())

        positive_count = len(words & SentimentAnalyzer.POSITIVE_WORDS)
        negative_count = len(words & SentimentAnalyzer.NEGATIVE_WORDS)

        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        return 'neutral'


class ExcerptRanker:
    """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–∏—Å–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏"""

    @staticmethod
    def calculate_importance(excerpt: Dict) -> float:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –≤—ã–ø–∏—Å–∫–∏ (0-1)

        –§–∞–∫—Ç–æ—Ä—ã:
        - –î–ª–∏–Ω–∞ (–æ–ø—Ç–∏–º—É–º 50-200 —Å–∏–º–≤–æ–ª–æ–≤)
        - –¢–∏–ø (quote > principle > key_idea > important > definition > example)
        - Sentiment (positive/neutral > negative)
        """
        score = 0.0
        text = excerpt['text']

        # Length score (optimal 50-200 chars)
        length = len(text)
        if 50 <= length <= 200:
            score += 0.4
        elif 30 <= length <= 300:
            score += 0.2

        # Type score
        type_scores = {
            'quote': 0.3,
            'principle': 0.25,
            'key_idea': 0.2,
            'important': 0.15,
            'definition': 0.1,
            'example': 0.05
        }
        score += type_scores.get(excerpt.get('type', 'quote'), 0.1)

        # Sentiment score
        sentiment = excerpt.get('sentiment', 'neutral')
        if sentiment == 'positive':
            score += 0.2
        elif sentiment == 'neutral':
            score += 0.1

        # Has tags bonus
        if excerpt.get('tags'):
            score += 0.1

        return min(score, 1.0)


class SpacedRepetitionScheduler:
    """–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã—Ö –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π (Spaced Repetition)"""

    INTERVALS = [1, 3, 7, 14, 30, 60, 120]  # days

    def __init__(self):
        self.review_schedule = {}

    def schedule_excerpt(self, excerpt_id: str, level: int = 0) -> datetime:
        """
        –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ

        level: —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å (0-6)
        Returns: –¥–∞—Ç–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        """
        if level >= len(self.INTERVALS):
            level = len(self.INTERVALS) - 1

        days = self.INTERVALS[level]
        next_review = datetime.now() + timedelta(days=days)

        self.review_schedule[excerpt_id] = {
            'level': level,
            'next_review': next_review,
            'last_reviewed': datetime.now()
        }

        return next_review

    def get_due_excerpts(self, all_excerpts: List[Dict]) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—ã–ø–∏—Å–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ä–∞ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å"""
        now = datetime.now()
        due = []

        for excerpt in all_excerpts:
            excerpt_id = excerpt.get('id', '')
            schedule = self.review_schedule.get(excerpt_id)

            if schedule and schedule['next_review'] <= now:
                excerpt['review_info'] = schedule
                due.append(excerpt)

        return due


class CommonplaceBookBuilder:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –∫–Ω–∏–≥–∏ –≤—ã–ø–∏—Å–æ–∫"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –í—ã–ø–∏—Å–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        self.excerpts = defaultdict(list)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_excerpts = 0

        # Analyzers
        self.sentiment_analyzer = SentimentAnalyzer()
        self.ranker = ExcerptRanker()
        self.scheduler = SpacedRepetitionScheduler()

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def extract_excerpts(self, content, source_file):
        """–ò–∑–≤–ª–µ—á—å –≤—ã–ø–∏—Å–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        excerpts = []

        # 1. –ë–ª–æ—á–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã (> —Ç–µ–∫—Å—Ç)
        blockquotes = re.findall(r'^>\s+(.+)$', content, re.MULTILINE)
        for quote in blockquotes:
            if len(quote) > 20:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
                excerpts.append({
                    'text': quote.strip(),
                    'type': 'quote',
                    'source': source_file
                })

        # 2. –í—ã–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (**–≤–∞–∂–Ω–æ**, *–≤–∞–∂–Ω–æ*)
        important = re.findall(r'\*\*([^*]{20,}?)\*\*', content)
        for text in important:
            # –ò—Å–∫–ª—é—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if not text.isupper() and ':' not in text[:20]:
                excerpts.append({
                    'text': text.strip(),
                    'type': 'important',
                    'source': source_file
                })

        # 3. –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã (–ø–∞—Ç—Ç–µ—Ä–Ω—ã)
        key_patterns = [
            r'–í–∞–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å[,:]\s*(.{30,200}?)[.!]',
            r'–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è[,:]\s*(.{30,200}?)[.!]',
            r'–ì–ª–∞–≤–Ω–æ–µ[,:]\s*(.{30,200}?)[.!]',
            r'–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–Ω–∏—Ç—å[,:]\s*(.{30,200}?)[.!]',
            r'–°–ª–µ–¥—É–µ—Ç –æ—Ç–º–µ—Ç–∏—Ç—å[,:]\s*(.{30,200}?)[.!]'
        ]

        for pattern in key_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                excerpts.append({
                    'text': match.strip(),
                    'type': 'key_idea',
                    'source': source_file
                })

        # 4. –°–ø–∏—Å–∫–∏ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤/–ø—Ä–∞–≤–∏–ª
        principle_patterns = [
            r'^[-*]\s+\*\*(.+?)\*\*\s*[-‚Äî‚Äì]\s*(.+)$',
            r'^\d+\.\s+\*\*(.+?)\*\*\s*[-‚Äî‚Äì]\s*(.+)$'
        ]

        for pattern in principle_patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            for title, description in matches:
                if len(description) > 20:
                    excerpts.append({
                        'text': f"{title}: {description}",
                        'type': 'principle',
                        'source': source_file
                    })

        # 5. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤
        definitions = re.findall(r'\*\*([–ê-–ØA-Z][^*]+?)\*\*\s*[-‚Äî‚Äì]\s*([^.\n]{20,200}?)[.]', content)
        for term, definition in definitions:
            excerpts.append({
                'text': f"{term} ‚Äî {definition}",
                'type': 'definition',
                'source': source_file
            })

        # 6. –ü—Ä–∏–º–µ—Ä—ã (Example:, –ü—Ä–∏–º–µ—Ä:)
        examples = re.findall(r'(?:Example|–ü—Ä–∏–º–µ—Ä)[:\s]+(.{50,300}?)(?:\n\n|\n(?=[A-Z–ê-–Ø]))', content, re.IGNORECASE)
        for example in examples:
            excerpts.append({
                'text': example.strip(),
                'type': 'example',
                'source': source_file
            })

        return excerpts

    def build_commonplace_book(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–Ω–∏–≥—É –≤—ã–ø–∏—Å–æ–∫"""
        print("üìñ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–Ω–∏–≥–∏ –≤—ã–ø–∏—Å–æ–∫...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            frontmatter, content = self.extract_frontmatter_and_content(md_file)

            if not content:
                continue

            article_path = str(md_file.relative_to(self.root_dir))
            title = frontmatter.get('title', md_file.stem) if frontmatter else md_file.stem
            category = frontmatter.get('category', '–û–±—â–µ–µ') if frontmatter else '–û–±—â–µ–µ'
            tags = frontmatter.get('tags', []) if frontmatter else []

            # –ò–∑–≤–ª–µ—á—å –≤—ã–ø–∏—Å–∫–∏
            excerpts = self.extract_excerpts(content, article_path)

            for excerpt in excerpts:
                excerpt['article_title'] = title
                excerpt['category'] = category
                excerpt['tags'] = tags

                # Generate ID
                excerpt_text = excerpt['text']
                excerpt['id'] = hashlib.md5(excerpt_text.encode()).hexdigest()[:12]

                # Sentiment analysis
                excerpt['sentiment'] = self.sentiment_analyzer.analyze(excerpt_text)

                # Calculate importance
                excerpt['importance'] = self.ranker.calculate_importance(excerpt)

                # Schedule for spaced repetition
                self.scheduler.schedule_excerpt(excerpt['id'], level=0)

                # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                self.excerpts[category].append(excerpt)
                self.total_excerpts += 1

        print(f"   –í—ã–ø–∏—Å–æ–∫ —Å–æ–±—Ä–∞–Ω–æ: {self.total_excerpts}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(self.excerpts)}\n")

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –∫–Ω–∏–≥—É –≤—ã–ø–∏—Å–æ–∫"""
        lines = []
        lines.append("# üìñ Commonplace Book ‚Äî –ö–Ω–∏–≥–∞ –≤—ã–ø–∏—Å–æ–∫\n\n")
        lines.append("> –°–æ–±—Ä–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º—ã—Å–ª–µ–π, —Ü–∏—Ç–∞—Ç –∏ –∏–¥–µ–π –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n\n")
        lines.append("*–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ —Ç—Ä–∞–¥–∏—Ü–∏–µ–π Renaissance commonplace books*\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–í—Å–µ–≥–æ –≤—ã–ø–∏—Å–æ–∫**: {self.total_excerpts}\n")
        lines.append(f"- **–ö–∞—Ç–µ–≥–æ—Ä–∏–π**: {len(self.excerpts)}\n\n")

        # –¢–∏–ø—ã –≤—ã–ø–∏—Å–æ–∫
        type_counts = defaultdict(int)
        for category_excerpts in self.excerpts.values():
            for excerpt in category_excerpts:
                type_counts[excerpt['type']] += 1

        lines.append("**–ü–æ —Ç–∏–ø–∞–º:**\n\n")
        type_names = {
            'quote': '–¶–∏—Ç–∞—Ç—ã',
            'important': '–í–∞–∂–Ω—ã–µ –º—ã—Å–ª–∏',
            'key_idea': '–ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏',
            'principle': '–ü—Ä–∏–Ω—Ü–∏–ø—ã',
            'definition': '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è',
            'example': '–ü—Ä–∏–º–µ—Ä—ã'
        }

        for excerpt_type, count in sorted(type_counts.items(), key=lambda x: -x[1]):
            name = type_names.get(excerpt_type, excerpt_type)
            lines.append(f"- **{name}**: {count}\n")

        lines.append("\n---\n\n")

        # –í—ã–ø–∏—Å–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category in sorted(self.excerpts.keys()):
            excerpts = self.excerpts[category]

            lines.append(f"## {category}\n\n")
            lines.append(f"*{len(excerpts)} –≤—ã–ø–∏—Å–æ–∫*\n\n")

            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ç–∏–ø–∞–º
            by_type = defaultdict(list)
            for excerpt in excerpts:
                by_type[excerpt['type']].append(excerpt)

            for excerpt_type in ['quote', 'key_idea', 'important', 'principle', 'definition', 'example']:
                if excerpt_type not in by_type:
                    continue

                type_name = type_names.get(excerpt_type, excerpt_type)
                lines.append(f"### {type_name}\n\n")

                for excerpt in by_type[excerpt_type][:10]:  # –¢–æ–ø-10 –ø–æ —Ç–∏–ø—É
                    lines.append(f"> {excerpt['text']}\n\n")
                    lines.append(f"‚Äî *[{excerpt['article_title']}]({excerpt['source']})*\n\n")

                if len(by_type[excerpt_type]) > 10:
                    lines.append(f"*...–∏ –µ—â—ë {len(by_type[excerpt_type]) - 10}*\n\n")

            lines.append("\n")

        output_file = self.root_dir / "COMMONPLACE_BOOK.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –ö–Ω–∏–≥–∞ –≤—ã–ø–∏—Å–æ–∫: {output_file}")

    def generate_by_topic(self):
        """–°–æ–∑–¥–∞—Ç—å —É–∫–∞–∑–∞—Ç–µ–ª—å –ø–æ —Ç–µ–º–∞–º"""
        lines = []
        lines.append("# üìö –í—ã–ø–∏—Å–∫–∏ –ø–æ —Ç–µ–º–∞–º\n\n")

        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Ç–µ–≥–∏
        all_tags = defaultdict(list)

        for category_excerpts in self.excerpts.values():
            for excerpt in category_excerpts:
                for tag in excerpt['tags']:
                    all_tags[tag].append(excerpt)

        # –í—ã–≤–µ—Å—Ç–∏ –ø–æ —Ç–µ–≥–∞–º
        for tag in sorted(all_tags.keys()):
            excerpts = all_tags[tag]

            lines.append(f"## {tag}\n\n")
            lines.append(f"*{len(excerpts)} –≤—ã–ø–∏—Å–æ–∫*\n\n")

            for excerpt in excerpts[:15]:
                lines.append(f"> {excerpt['text'][:150]}{'...' if len(excerpt['text']) > 150 else ''}\n\n")
                lines.append(f"‚Äî *[{excerpt['article_title']}]({excerpt['source']})*\n\n")

            if len(excerpts) > 15:
                lines.append(f"*...–∏ –µ—â—ë {len(excerpts) - 15}*\n\n")

            lines.append("\n")

        output_file = self.root_dir / "EXCERPTS_BY_TOPIC.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –í—ã–ø–∏—Å–∫–∏ –ø–æ —Ç–µ–º–∞–º: {output_file}")

    def save_json(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã–ø–∏—Å–∫–∏ –≤ JSON"""
        data = {
            'total': self.total_excerpts,
            'categories': {}
        }

        for category, excerpts in self.excerpts.items():
            data['categories'][category] = [
                {
                    'text': e['text'],
                    'type': e['type'],
                    'source': e['source'],
                    'article_title': e['article_title'],
                    'tags': e['tags']
                }
                for e in excerpts
            ]

        output_file = self.root_dir / "commonplace_book.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON –¥–∞–Ω–Ω—ã–µ: {output_file}")

    def generate_top_excerpts(self, limit: int = 50):
        """–°–æ–∑–¥–∞—Ç—å —Ç–æ–ø –≤—ã–ø–∏—Å–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏"""
        all_excerpts = []
        for category_excerpts in self.excerpts.values():
            all_excerpts.extend(category_excerpts)

        # Sort by importance
        all_excerpts.sort(key=lambda x: x.get('importance', 0), reverse=True)

        lines = []
        lines.append("# üåü –¢–æ–ø –≤—ã–ø–∏—Å–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\n\n")

        for i, excerpt in enumerate(all_excerpts[:limit], 1):
            importance = excerpt.get('importance', 0)
            sentiment = excerpt.get('sentiment', 'neutral')

            sentiment_emoji = {'positive': 'üòä', 'negative': 'üòü', 'neutral': 'üòê'}
            emoji = sentiment_emoji.get(sentiment, 'üòê')

            lines.append(f"## {i}. {emoji} [{excerpt['article_title']}]({excerpt['source']})\n\n")
            lines.append(f"> {excerpt['text']}\n\n")
            lines.append(f"**–í–∞–∂–Ω–æ—Å—Ç—å**: {importance:.2f} | **–¢–∏–ø**: {excerpt['type']} | **–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å**: {sentiment}\n\n")

        output_file = self.root_dir / "TOP_EXCERPTS.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –¢–æ–ø –≤—ã–ø–∏—Å–æ–∫: {output_file}")

    def generate_html_visualization(self):
        """–°–æ–∑–¥–∞—Ç—å HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é"""
        all_excerpts = []
        for category_excerpts in self.excerpts.values():
            all_excerpts.extend(category_excerpts)

        all_excerpts.sort(key=lambda x: x.get('importance', 0), reverse=True)

        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Commonplace Book</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: 'Georgia', serif; max-width: 900px; margin: 40px auto; padding: 20px; background: #f9f7f4; }}
        h1 {{ color: #5a4a42; border-bottom: 3px solid #8b7355; padding-bottom: 10px; }}
        .excerpt {{ background: white; padding: 20px; margin: 20px 0; border-left: 4px solid #8b7355; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .excerpt-text {{ font-size: 1.1em; line-height: 1.6; color: #333; font-style: italic; margin: 15px 0; }}
        .excerpt-meta {{ font-size: 0.9em; color: #666; }}
        .importance-bar {{ height: 6px; background: #ddd; margin: 10px 0; }}
        .importance-fill {{ height: 100%; background: linear-gradient(90deg, #8b7355, #d4a574); }}
        .sentiment-positive {{ border-left-color: #4caf50; }}
        .sentiment-negative {{ border-left-color: #f44336; }}
        .sentiment-neutral {{ border-left-color: #8b7355; }}
    </style>
</head>
<body>
    <h1>üìñ Commonplace Book</h1>
    <p><em>–°–æ–±—Ä–∞–Ω–∏–µ {len(all_excerpts)} —Ü–µ–Ω–Ω—ã—Ö –º—ã—Å–ª–µ–π –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π</em></p>
"""

        for i, excerpt in enumerate(all_excerpts[:100], 1):
            importance = excerpt.get('importance', 0) * 100
            sentiment = excerpt.get('sentiment', 'neutral')

            html += f"""
    <div class="excerpt sentiment-{sentiment}">
        <div class="excerpt-text">"{excerpt['text']}"</div>
        <div class="excerpt-meta">
            ‚Äî <strong>{excerpt['article_title']}</strong> ‚Ä¢ {excerpt['type']}
        </div>
        <div class="importance-bar">
            <div class="importance-fill" style="width: {importance}%"></div>
        </div>
    </div>
"""

        html += """
</body>
</html>"""

        output_file = self.root_dir / "commonplace_book.html"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html)

        print(f"‚úÖ HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description='Commonplace Book - –ö–Ω–∏–≥–∞ –≤—ã–ø–∏—Å–æ–∫',
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  %(prog)s                  # –ü–æ–ª–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
  %(prog)s --top 50         # –¢–æ–ø-50 –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
  %(prog)s --html           # HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
  %(prog)s --sentiment      # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        """
    )

    parser.add_argument('--top', type=int, metavar='N',
                       help='–°–æ–∑–¥–∞—Ç—å —Ç–æ–ø-N –≤—ã–ø–∏—Å–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏')
    parser.add_argument('--html', action='store_true',
                       help='–°–æ–∑–¥–∞—Ç—å HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é')
    parser.add_argument('--sentiment', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏')
    parser.add_argument('--by-topic', action='store_true',
                       help='–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ç–µ–º–∞–º')

    args = parser.parse_args()

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    builder = CommonplaceBookBuilder(root_dir)
    builder.build_commonplace_book()

    if args.sentiment:
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:\n")
        sentiment_counts = Counter()
        for category_excerpts in builder.excerpts.values():
            for excerpt in category_excerpts:
                sentiment_counts[excerpt.get('sentiment', 'neutral')] += 1

        total = sum(sentiment_counts.values())
        for sentiment, count in sentiment_counts.most_common():
            percent = (count / total * 100) if total > 0 else 0
            emoji = {'positive': 'üòä', 'negative': 'üòü', 'neutral': 'üòê'}
            print(f"{emoji.get(sentiment, 'üòê')} {sentiment}: {count} ({percent:.1f}%)")
        print()

    if args.top:
        builder.generate_top_excerpts(limit=args.top)

    if args.html:
        builder.generate_html_visualization()

    if args.by_topic:
        builder.generate_by_topic()

    if not any([args.top, args.html, args.sentiment, args.by_topic]):
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø–æ–ª–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        builder.generate_report()
        builder.generate_by_topic()
        builder.generate_top_excerpts()
        builder.generate_html_visualization()
        builder.save_json()


if __name__ == "__main__":
    main()
