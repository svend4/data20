#!/usr/bin/env python3
"""
Master Index - –ì–ª–∞–≤–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å
–°–æ–∑–¥–∞—ë—Ç –ø–æ–ª–Ω—ã–π –∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å –≤—Å–µ—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: Book index, Encyclopedia index
"""

from pathlib import Path
import yaml
import re
from collections import defaultdict
import json


class MasterIndexBuilder:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –≥–ª–∞–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞—Ç–µ–ª—è"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –ò–Ω–¥–µ–∫—Å: —Ç–µ—Ä–º–∏–Ω -> —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
        self.index = defaultdict(list)

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def extract_terms(self, content):
        """–ò–∑–≤–ª–µ—á—å —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        terms = set()

        # –í—ã–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (**—Ç–µ—Ä–º–∏–Ω**)
        bold_terms = re.findall(r'\*\*([–ê-–ØA-Z][^\*]{2,40}?)\*\*', content)
        terms.update(bold_terms)

        # –¢–µ—Ä–º–∏–Ω—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        headings = re.findall(r'^#{2,6}\s+(.+)$', content, re.MULTILINE)
        terms.update(headings)

        return terms

    def build_index(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å"""
        print("üìá –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞—Ç–µ–ª—è...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            frontmatter, content = self.extract_frontmatter_and_content(md_file)

            if not content:
                continue

            article_path = str(md_file.relative_to(self.root_dir))
            title = frontmatter.get('title', md_file.stem) if frontmatter else md_file.stem

            # –ò–∑–≤–ª–µ—á—å —Ç–µ—Ä–º–∏–Ω—ã
            terms = self.extract_terms(content)

            # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Ä–º–∏–Ω—ã –≤ –∏–Ω–¥–µ–∫—Å
            for term in terms:
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                term_clean = term.strip()

                if len(term_clean) < 3:
                    continue

                # –î–æ–±–∞–≤–∏—Ç—å –≤ –∏–Ω–¥–µ–∫—Å
                if article_path not in [a['path'] for a in self.index[term_clean]]:
                    self.index[term_clean].append({
                        'path': article_path,
                        'title': title
                    })

            # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–≥–∏ –∫–∞–∫ —Ç–µ—Ä–º–∏–Ω—ã
            if frontmatter and 'tags' in frontmatter:
                for tag in frontmatter['tags']:
                    if article_path not in [a['path'] for a in self.index[tag]]:
                        self.index[tag].append({
                            'path': article_path,
                            'title': title
                        })

        print(f"   –¢–µ—Ä–º–∏–Ω–æ–≤ –≤ —É–∫–∞–∑–∞—Ç–µ–ª–µ: {len(self.index)}")
        print(f"   –°—Å—ã–ª–æ–∫: {sum(len(articles) for articles in self.index.values())}\n")

    def generate_master_index(self):
        """–°–æ–∑–¥–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å"""
        lines = []
        lines.append("# üìá –ì–ª–∞–≤–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å\n\n")
        lines.append("> –ê–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å –≤—Å–µ—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–¢–µ—Ä–º–∏–Ω–æ–≤**: {len(self.index)}\n")
        lines.append(f"- **–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫**: {sum(len(articles) for articles in self.index.values())}\n\n")

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –ø–µ—Ä–≤–æ–π –±—É–∫–≤–µ
        by_letter = defaultdict(list)

        for term in sorted(self.index.keys(), key=str.lower):
            first_letter = term[0].upper()
            by_letter[first_letter].append(term)

        # –ù–∞–≤–∏–≥–∞—Ü–∏—è
        lines.append("## –ù–∞–≤–∏–≥–∞—Ü–∏—è\n\n")
        for letter in sorted(by_letter.keys()):
            lines.append(f"[{letter}](#{letter}) ")
        lines.append("\n\n")

        # –¢–µ—Ä–º–∏–Ω—ã –ø–æ –±—É–∫–≤–∞–º
        for letter in sorted(by_letter.keys()):
            lines.append(f"## {letter}\n\n")

            for term in sorted(by_letter[letter], key=str.lower):
                articles = self.index[term]

                lines.append(f"### {term}\n\n")

                for article in articles:
                    lines.append(f"- [{article['title']}]({article['path']})\n")

                lines.append("\n")

        output_file = self.root_dir / "MASTER_INDEX.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –ì–ª–∞–≤–Ω—ã–π —É–∫–∞–∑–∞—Ç–µ–ª—å: {output_file}")

    def save_json(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON"""
        data = {
            'total_terms': len(self.index),
            'total_references': sum(len(articles) for articles in self.index.values()),
            'index': {
                term: articles
                for term, articles in sorted(self.index.items())
            }
        }

        output_file = self.root_dir / "master_index.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON –∏–Ω–¥–µ–∫—Å: {output_file}")


def main():
    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    builder = MasterIndexBuilder(root_dir)
    builder.build_index()
    builder.generate_master_index()
    builder.save_json()

    print("\nüéâ –í–°–ï 47 –ú–ï–¢–û–î–û–í –†–ï–ê–õ–ò–ó–û–í–ê–ù–´!")


if __name__ == "__main__":
    main()
