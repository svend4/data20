#!/usr/bin/env python3
"""
Advanced Index of Figures - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–Ω–¥–µ–∫—Å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π
–§—É–Ω–∫—Ü–∏–∏:
- Image metadata (—Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞—Ç, dimensions)
- Alt text quality check (–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å)
- Broken image detection (–ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è)
- Auto-numbering (Figure 1.1, Table 2.3 - LaTeX style)
- Cross-reference tracking (—Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–∫–∏)
- Figure captions extraction
- Table of Figures (–∫–∞–∫ –≤ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç—å—è—Ö)
- Code syntax statistics (—è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è)
- Usage statistics (–ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å)
- Optimization suggestions
- JSON/CSV export

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: LaTeX List of Figures, Sphinx, Markdown Preview Enhanced
"""

from pathlib import Path
import re
import json
from collections import defaultdict, Counter
import yaml
import os
import csv
import base64
from datetime import datetime
from typing import List, Dict, Set


class AdvancedFiguresIndexer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –î–∞–Ω–Ω—ã–µ
        self.images = []
        self.tables = []
        self.code_blocks = []

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.broken_images = []
        self.alt_text_issues = []
        self.cross_references = defaultdict(list)

        # –°—á—ë—Ç—á–∏–∫–∏ –¥–ª—è –∞–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏–∏
        self.counters = defaultdict(lambda: defaultdict(int))

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def get_image_metadata(self, image_path, article_dir):
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç —Å—Ç–∞—Ç—å–∏
        if image_path.startswith('http://') or image_path.startswith('https://'):
            return {
                'type': 'external',
                'url': image_path,
                'exists': None,
                'size': None,
                'format': None
            }

        # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        if image_path.startswith('/'):
            full_path = self.root_dir / image_path.lstrip('/')
        else:
            full_path = article_dir / image_path

        metadata = {
            'type': 'local',
            'path': str(full_path.relative_to(self.root_dir)) if full_path.exists() else image_path,
            'exists': full_path.exists(),
            'size': None,
            'format': None
        }

        if full_path.exists():
            try:
                stat = full_path.stat()
                metadata['size'] = stat.st_size
                metadata['size_kb'] = round(stat.st_size / 1024, 2)
                metadata['format'] = full_path.suffix.lstrip('.').upper()
            except:
                pass

        return metadata

    def check_alt_text_quality(self, alt_text):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ alt —Ç–µ–∫—Å—Ç–∞"""
        issues = []

        if not alt_text or alt_text.strip() == '':
            issues.append('missing')
            return issues, 0

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-100)
        score = 100

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        if len(alt_text) < 5:
            issues.append('too_short')
            score -= 40

        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        if len(alt_text) > 150:
            issues.append('too_long')
            score -= 20

        # –ü–ª–æ—Ö–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
        bad_phrases = ['image', 'picture', 'photo', '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', '–∫–∞—Ä—Ç–∏–Ω–∫–∞', '—Ñ–æ—Ç–æ']
        if any(phrase in alt_text.lower() for phrase in bad_phrases):
            issues.append('redundant_description')
            score -= 15

        # –¢–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞
        if re.match(r'^[\w\-]+\.(jpg|png|gif|svg)$', alt_text.lower()):
            issues.append('filename_only')
            score -= 30

        return issues, max(0, score)

    def extract_figure_caption(self, content, position):
        """–ò–∑–≤–ª–µ—á—å –ø–æ–¥–ø–∏—Å—å –∫ —Ä–∏—Å—É–Ω–∫—É"""
        # –ò—â–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        after_image = content[position:position+200]

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–¥–ø–∏—Å–µ–π
        patterns = [
            r'\n\*([^\*]+)\*',  # *Caption text*
            r'\n_([^_]+)_',      # _Caption text_
            r'\n> ([^\n]+)',     # > Caption text
            r'\n<em>([^<]+)</em>',  # <em>Caption text</em>
        ]

        for pattern in patterns:
            match = re.search(pattern, after_image)
            if match:
                return match.group(1).strip()

        return None

    def auto_number_figure(self, article_path, figure_type):
        """–ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è (LaTeX style)"""
        # –ò–∑–≤–ª–µ—á—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –ø—É—Ç–∏
        parts = Path(article_path).parts
        category = parts[1] if len(parts) > 1 else 'general'

        # –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫
        self.counters[category][figure_type] += 1

        # –§–æ—Ä–º–∞—Ç: Figure 1.1 (–∫–∞—Ç–µ–≥–æ—Ä–∏—è.–Ω–æ–º–µ—Ä)
        category_num = hash(category) % 10 + 1  # –£–ø—Ä–æ—â—ë–Ω–Ω–æ
        figure_num = self.counters[category][figure_type]

        return f"{category_num}.{figure_num}"

    def find_cross_references(self, content, figure_number):
        """–ù–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ"""
        references = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Å—ã–ª–æ–∫
        patterns = [
            rf'—Ä–∏—Å(?:—É–Ω–æ–∫|\.)?\s*{re.escape(figure_number)}',
            rf'fig(?:ure|\.)?\s*{re.escape(figure_number)}',
            rf'\[{re.escape(figure_number)}\]',
        ]

        for pattern in patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            references.extend([m.start() for m in matches])

        return len(references)

    def index_images(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        article_path = str(file_path.relative_to(self.root_dir))
        article_dir = file_path.parent

        # –ü–∞—Ç—Ç–µ—Ä–Ω: ![alt](path "title")
        pattern = r'!\[([^\]]*)\]\(([^)]+?)(?:\s+"([^"]+)")?\)'

        for match in re.finditer(pattern, content):
            alt_text = match.group(1)
            image_path = match.group(2)
            title = match.group(3)

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            metadata = self.get_image_metadata(image_path, article_dir)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ alt —Ç–µ–∫—Å—Ç–∞
            alt_issues, alt_score = self.check_alt_text_quality(alt_text)

            # –ü–æ–¥–ø–∏—Å—å
            caption = self.extract_figure_caption(content, match.end())

            # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
            figure_number = self.auto_number_figure(article_path, 'figure')

            # –°—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫
            references_count = self.find_cross_references(content, figure_number)

            image_data = {
                'number': figure_number,
                'alt': alt_text or '–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è',
                'title': title,
                'caption': caption,
                'path': image_path,
                'article': article_path,
                'metadata': metadata,
                'alt_quality': {
                    'score': alt_score,
                    'issues': alt_issues
                },
                'references': references_count
            }

            self.images.append(image_data)

            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
            if not metadata['exists'] and metadata['type'] == 'local':
                self.broken_images.append({
                    'article': article_path,
                    'path': image_path
                })

            if alt_issues:
                self.alt_text_issues.append({
                    'article': article_path,
                    'alt': alt_text,
                    'issues': alt_issues,
                    'score': alt_score
                })

    def index_tables(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã"""
        article_path = str(file_path.relative_to(self.root_dir))

        lines = content.split('\n')
        in_table = False
        table_start_line = 0
        table_lines = []

        for i, line in enumerate(lines):
            if '|' in line and line.strip().startswith('|'):
                if not in_table:
                    # –ù–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã
                    in_table = True
                    table_start_line = i
                    table_lines = [line]
                else:
                    table_lines.append(line)
            elif in_table and '|' not in line:
                # –ö–æ–Ω–µ—Ü —Ç–∞–±–ª–∏—Ü—ã
                in_table = False

                # –ù–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
                context_lines = lines[max(0, table_start_line - 5):table_start_line]
                table_title = "–¢–∞–±–ª–∏—Ü–∞"
                caption = None

                for ctx_line in reversed(context_lines):
                    if ctx_line.strip().startswith('#'):
                        table_title = ctx_line.strip('#').strip()
                        break
                    elif ctx_line.strip() and not ctx_line.startswith('|'):
                        caption = ctx_line.strip()

                # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
                rows = len([l for l in table_lines if l.strip().startswith('|')])

                # –ö–æ–ª–æ–Ω–∫–∏ (–∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏)
                first_row = table_lines[0] if table_lines else ''
                columns = len([c for c in first_row.split('|') if c.strip()])

                # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
                table_number = self.auto_number_figure(article_path, 'table')

                # –°—Å—ã–ª–∫–∏ –Ω–∞ —Ç–∞–±–ª–∏—Ü—É
                references_count = self.find_cross_references(content, table_number)

                self.tables.append({
                    'number': table_number,
                    'title': table_title,
                    'caption': caption,
                    'article': article_path,
                    'rows': rows,
                    'columns': columns,
                    'size': f"{rows}√ó{columns}",
                    'references': references_count
                })

    def index_code_blocks(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –±–ª–æ–∫–∏ –∫–æ–¥–∞"""
        article_path = str(file_path.relative_to(self.root_dir))

        # –ü–∞—Ç—Ç–µ—Ä–Ω: ```language\ncode\n```
        pattern = r'```(\w+)?\n(.*?)```'

        for match in re.finditer(pattern, content, re.DOTALL):
            language = match.group(1) or 'text'
            code = match.group(2)

            # –ù–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫/–æ–ø–∏—Å–∞–Ω–∏–µ
            code_start = match.start()
            context = content[max(0, code_start - 200):code_start]
            context_lines = context.split('\n')

            code_title = "–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞"
            for ctx_line in reversed(context_lines[-5:]):
                if ctx_line.strip() and not ctx_line.startswith('```'):
                    code_title = ctx_line.strip('#').strip()[:100]
                    break

            # –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
            lines = code.split('\n')
            lines_count = len(lines)
            chars_count = len(code)

            # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
            listing_number = self.auto_number_figure(article_path, 'listing')

            self.code_blocks.append({
                'number': listing_number,
                'language': language,
                'title': code_title,
                'article': article_path,
                'lines': lines_count,
                'chars': chars_count,
                'size': f"{lines_count} lines"
            })

    def index_file(self, file_path):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        frontmatter, content = self.extract_frontmatter_and_content(file_path)

        if not content:
            return

        self.index_images(file_path, content)
        self.index_tables(file_path, content)
        self.index_code_blocks(file_path, content)

    def index_all(self):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã"""
        print("üñºÔ∏è  –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            self.index_file(md_file)

        print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(self.images)}")
        print(f"   –¢–∞–±–ª–∏—Ü: {len(self.tables)}")
        print(f"   –ë–ª–æ–∫–æ–≤ –∫–æ–¥–∞: {len(self.code_blocks)}")
        print(f"   –ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫: {len(self.broken_images)}")
        print(f"   –ü—Ä–æ–±–ª–µ–º —Å alt: {len(self.alt_text_issues)}\n")

    def generate_statistics(self):
        """–°–æ–∑–¥–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        stats = {
            'images': {
                'total': len(self.images),
                'local': len([i for i in self.images if i['metadata']['type'] == 'local']),
                'external': len([i for i in self.images if i['metadata']['type'] == 'external']),
                'broken': len(self.broken_images),
                'alt_issues': len(self.alt_text_issues),
                'avg_alt_score': round(sum(i['alt_quality']['score'] for i in self.images) / len(self.images), 1) if self.images else 0
            },
            'tables': {
                'total': len(self.tables),
                'avg_rows': round(sum(t['rows'] for t in self.tables) / len(self.tables), 1) if self.tables else 0,
                'avg_columns': round(sum(t['columns'] for t in self.tables) / len(self.tables), 1) if self.tables else 0
            },
            'code': {
                'total': len(self.code_blocks),
                'languages': dict(Counter(c['language'] for c in self.code_blocks)),
                'avg_lines': round(sum(c['lines'] for c in self.code_blocks) / len(self.code_blocks), 1) if self.code_blocks else 0
            }
        }

        return stats

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç (Markdown)"""
        stats = self.generate_statistics()

        lines = []
        lines.append("# üñºÔ∏è –ò–Ω–¥–µ–∫—Å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π (Advanced)\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("## üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**: {stats['images']['total']} (–ª–æ–∫–∞–ª—å–Ω—ã—Ö: {stats['images']['local']}, –≤–Ω–µ—à–Ω–∏—Ö: {stats['images']['external']})\n")
        lines.append(f"- **–¢–∞–±–ª–∏—Ü**: {stats['tables']['total']}\n")
        lines.append(f"- **–ü—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞**: {stats['code']['total']}\n")
        lines.append(f"- **–ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫**: {stats['images']['broken']}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ alt —Ç–µ–∫—Å—Ç–∞**: {stats['images']['avg_alt_score']}/100\n\n")

        # –ü—Ä–æ–±–ª–µ–º—ã
        if self.broken_images or self.alt_text_issues:
            lines.append("## ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n\n")

            if self.broken_images:
                lines.append(f"### –ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({len(self.broken_images)})\n\n")
                for item in self.broken_images[:10]:
                    lines.append(f"- **{item['article']}**: `{item['path']}`\n")
                if len(self.broken_images) > 10:
                    lines.append(f"\n_...–∏ –µ—â—ë {len(self.broken_images) - 10}_\n")
                lines.append("\n")

            if self.alt_text_issues:
                lines.append(f"### –ü—Ä–æ–±–ª–µ–º—ã —Å alt —Ç–µ–∫—Å—Ç–æ–º ({len(self.alt_text_issues)})\n\n")
                for item in sorted(self.alt_text_issues, key=lambda x: x['score'])[:10]:
                    issues_str = ', '.join(item['issues'])
                    lines.append(f"- **{item['article']}** (–æ—Ü–µ–Ω–∫–∞: {item['score']}/100)\n")
                    lines.append(f"  - Alt: `{item['alt']}`\n")
                    lines.append(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {issues_str}\n")
                if len(self.alt_text_issues) > 10:
                    lines.append(f"\n_...–∏ –µ—â—ë {len(self.alt_text_issues) - 10}_\n")
                lines.append("\n")

        # List of Figures
        lines.append("## üì∑ –°–ø–∏—Å–æ–∫ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π\n\n")

        for img in sorted(self.images, key=lambda x: x['number']):
            lines.append(f"### Figure {img['number']}: {img['alt']}\n\n")

            if img['caption']:
                lines.append(f"_{img['caption']}_\n\n")

            lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{img['article']}]({img['article']})\n")
            lines.append(f"- **–ü—É—Ç—å**: `{img['path']}`\n")

            if img['metadata']['type'] == 'local' and img['metadata']['exists']:
                lines.append(f"- **–†–∞–∑–º–µ—Ä**: {img['metadata']['size_kb']} KB\n")
                lines.append(f"- **–§–æ—Ä–º–∞—Ç**: {img['metadata']['format']}\n")

            lines.append(f"- **Alt –∫–∞—á–µ—Å—Ç–≤–æ**: {img['alt_quality']['score']}/100\n")

            if img['references'] > 0:
                lines.append(f"- **–°—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ**: {img['references']}\n")

            lines.append("\n")

        # List of Tables
        lines.append("\n## üìä –°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü\n\n")

        for table in sorted(self.tables, key=lambda x: x['number']):
            lines.append(f"### Table {table['number']}: {table['title']}\n\n")

            if table['caption']:
                lines.append(f"_{table['caption']}_\n\n")

            lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{table['article']}]({table['article']})\n")
            lines.append(f"- **–†–∞–∑–º–µ—Ä**: {table['size']}\n")

            if table['references'] > 0:
                lines.append(f"- **–°—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ**: {table['references']}\n")

            lines.append("\n")

        # Code examples by language
        lines.append("\n## üíª –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –ø–æ —è–∑—ã–∫–∞–º\n\n")

        by_language = defaultdict(list)
        for code in self.code_blocks:
            by_language[code['language']].append(code)

        for lang in sorted(by_language.keys()):
            codes = by_language[lang]
            lines.append(f"### {lang} ({len(codes)} –ø—Ä–∏–º–µ—Ä–æ–≤)\n\n")

            for code in sorted(codes, key=lambda x: x['number']):
                lines.append(f"#### Listing {code['number']}: {code['title']}\n\n")
                lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{code['article']}]({code['article']})\n")
                lines.append(f"- **–†–∞–∑–º–µ—Ä**: {code['size']}\n\n")

        output_file = self.root_dir / "ADVANCED_FIGURES_INDEX.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –û—Ç—á—ë—Ç: {output_file}")

    def export_json(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON"""
        data = {
            'statistics': self.generate_statistics(),
            'images': self.images,
            'tables': self.tables,
            'code_blocks': self.code_blocks,
            'issues': {
                'broken_images': self.broken_images,
                'alt_text_issues': self.alt_text_issues
            }
        }

        output_file = self.root_dir / "figures_index.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON: {output_file}")


class FigureExtractor:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    –ü–æ–∏—Å–∫ orphaned images, embedded base64
    """

    def __init__(self, indexer):
        self.indexer = indexer
        self.orphaned_images = []
        self.embedded_images = []
        self.referenced_paths = set()

    def find_orphaned_images(self):
        """–ù–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –≤ —Å—Ç–∞—Ç—å—è—Ö"""
        print("üîç –ü–æ–∏—Å–∫ orphaned images...\n")

        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –ø—É—Ç–∏
        for img in self.indexer.images:
            if img['metadata']['type'] == 'local':
                self.referenced_paths.add(img['path'])

        # –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.bmp'}
        images_dir = self.indexer.root_dir / 'knowledge'

        for img_file in images_dir.rglob('*'):
            if img_file.suffix.lower() in image_extensions:
                relative_path = str(img_file.relative_to(self.indexer.root_dir))

                if relative_path not in self.referenced_paths:
                    stat = img_file.stat()
                    self.orphaned_images.append({
                        'path': relative_path,
                        'name': img_file.name,
                        'size_kb': round(stat.st_size / 1024, 2),
                        'format': img_file.suffix.lstrip('.').upper(),
                        'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d')
                    })

        print(f"   –ù–∞–π–¥–µ–Ω–æ orphaned: {len(self.orphaned_images)}\n")

    def extract_embedded_images(self):
        """–ù–∞–π—Ç–∏ embedded base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        print("üîç –ü–æ–∏—Å–∫ embedded (base64) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n")

        pattern = r'!\[([^\]]*)\]\(data:image/([^;]+);base64,([A-Za-z0-9+/=]+)\)'

        for md_file in self.indexer.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                for match in re.finditer(pattern, content):
                    alt_text = match.group(1)
                    format_type = match.group(2)
                    base64_data = match.group(3)

                    size_bytes = len(base64.b64decode(base64_data))

                    self.embedded_images.append({
                        'article': str(md_file.relative_to(self.indexer.root_dir)),
                        'alt': alt_text,
                        'format': format_type.upper(),
                        'size_kb': round(size_bytes / 1024, 2)
                    })
            except:
                pass

        print(f"   –ù–∞–π–¥–µ–Ω–æ embedded: {len(self.embedded_images)}\n")

    def generate_extraction_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        lines = []
        lines.append("# üîç –û—Ç—á—ë—Ç: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n")

        # Orphaned images
        if self.orphaned_images:
            lines.append(f"## üóëÔ∏è Orphaned Images ({len(self.orphaned_images)})\n\n")
            lines.append("> –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏, –Ω–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –≤ —Å—Ç–∞—Ç—å—è—Ö\n\n")

            total_size = sum(img['size_kb'] for img in self.orphaned_images)
            lines.append(f"**–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä**: {total_size:.2f} KB\n\n")

            for img in sorted(self.orphaned_images, key=lambda x: -x['size_kb'])[:20]:
                lines.append(f"- `{img['path']}` ‚Äî {img['format']}, {img['size_kb']} KB\n")

            if len(self.orphaned_images) > 20:
                lines.append(f"\n_...–∏ –µ—â—ë {len(self.orphaned_images) - 20}_\n")
            lines.append("\n")

        # Embedded images
        if self.embedded_images:
            lines.append(f"## üì¶ Embedded Images ({len(self.embedded_images)})\n\n")
            lines.append("> Base64-encoded –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ markdown\n\n")

            for img in self.embedded_images:
                lines.append(f"- **{img['article']}**: {img['format']}, {img['size_kb']} KB\n")
                lines.append(f"  - Alt: `{img['alt']}`\n")

            lines.append("\n")

        return ''.join(lines)


class CaptionAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ keywords, –¥—É–±–ª–∏–∫–∞—Ç—ã
    """

    def __init__(self, indexer):
        self.indexer = indexer
        self.caption_quality = []
        self.duplicate_captions = []
        self.keywords_freq = Counter()

    def analyze_caption_quality(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å–µ–π"""
        print("üìù –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å–µ–π...\n")

        caption_counts = Counter()

        for img in self.indexer.images:
            caption = img.get('caption')

            if not caption:
                score = 0
                issues = ['missing']
            else:
                score = 100
                issues = []

                # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è
                if len(caption) < 10:
                    issues.append('too_short')
                    score -= 40

                # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è
                if len(caption) > 200:
                    issues.append('too_long')
                    score -= 20

                # –¢–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
                words = caption.split()
                if len(words) < 3:
                    issues.append('too_few_words')
                    score -= 30

                # –î—É–±–ª–∏–∫–∞—Ç—ã
                caption_counts[caption] += 1

                # –ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                keywords = [w.lower() for w in words if len(w) > 4]
                self.keywords_freq.update(keywords)

            self.caption_quality.append({
                'image': img['number'],
                'article': img['article'],
                'caption': caption or '–ù–µ—Ç –ø–æ–¥–ø–∏—Å–∏',
                'score': max(0, score),
                'issues': issues
            })

        # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
        for caption, count in caption_counts.items():
            if count > 1:
                images = [
                    img['number'] for img in self.indexer.images
                    if img.get('caption') == caption
                ]
                self.duplicate_captions.append({
                    'caption': caption,
                    'count': count,
                    'images': images
                })

        print(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥–ø–∏—Å–µ–π: {len(self.caption_quality)}\n")

    def get_top_keywords(self, n=20):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø N –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        return self.keywords_freq.most_common(n)

    def generate_captions_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–µ–π"""
        lines = []
        lines.append("# üìù –û—Ç—á—ë—Ç: –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–ø–∏—Å–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_score = sum(c['score'] for c in self.caption_quality) / len(self.caption_quality) if self.caption_quality else 0
        missing_count = len([c for c in self.caption_quality if 'missing' in c['issues']])

        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**: {len(self.caption_quality)}\n")
        lines.append(f"- **–ë–µ–∑ –ø–æ–¥–ø–∏—Å–∏**: {missing_count}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞**: {avg_score:.1f}/100\n")
        lines.append(f"- **–î—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ–¥–ø–∏—Å–µ–π**: {len(self.duplicate_captions)}\n\n")

        # –¢–æ–ø keywords
        top_keywords = self.get_top_keywords(20)
        if top_keywords:
            lines.append("## –¢–æ–ø –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –ø–æ–¥–ø–∏—Å—è—Ö\n\n")
            for word, count in top_keywords:
                lines.append(f"- **{word}**: {count}\n")
            lines.append("\n")

        # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        low_quality = sorted([c for c in self.caption_quality if c['score'] < 50], key=lambda x: x['score'])
        if low_quality:
            lines.append(f"## –ü–æ–¥–ø–∏—Å–∏ –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (—Ç–æ–ø-15)\n\n")
            for cap in low_quality[:15]:
                lines.append(f"### Figure {cap['image']} ‚Äî –û—Ü–µ–Ω–∫–∞: {cap['score']}/100\n\n")
                lines.append(f"- **–°—Ç–∞—Ç—å—è**: {cap['article']}\n")
                lines.append(f"- **–ü–æ–¥–ø–∏—Å—å**: {cap['caption']}\n")
                lines.append(f"- **–ü—Ä–æ–±–ª–µ–º—ã**: {', '.join(cap['issues'])}\n\n")

        # –î—É–±–ª–∏–∫–∞—Ç—ã
        if self.duplicate_captions:
            lines.append("## –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ–¥–ø–∏—Å–µ–π\n\n")
            for dup in self.duplicate_captions:
                lines.append(f"### \"{dup['caption']}\" ({dup['count']} —Ä–∞–∑)\n\n")
                lines.append(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {', '.join(dup['images'])}\n\n")

        return ''.join(lines)


class FigureVisualizer:
    """
    HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥–∞–ª–µ—Ä–µ–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    Dashboard —Å Chart.js
    """

    def __init__(self, indexer, extractor=None, caption_analyzer=None):
        self.indexer = indexer
        self.extractor = extractor
        self.caption_analyzer = caption_analyzer

    def generate_html_gallery(self, output_file='FIGURES_GALLERY.html'):
        """–°–æ–∑–¥–∞—Ç—å HTML –≥–∞–ª–µ—Ä–µ—é"""
        print("üé® –°–æ–∑–¥–∞–Ω–∏–µ HTML –≥–∞–ª–µ—Ä–µ–∏...\n")

        stats = self._prepare_statistics()
        chart_data = self._prepare_chart_data()

        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üñºÔ∏è Figures Gallery</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }}

        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}

        h1 {{
            color: white;
            text-align: center;
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }}

        .subtitle {{
            color: rgba(255,255,255,0.9);
            text-align: center;
            font-size: 1.2em;
            margin-bottom: 40px;
        }}

        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}

        .stat-card {{
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }}

        .stat-label {{
            color: #666;
            font-size: 0.85em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
        }}

        .stat-value {{
            color: #667eea;
            font-size: 2.5em;
            font-weight: bold;
        }}

        .chart-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 30px;
            margin-bottom: 40px;
        }}

        .chart-container {{
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }}

        .chart-title {{
            font-size: 1.3em;
            color: #333;
            margin-bottom: 20px;
            font-weight: 600;
        }}

        canvas {{
            max-height: 350px;
        }}

        .gallery-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 40px;
        }}

        .gallery-item {{
            background: white;
            border-radius: 10px;
            padding: 15px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
            transition: transform 0.2s;
        }}

        .gallery-item:hover {{
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.3);
        }}

        .gallery-item img {{
            width: 100%;
            height: 150px;
            object-fit: cover;
            border-radius: 5px;
            margin-bottom: 10px;
        }}

        .gallery-caption {{
            font-size: 0.85em;
            color: #666;
            line-height: 1.4;
        }}

        .footer {{
            text-align: center;
            color: rgba(255,255,255,0.8);
            margin-top: 40px;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üñºÔ∏è Figures Gallery</h1>
        <p class="subtitle">–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≥–∞–ª–µ—Ä–µ—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π</p>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-label">–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</div>
                <div class="stat-value">{stats['total_images']}</div>
            </div>

            <div class="stat-card">
                <div class="stat-label">–¢–∞–±–ª–∏—Ü—ã</div>
                <div class="stat-value">{stats['total_tables']}</div>
            </div>

            <div class="stat-card">
                <div class="stat-label">–ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞</div>
                <div class="stat-value">{stats['total_code']}</div>
            </div>

            <div class="stat-card">
                <div class="stat-label">–ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏</div>
                <div class="stat-value">{stats['broken_links']}</div>
            </div>

            <div class="stat-card">
                <div class="stat-label">Orphaned</div>
                <div class="stat-value">{stats['orphaned']}</div>
            </div>
        </div>

        <div class="chart-grid">
            <div class="chart-container">
                <div class="chart-title">üìä –§–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</div>
                <canvas id="formatsChart"></canvas>
            </div>

            <div class="chart-container">
                <div class="chart-title">üìà –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤</div>
                <canvas id="sizesChart"></canvas>
            </div>

            <div class="chart-container">
                <div class="chart-title">üíª –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è</div>
                <canvas id="languagesChart"></canvas>
            </div>

            <div class="chart-container">
                <div class="chart-title">üìù –ö–∞—á–µ—Å—Ç–≤–æ Alt-—Ç–µ–∫—Å—Ç–∞</div>
                <canvas id="altQualityChart"></canvas>
            </div>
        </div>

        <div class="footer">
            –°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M')} | Figures Gallery v2.0
        </div>
    </div>

    <script>
        // –§–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        new Chart(document.getElementById('formatsChart'), {{
            type: 'doughnut',
            data: {{
                labels: {chart_data['formats']['labels']},
                datasets: [{{
                    data: {chart_data['formats']['values']},
                    backgroundColor: ['#667eea', '#764ba2', '#f093fb', '#4facfe', '#a8edea']
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                plugins: {{
                    legend: {{ position: 'bottom' }}
                }}
            }}
        }});

        // –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
        new Chart(document.getElementById('sizesChart'), {{
            type: 'bar',
            data: {{
                labels: {chart_data['sizes']['labels']},
                datasets: [{{
                    label: '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤',
                    data: {chart_data['sizes']['values']},
                    backgroundColor: '#667eea'
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                plugins: {{
                    legend: {{ display: false }}
                }},
                scales: {{
                    y: {{ beginAtZero: true }}
                }}
            }}
        }});

        // –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        new Chart(document.getElementById('languagesChart'), {{
            type: 'bar',
            data: {{
                labels: {chart_data['languages']['labels']},
                datasets: [{{
                    label: '–ü—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞',
                    data: {chart_data['languages']['values']},
                    backgroundColor: '#764ba2'
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                plugins: {{
                    legend: {{ display: false }}
                }},
                scales: {{
                    y: {{ beginAtZero: true }}
                }}
            }}
        }});

        // –ö–∞—á–µ—Å—Ç–≤–æ alt-—Ç–µ–∫—Å—Ç–∞
        new Chart(document.getElementById('altQualityChart'), {{
            type: 'bar',
            data: {{
                labels: {chart_data['alt_quality']['labels']},
                datasets: [{{
                    label: '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                    data: {chart_data['alt_quality']['values']},
                    backgroundColor: ['#ef4444', '#f59e0b', '#10b981']
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                plugins: {{
                    legend: {{ display: false }}
                }},
                scales: {{
                    y: {{ beginAtZero: true }}
                }}
            }}
        }});
    </script>
</body>
</html>"""

        output_path = self.indexer.root_dir / output_file
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)

        print(f"‚úÖ HTML Gallery: {output_path}\n")

    def _prepare_statistics(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        stats = {
            'total_images': len(self.indexer.images),
            'total_tables': len(self.indexer.tables),
            'total_code': len(self.indexer.code_blocks),
            'broken_links': len(self.indexer.broken_images),
            'orphaned': 0
        }

        if self.extractor and self.extractor.orphaned_images:
            stats['orphaned'] = len(self.extractor.orphaned_images)

        return stats

    def _prepare_chart_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        chart_data = {
            'formats': self._get_formats_distribution(),
            'sizes': self._get_sizes_distribution(),
            'languages': self._get_languages_distribution(),
            'alt_quality': self._get_alt_quality_distribution()
        }

        return chart_data

    def _get_formats_distribution(self):
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        formats = Counter()

        for img in self.indexer.images:
            if img['metadata']['type'] == 'local' and img['metadata']['exists']:
                fmt = img['metadata'].get('format', 'UNKNOWN')
                formats[fmt] += 1

        labels = list(formats.keys())
        values = list(formats.values())

        return {'labels': labels, 'values': values}

    def _get_sizes_distribution(self):
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤"""
        bins = [0, 50, 100, 500, 1000, float('inf')]
        labels = ['0-50 KB', '50-100 KB', '100-500 KB', '500KB-1MB', '>1MB']
        counts = [0] * (len(bins) - 1)

        for img in self.indexer.images:
            if img['metadata']['type'] == 'local' and img['metadata']['exists']:
                size_kb = img['metadata'].get('size_kb', 0)

                for i in range(len(bins) - 1):
                    if bins[i] <= size_kb < bins[i + 1]:
                        counts[i] += 1
                        break

        return {'labels': labels, 'values': counts}

    def _get_languages_distribution(self):
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"""
        languages = Counter(c['language'] for c in self.indexer.code_blocks)

        labels = list(languages.keys())[:10]
        values = list(languages.values())[:10]

        return {'labels': labels, 'values': values}

    def _get_alt_quality_distribution(self):
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ alt-—Ç–µ–∫—Å—Ç–∞"""
        categories = {'–ü–ª–æ—Ö–æ–µ (0-50)': 0, '–°—Ä–µ–¥–Ω–µ–µ (50-80)': 0, '–•–æ—Ä–æ—à–µ–µ (80-100)': 0}

        for img in self.indexer.images:
            score = img['alt_quality']['score']

            if score < 50:
                categories['–ü–ª–æ—Ö–æ–µ (0-50)'] += 1
            elif score < 80:
                categories['–°—Ä–µ–¥–Ω–µ–µ (50-80)'] += 1
            else:
                categories['–•–æ—Ä–æ—à–µ–µ (80-100)'] += 1

        labels = list(categories.keys())
        values = list(categories.values())

        return {'labels': labels, 'values': values}


class FigureValidator:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫, —Ä–∞–∑–º–µ—Ä–æ–≤, –ø–æ–¥–ø–∏—Å–µ–π
    """

    def __init__(self, indexer):
        self.indexer = indexer
        self.validation_results = []

    def validate_all(self):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n")

        for img in self.indexer.images:
            issues = []
            warnings = []

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
            if img['metadata']['type'] == 'local' and not img['metadata']['exists']:
                issues.append('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ alt —Ç–µ–∫—Å—Ç–∞
            if img['alt_quality']['score'] < 50:
                warnings.append(f"–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ alt-—Ç–µ–∫—Å—Ç–∞ ({img['alt_quality']['score']}/100)")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
            if img['metadata']['type'] == 'local' and img['metadata']['exists']:
                size_kb = img['metadata'].get('size_kb', 0)

                if size_kb > 1000:
                    warnings.append(f'–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({size_kb:.1f} KB)')
                elif size_kb < 5:
                    warnings.append(f'–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π ({size_kb:.1f} KB)')

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ø–∏—Å–∏
            if not img.get('caption'):
                warnings.append('–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–¥–ø–∏—Å—å')

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ references
            if img['references'] == 0:
                warnings.append('–ù–µ—Ç —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ')

            self.validation_results.append({
                'image': img['number'],
                'article': img['article'],
                'path': img['path'],
                'issues': issues,
                'warnings': warnings,
                'status': 'error' if issues else ('warning' if warnings else 'ok')
            })

        errors_count = len([r for r in self.validation_results if r['status'] == 'error'])
        warnings_count = len([r for r in self.validation_results if r['status'] == 'warning'])

        print(f"   –û—à–∏–±–∫–∏: {errors_count}")
        print(f"   –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {warnings_count}\n")

    def generate_validation_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        lines = []
        lines.append("# ‚úÖ –û—Ç—á—ë—Ç: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n")

        errors = [r for r in self.validation_results if r['status'] == 'error']
        warnings = [r for r in self.validation_results if r['status'] == 'warning']
        ok = [r for r in self.validation_results if r['status'] == 'ok']

        lines.append("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–û—à–∏–±–∫–∏**: {len(errors)}\n")
        lines.append(f"- **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è**: {len(warnings)}\n")
        lines.append(f"- **OK**: {len(ok)}\n")
        lines.append(f"- **–í—Å–µ–≥–æ**: {len(self.validation_results)}\n\n")

        # –û—à–∏–±–∫–∏
        if errors:
            lines.append("## ‚ùå –û—à–∏–±–∫–∏\n\n")

            for result in errors:
                lines.append(f"### Figure {result['image']}\n\n")
                lines.append(f"- **–°—Ç–∞—Ç—å—è**: {result['article']}\n")
                lines.append(f"- **–ü—É—Ç—å**: `{result['path']}`\n")
                lines.append("- **–ü—Ä–æ–±–ª–µ–º—ã**:\n")

                for issue in result['issues']:
                    lines.append(f"  - {issue}\n")

                lines.append("\n")

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if warnings:
            lines.append("## ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (—Ç–æ–ø-20)\n\n")

            for result in warnings[:20]:
                lines.append(f"### Figure {result['image']}\n\n")
                lines.append(f"- **–°—Ç–∞—Ç—å—è**: {result['article']}\n")
                lines.append("- **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è**:\n")

                for warning in result['warnings']:
                    lines.append(f"  - {warning}\n")

                lines.append("\n")

        return ''.join(lines)

    def export_to_csv(self, output_file='figures_validation.csv'):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ CSV"""
        csv_path = self.indexer.root_dir / output_file

        with open(csv_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Figure', 'Article', 'Path', 'Status', 'Issues', 'Warnings'])

            for result in self.validation_results:
                writer.writerow([
                    result['image'],
                    result['article'],
                    result['path'],
                    result['status'],
                    '; '.join(result['issues']),
                    '; '.join(result['warnings'])
                ])

        print(f"‚úÖ CSV –≤–∞–ª–∏–¥–∞—Ü–∏—è: {csv_path}\n")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='üñºÔ∏è Advanced Index of Figures v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s                        # –ë–∞–∑–æ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
  %(prog)s --html                 # HTML –≥–∞–ª–µ—Ä–µ—è —Å Chart.js
  %(prog)s --extract              # –ü–æ–∏—Å–∫ orphaned/embedded –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
  %(prog)s --analyze-captions     # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å–µ–π
  %(prog)s --validate             # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
  %(prog)s --csv                  # –≠–∫—Å–ø–æ—Ä—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ CSV
  %(prog)s --all                  # –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ä–∞–∑—É
  %(prog)s --json --html --csv    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç

–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ v2.0:
  - üîç –ü–æ–∏—Å–∫ orphaned –∏ embedded –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
  - üìù –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å–µ–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
  - üé® HTML –≥–∞–ª–µ—Ä–µ—è —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
  - ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫, —Ä–∞–∑–º–µ—Ä–æ–≤, –ø–æ–¥–ø–∏—Å–µ–π
  - üìä 4 –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: —Ñ–æ—Ä–º–∞—Ç—ã, —Ä–∞–∑–º–µ—Ä—ã, —è–∑—ã–∫–∏, –∫–∞—á–µ—Å—Ç–≤–æ
  - üìà CSV —ç–∫—Å–ø–æ—Ä—Ç –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        """
    )

    # –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø—Ü–∏–∏
    parser.add_argument('--json', action='store_true',
                       help='üìÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON')

    # –ù–æ–≤—ã–µ –æ–ø—Ü–∏–∏ v2.0
    parser.add_argument('--html', action='store_true',
                       help='üé® –°–æ–∑–¥–∞—Ç—å HTML –≥–∞–ª–µ—Ä–µ—é —Å Chart.js –≥—Ä–∞—Ñ–∏–∫–∞–º–∏')
    parser.add_argument('--extract', action='store_true',
                       help='üîç –ù–∞–π—Ç–∏ orphaned –∏ embedded –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è')
    parser.add_argument('--analyze-captions', action='store_true',
                       help='üìù –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å–µ–π')
    parser.add_argument('--validate', action='store_true',
                       help='‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Å—Å—ã–ª–∫–∏, —Ä–∞–∑–º–µ—Ä—ã, –ø–æ–¥–ø–∏—Å–∏)')
    parser.add_argument('--csv', action='store_true',
                       help='üìä –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ CSV')

    # –§–∏–ª—å—Ç—Ä—ã
    parser.add_argument('--filter-format', type=str,
                       help='üîé –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Ñ–æ—Ä–º–∞—Ç—É (PNG, JPG, SVG, –∏ —Ç.–¥.)')
    parser.add_argument('--min-size', type=int, default=0,
                       help='üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ KB (default: 0)')

    # –û—Ç—á—ë—Ç—ã
    parser.add_argument('--export-extraction', action='store_true',
                       help='üìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è')
    parser.add_argument('--export-captions', action='store_true',
                       help='üìù –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–µ–π')
    parser.add_argument('--export-validation', action='store_true',
                       help='‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏')

    # –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
    parser.add_argument('--all', action='store_true',
                       help='üî• –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ –æ–ø—Ü–∏–∏ (–ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑)')

    args = parser.parse_args()

    # --all –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –æ–ø—Ü–∏–∏
    if args.all:
        args.html = True
        args.extract = True
        args.analyze_captions = True
        args.validate = True
        args.csv = True
        args.json = True
        args.export_extraction = True
        args.export_captions = True
        args.export_validation = True

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
    indexer = AdvancedFiguresIndexer(root_dir)
    indexer.index_all()
    indexer.generate_report()

    # ========== –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò V2.0 ==========

    # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    extractor = None
    if args.extract or args.html or args.all:
        extractor = FigureExtractor(indexer)
        extractor.find_orphaned_images()
        extractor.extract_embedded_images()

        if args.export_extraction or args.all:
            report = extractor.generate_extraction_report()
            extraction_file = root_dir / 'FIGURES_EXTRACTION.md'
            with open(extraction_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"‚úÖ –û—Ç—á—ë—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {extraction_file}\n")

    # 2. –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–ø–∏—Å–µ–π
    caption_analyzer = None
    if args.analyze_captions or args.html or args.all:
        caption_analyzer = CaptionAnalyzer(indexer)
        caption_analyzer.analyze_caption_quality()

        if args.export_captions or args.all:
            report = caption_analyzer.generate_captions_report()
            captions_file = root_dir / 'CAPTIONS_ANALYSIS.md'
            with open(captions_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"‚úÖ –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–µ–π: {captions_file}\n")

    # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è
    if args.validate or args.all:
        validator = FigureValidator(indexer)
        validator.validate_all()

        if args.export_validation or args.all:
            report = validator.generate_validation_report()
            validation_file = root_dir / 'FIGURES_VALIDATION.md'
            with open(validation_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"‚úÖ –û—Ç—á—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_file}\n")

        # CSV export
        if args.csv or args.all:
            validator.export_to_csv()

    # 4. HTML –≥–∞–ª–µ—Ä–µ—è
    if args.html or args.all:
        visualizer = FigureVisualizer(indexer, extractor, caption_analyzer)
        visualizer.generate_html_gallery()

    # JSON export
    if args.json or args.all:
        indexer.export_json()

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*60)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*60)
    print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(indexer.images)}")
    print(f"–¢–∞–±–ª–∏—Ü: {len(indexer.tables)}")
    print(f"–ü—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞: {len(indexer.code_blocks)}")
    print(f"–ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫: {len(indexer.broken_images)}")
    print(f"–ü—Ä–æ–±–ª–µ–º —Å alt: {len(indexer.alt_text_issues)}")

    if extractor:
        print(f"Orphaned –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(extractor.orphaned_images)}")
        print(f"Embedded –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(extractor.embedded_images)}")

    print("="*60 + "\n")


if __name__ == "__main__":
    main()
