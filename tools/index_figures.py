#!/usr/bin/env python3
"""
Advanced Index of Figures - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–Ω–¥–µ–∫—Å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π
–§—É–Ω–∫—Ü–∏–∏:
- Image metadata (—Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞—Ç, dimensions)
- Alt text quality check (–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å)
- Broken image detection (–ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è)
- Auto-numbering (Figure 1.1, Table 2.3 - LaTeX style)
- Cross-reference tracking (—Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–∫–∏)
- Figure captions extraction
- Table of Figures (–∫–∞–∫ –≤ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç—å—è—Ö)
- Code syntax statistics (—è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è)
- Usage statistics (–ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å)
- Optimization suggestions
- JSON/CSV export

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: LaTeX List of Figures, Sphinx, Markdown Preview Enhanced
"""

from pathlib import Path
import re
import json
from collections import defaultdict, Counter
import yaml
import os


class AdvancedFiguresIndexer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –î–∞–Ω–Ω—ã–µ
        self.images = []
        self.tables = []
        self.code_blocks = []

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.broken_images = []
        self.alt_text_issues = []
        self.cross_references = defaultdict(list)

        # –°—á—ë—Ç—á–∏–∫–∏ –¥–ª—è –∞–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏–∏
        self.counters = defaultdict(lambda: defaultdict(int))

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def get_image_metadata(self, image_path, article_dir):
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç —Å—Ç–∞—Ç—å–∏
        if image_path.startswith('http://') or image_path.startswith('https://'):
            return {
                'type': 'external',
                'url': image_path,
                'exists': None,
                'size': None,
                'format': None
            }

        # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        if image_path.startswith('/'):
            full_path = self.root_dir / image_path.lstrip('/')
        else:
            full_path = article_dir / image_path

        metadata = {
            'type': 'local',
            'path': str(full_path.relative_to(self.root_dir)) if full_path.exists() else image_path,
            'exists': full_path.exists(),
            'size': None,
            'format': None
        }

        if full_path.exists():
            try:
                stat = full_path.stat()
                metadata['size'] = stat.st_size
                metadata['size_kb'] = round(stat.st_size / 1024, 2)
                metadata['format'] = full_path.suffix.lstrip('.').upper()
            except:
                pass

        return metadata

    def check_alt_text_quality(self, alt_text):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ alt —Ç–µ–∫—Å—Ç–∞"""
        issues = []

        if not alt_text or alt_text.strip() == '':
            issues.append('missing')
            return issues, 0

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-100)
        score = 100

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        if len(alt_text) < 5:
            issues.append('too_short')
            score -= 40

        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        if len(alt_text) > 150:
            issues.append('too_long')
            score -= 20

        # –ü–ª–æ—Ö–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
        bad_phrases = ['image', 'picture', 'photo', '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', '–∫–∞—Ä—Ç–∏–Ω–∫–∞', '—Ñ–æ—Ç–æ']
        if any(phrase in alt_text.lower() for phrase in bad_phrases):
            issues.append('redundant_description')
            score -= 15

        # –¢–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞
        if re.match(r'^[\w\-]+\.(jpg|png|gif|svg)$', alt_text.lower()):
            issues.append('filename_only')
            score -= 30

        return issues, max(0, score)

    def extract_figure_caption(self, content, position):
        """–ò–∑–≤–ª–µ—á—å –ø–æ–¥–ø–∏—Å—å –∫ —Ä–∏—Å—É–Ω–∫—É"""
        # –ò—â–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        after_image = content[position:position+200]

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–¥–ø–∏—Å–µ–π
        patterns = [
            r'\n\*([^\*]+)\*',  # *Caption text*
            r'\n_([^_]+)_',      # _Caption text_
            r'\n> ([^\n]+)',     # > Caption text
            r'\n<em>([^<]+)</em>',  # <em>Caption text</em>
        ]

        for pattern in patterns:
            match = re.search(pattern, after_image)
            if match:
                return match.group(1).strip()

        return None

    def auto_number_figure(self, article_path, figure_type):
        """–ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è (LaTeX style)"""
        # –ò–∑–≤–ª–µ—á—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –ø—É—Ç–∏
        parts = Path(article_path).parts
        category = parts[1] if len(parts) > 1 else 'general'

        # –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫
        self.counters[category][figure_type] += 1

        # –§–æ—Ä–º–∞—Ç: Figure 1.1 (–∫–∞—Ç–µ–≥–æ—Ä–∏—è.–Ω–æ–º–µ—Ä)
        category_num = hash(category) % 10 + 1  # –£–ø—Ä–æ—â—ë–Ω–Ω–æ
        figure_num = self.counters[category][figure_type]

        return f"{category_num}.{figure_num}"

    def find_cross_references(self, content, figure_number):
        """–ù–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ"""
        references = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Å—ã–ª–æ–∫
        patterns = [
            rf'—Ä–∏—Å(?:—É–Ω–æ–∫|\.)?\s*{re.escape(figure_number)}',
            rf'fig(?:ure|\.)?\s*{re.escape(figure_number)}',
            rf'\[{re.escape(figure_number)}\]',
        ]

        for pattern in patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            references.extend([m.start() for m in matches])

        return len(references)

    def index_images(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        article_path = str(file_path.relative_to(self.root_dir))
        article_dir = file_path.parent

        # –ü–∞—Ç—Ç–µ—Ä–Ω: ![alt](path "title")
        pattern = r'!\[([^\]]*)\]\(([^)]+?)(?:\s+"([^"]+)")?\)'

        for match in re.finditer(pattern, content):
            alt_text = match.group(1)
            image_path = match.group(2)
            title = match.group(3)

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            metadata = self.get_image_metadata(image_path, article_dir)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ alt —Ç–µ–∫—Å—Ç–∞
            alt_issues, alt_score = self.check_alt_text_quality(alt_text)

            # –ü–æ–¥–ø–∏—Å—å
            caption = self.extract_figure_caption(content, match.end())

            # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
            figure_number = self.auto_number_figure(article_path, 'figure')

            # –°—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫
            references_count = self.find_cross_references(content, figure_number)

            image_data = {
                'number': figure_number,
                'alt': alt_text or '–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è',
                'title': title,
                'caption': caption,
                'path': image_path,
                'article': article_path,
                'metadata': metadata,
                'alt_quality': {
                    'score': alt_score,
                    'issues': alt_issues
                },
                'references': references_count
            }

            self.images.append(image_data)

            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
            if not metadata['exists'] and metadata['type'] == 'local':
                self.broken_images.append({
                    'article': article_path,
                    'path': image_path
                })

            if alt_issues:
                self.alt_text_issues.append({
                    'article': article_path,
                    'alt': alt_text,
                    'issues': alt_issues,
                    'score': alt_score
                })

    def index_tables(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã"""
        article_path = str(file_path.relative_to(self.root_dir))

        lines = content.split('\n')
        in_table = False
        table_start_line = 0
        table_lines = []

        for i, line in enumerate(lines):
            if '|' in line and line.strip().startswith('|'):
                if not in_table:
                    # –ù–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã
                    in_table = True
                    table_start_line = i
                    table_lines = [line]
                else:
                    table_lines.append(line)
            elif in_table and '|' not in line:
                # –ö–æ–Ω–µ—Ü —Ç–∞–±–ª–∏—Ü—ã
                in_table = False

                # –ù–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
                context_lines = lines[max(0, table_start_line - 5):table_start_line]
                table_title = "–¢–∞–±–ª–∏—Ü–∞"
                caption = None

                for ctx_line in reversed(context_lines):
                    if ctx_line.strip().startswith('#'):
                        table_title = ctx_line.strip('#').strip()
                        break
                    elif ctx_line.strip() and not ctx_line.startswith('|'):
                        caption = ctx_line.strip()

                # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
                rows = len([l for l in table_lines if l.strip().startswith('|')])

                # –ö–æ–ª–æ–Ω–∫–∏ (–∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏)
                first_row = table_lines[0] if table_lines else ''
                columns = len([c for c in first_row.split('|') if c.strip()])

                # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
                table_number = self.auto_number_figure(article_path, 'table')

                # –°—Å—ã–ª–∫–∏ –Ω–∞ —Ç–∞–±–ª–∏—Ü—É
                references_count = self.find_cross_references(content, table_number)

                self.tables.append({
                    'number': table_number,
                    'title': table_title,
                    'caption': caption,
                    'article': article_path,
                    'rows': rows,
                    'columns': columns,
                    'size': f"{rows}√ó{columns}",
                    'references': references_count
                })

    def index_code_blocks(self, file_path, content):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –±–ª–æ–∫–∏ –∫–æ–¥–∞"""
        article_path = str(file_path.relative_to(self.root_dir))

        # –ü–∞—Ç—Ç–µ—Ä–Ω: ```language\ncode\n```
        pattern = r'```(\w+)?\n(.*?)```'

        for match in re.finditer(pattern, content, re.DOTALL):
            language = match.group(1) or 'text'
            code = match.group(2)

            # –ù–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫/–æ–ø–∏—Å–∞–Ω–∏–µ
            code_start = match.start()
            context = content[max(0, code_start - 200):code_start]
            context_lines = context.split('\n')

            code_title = "–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞"
            for ctx_line in reversed(context_lines[-5:]):
                if ctx_line.strip() and not ctx_line.startswith('```'):
                    code_title = ctx_line.strip('#').strip()[:100]
                    break

            # –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
            lines = code.split('\n')
            lines_count = len(lines)
            chars_count = len(code)

            # –ê–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è
            listing_number = self.auto_number_figure(article_path, 'listing')

            self.code_blocks.append({
                'number': listing_number,
                'language': language,
                'title': code_title,
                'article': article_path,
                'lines': lines_count,
                'chars': chars_count,
                'size': f"{lines_count} lines"
            })

    def index_file(self, file_path):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        frontmatter, content = self.extract_frontmatter_and_content(file_path)

        if not content:
            return

        self.index_images(file_path, content)
        self.index_tables(file_path, content)
        self.index_code_blocks(file_path, content)

    def index_all(self):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã"""
        print("üñºÔ∏è  –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            self.index_file(md_file)

        print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(self.images)}")
        print(f"   –¢–∞–±–ª–∏—Ü: {len(self.tables)}")
        print(f"   –ë–ª–æ–∫–æ–≤ –∫–æ–¥–∞: {len(self.code_blocks)}")
        print(f"   –ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫: {len(self.broken_images)}")
        print(f"   –ü—Ä–æ–±–ª–µ–º —Å alt: {len(self.alt_text_issues)}\n")

    def generate_statistics(self):
        """–°–æ–∑–¥–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        stats = {
            'images': {
                'total': len(self.images),
                'local': len([i for i in self.images if i['metadata']['type'] == 'local']),
                'external': len([i for i in self.images if i['metadata']['type'] == 'external']),
                'broken': len(self.broken_images),
                'alt_issues': len(self.alt_text_issues),
                'avg_alt_score': round(sum(i['alt_quality']['score'] for i in self.images) / len(self.images), 1) if self.images else 0
            },
            'tables': {
                'total': len(self.tables),
                'avg_rows': round(sum(t['rows'] for t in self.tables) / len(self.tables), 1) if self.tables else 0,
                'avg_columns': round(sum(t['columns'] for t in self.tables) / len(self.tables), 1) if self.tables else 0
            },
            'code': {
                'total': len(self.code_blocks),
                'languages': dict(Counter(c['language'] for c in self.code_blocks)),
                'avg_lines': round(sum(c['lines'] for c in self.code_blocks) / len(self.code_blocks), 1) if self.code_blocks else 0
            }
        }

        return stats

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç (Markdown)"""
        stats = self.generate_statistics()

        lines = []
        lines.append("# üñºÔ∏è –ò–Ω–¥–µ–∫—Å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π (Advanced)\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("## üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**: {stats['images']['total']} (–ª–æ–∫–∞–ª—å–Ω—ã—Ö: {stats['images']['local']}, –≤–Ω–µ—à–Ω–∏—Ö: {stats['images']['external']})\n")
        lines.append(f"- **–¢–∞–±–ª–∏—Ü**: {stats['tables']['total']}\n")
        lines.append(f"- **–ü—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞**: {stats['code']['total']}\n")
        lines.append(f"- **–ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫**: {stats['images']['broken']}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ alt —Ç–µ–∫—Å—Ç–∞**: {stats['images']['avg_alt_score']}/100\n\n")

        # –ü—Ä–æ–±–ª–µ–º—ã
        if self.broken_images or self.alt_text_issues:
            lines.append("## ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n\n")

            if self.broken_images:
                lines.append(f"### –ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({len(self.broken_images)})\n\n")
                for item in self.broken_images[:10]:
                    lines.append(f"- **{item['article']}**: `{item['path']}`\n")
                if len(self.broken_images) > 10:
                    lines.append(f"\n_...–∏ –µ—â—ë {len(self.broken_images) - 10}_\n")
                lines.append("\n")

            if self.alt_text_issues:
                lines.append(f"### –ü—Ä–æ–±–ª–µ–º—ã —Å alt —Ç–µ–∫—Å—Ç–æ–º ({len(self.alt_text_issues)})\n\n")
                for item in sorted(self.alt_text_issues, key=lambda x: x['score'])[:10]:
                    issues_str = ', '.join(item['issues'])
                    lines.append(f"- **{item['article']}** (–æ—Ü–µ–Ω–∫–∞: {item['score']}/100)\n")
                    lines.append(f"  - Alt: `{item['alt']}`\n")
                    lines.append(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {issues_str}\n")
                if len(self.alt_text_issues) > 10:
                    lines.append(f"\n_...–∏ –µ—â—ë {len(self.alt_text_issues) - 10}_\n")
                lines.append("\n")

        # List of Figures
        lines.append("## üì∑ –°–ø–∏—Å–æ–∫ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π\n\n")

        for img in sorted(self.images, key=lambda x: x['number']):
            lines.append(f"### Figure {img['number']}: {img['alt']}\n\n")

            if img['caption']:
                lines.append(f"_{img['caption']}_\n\n")

            lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{img['article']}]({img['article']})\n")
            lines.append(f"- **–ü—É—Ç—å**: `{img['path']}`\n")

            if img['metadata']['type'] == 'local' and img['metadata']['exists']:
                lines.append(f"- **–†–∞–∑–º–µ—Ä**: {img['metadata']['size_kb']} KB\n")
                lines.append(f"- **–§–æ—Ä–º–∞—Ç**: {img['metadata']['format']}\n")

            lines.append(f"- **Alt –∫–∞—á–µ—Å—Ç–≤–æ**: {img['alt_quality']['score']}/100\n")

            if img['references'] > 0:
                lines.append(f"- **–°—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ**: {img['references']}\n")

            lines.append("\n")

        # List of Tables
        lines.append("\n## üìä –°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü\n\n")

        for table in sorted(self.tables, key=lambda x: x['number']):
            lines.append(f"### Table {table['number']}: {table['title']}\n\n")

            if table['caption']:
                lines.append(f"_{table['caption']}_\n\n")

            lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{table['article']}]({table['article']})\n")
            lines.append(f"- **–†–∞–∑–º–µ—Ä**: {table['size']}\n")

            if table['references'] > 0:
                lines.append(f"- **–°—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ**: {table['references']}\n")

            lines.append("\n")

        # Code examples by language
        lines.append("\n## üíª –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –ø–æ —è–∑—ã–∫–∞–º\n\n")

        by_language = defaultdict(list)
        for code in self.code_blocks:
            by_language[code['language']].append(code)

        for lang in sorted(by_language.keys()):
            codes = by_language[lang]
            lines.append(f"### {lang} ({len(codes)} –ø—Ä–∏–º–µ—Ä–æ–≤)\n\n")

            for code in sorted(codes, key=lambda x: x['number']):
                lines.append(f"#### Listing {code['number']}: {code['title']}\n\n")
                lines.append(f"- **–°—Ç–∞—Ç—å—è**: [{code['article']}]({code['article']})\n")
                lines.append(f"- **–†–∞–∑–º–µ—Ä**: {code['size']}\n\n")

        output_file = self.root_dir / "ADVANCED_FIGURES_INDEX.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –û—Ç—á—ë—Ç: {output_file}")

    def export_json(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON"""
        data = {
            'statistics': self.generate_statistics(),
            'images': self.images,
            'tables': self.tables,
            'code_blocks': self.code_blocks,
            'issues': {
                'broken_images': self.broken_images,
                'alt_text_issues': self.alt_text_issues
            }
        }

        output_file = self.root_dir / "figures_index.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Advanced Index of Figures')
    parser.add_argument('--json', action='store_true', help='–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON')

    args = parser.parse_args()

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    indexer = AdvancedFiguresIndexer(root_dir)
    indexer.index_all()
    indexer.generate_report()

    if args.json:
        indexer.export_json()


if __name__ == "__main__":
    main()
