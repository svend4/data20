#!/usr/bin/env python3
"""
Glossary Builder - –ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –≥–ª–æ—Å—Å–∞—Ä–∏—è
–°–æ–∑–¥–∞—ë—Ç —Å–ª–æ–≤–∞—Ä—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç:
- –¢–µ—Ä–º–∏–Ω—ã –≤ –∂–∏—Ä–Ω–æ–º —à—Ä–∏—Ñ—Ç–µ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏
- –¢–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–µ–∑–∞—É—Ä—É—Å–∞
- –ê–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
"""

from pathlib import Path
import re
import json


class GlossaryBuilder:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –≥–ª–æ—Å—Å–∞—Ä–∏—è"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"
        self.glossary = {}

    def extract_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n.*?\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return match.group(1)
        except:
            pass
        return None

    def extract_definitions(self, content):
        """–ò–∑–≤–ª–µ—á—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        definitions = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω: **–¢–µ—Ä–º–∏–Ω** ‚Äî –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        pattern1 = r'\*\*([^*]+)\*\*\s*[-‚Äî‚Äì]\s*([^.\n]+[.])'
        for match in re.finditer(pattern1, content):
            term = match.group(1).strip()
            definition = match.group(2).strip()
            definitions.append((term, definition))

        # –ü–∞—Ç—Ç–µ—Ä–Ω: **–¢–µ—Ä–º–∏–Ω**: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        pattern2 = r'\*\*([^*]+)\*\*:\s*([^.\n]+[.])'
        for match in re.finditer(pattern2, content):
            term = match.group(1).strip()
            definition = match.group(2).strip()
            if (term, definition) not in definitions:
                definitions.append((term, definition))

        return definitions

    def extract_abbreviations(self, content):
        """–ò–∑–≤–ª–µ—á—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã"""
        abbrevs = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω: ABBR (Full Name)
        pattern = r'\b([A-Z–ê-–Ø]{2,})\s*\(([^)]+)\)'
        for match in re.finditer(pattern, content):
            abbr = match.group(1).strip()
            full = match.group(2).strip()
            abbrevs.append((abbr, full))

        return abbrevs

    def build(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π"""
        print("üìñ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            content = self.extract_content(md_file)
            if not content:
                continue

            article_file = str(md_file.relative_to(self.root_dir))

            # –ò–∑–≤–ª–µ—á—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            definitions = self.extract_definitions(content)
            for term, definition in definitions:
                if term not in self.glossary:
                    self.glossary[term] = {
                        'definition': definition,
                        'articles': []
                    }
                if article_file not in self.glossary[term]['articles']:
                    self.glossary[term]['articles'].append(article_file)

            # –ò–∑–≤–ª–µ—á—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
            abbrevs = self.extract_abbreviations(content)
            for abbr, full in abbrevs:
                if abbr not in self.glossary:
                    self.glossary[abbr] = {
                        'definition': f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –æ—Ç: {full}",
                        'articles': []
                    }
                if article_file not in self.glossary[abbr]['articles']:
                    self.glossary[abbr]['articles'].append(article_file)

        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(self.glossary)}")

    def save_markdown(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π –≤ markdown"""
        lines = []
        lines.append("# üìñ –ì–ª–æ—Å—Å–∞—Ä–∏–π\n\n")
        lines.append("> –°–ª–æ–≤–∞—Ä—å —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä\n\n")

        lines.append(f"**–í—Å–µ–≥–æ —Ç–µ—Ä–º–∏–Ω–æ–≤**: {len(self.glossary)}\n\n")

        # –ê–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        current_letter = None

        for term in sorted(self.glossary.keys(), key=lambda x: x.lower()):
            data = self.glossary[term]

            # –ù–æ–≤–∞—è –±—É–∫–≤–∞
            first_letter = term[0].upper()
            if first_letter != current_letter:
                current_letter = first_letter
                lines.append(f"\n## {current_letter}\n\n")

            # –¢–µ—Ä–º–∏–Ω
            lines.append(f"### {term}\n\n")
            lines.append(f"{data['definition']}\n\n")

            # –°—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏
            if data['articles']:
                lines.append("**–í—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤:**\n")
                for article in data['articles'][:3]:
                    lines.append(f"- [{article}]({article})\n")
                if len(data['articles']) > 3:
                    lines.append(f"\n...–∏ –µ—â—ë {len(data['articles']) - 3}\n")
                lines.append("\n")

        output_file = self.root_dir / "GLOSSARY.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π: {output_file}")


def main():
    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    builder = GlossaryBuilder(root_dir)
    builder.build()
    builder.save_markdown()


if __name__ == "__main__":
    main()
