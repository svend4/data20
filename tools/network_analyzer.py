#!/usr/bin/env python3
"""
Network Analyzer - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ—Ç–∏
–í—ã—á–∏—Å–ª—è–µ—Ç —à–∏—Ä–æ–∫–∏–π —Å–ø–µ–∫—Ç—Ä —Å–µ—Ç–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫:
- Centrality (degree, betweenness, closeness, eigenvector, PageRank)
- Clustering coefficient
- Community detection
- Graph properties (density, diameter, components)
- Path analysis

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: NetworkX, Gephi, igraph, Neo4j
"""

from pathlib import Path
import yaml
import re
from collections import defaultdict, deque
import json
import math


class CentralityAnalyzer:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏"""

    def __init__(self, graph, undirected_graph, articles):
        self.graph = graph
        self.undirected_graph = undirected_graph
        self.articles = articles

    def calculate_eigenvector_centrality(self, max_iterations=100, tolerance=1e-6):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å eigenvector centrality

        Eigenvector centrality - –º–µ—Ä–∞ –≤–ª–∏—è–Ω–∏—è —É–∑–ª–∞ –≤ —Å–µ—Ç–∏.
        –£–∑–µ–ª –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫–∏–π eigenvector centrality, –µ—Å–ª–∏ —Å–≤—è–∑–∞–Ω —Å —É–∑–ª–∞–º–∏,
        –∫–æ—Ç–æ—Ä—ã–µ —Å–∞–º–∏ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π eigenvector centrality.

        Returns:
            dict: {article: eigenvector_score}
        """
        n = len(self.articles)
        centrality = {article: 1.0 / n for article in self.articles}

        for iteration in range(max_iterations):
            new_centrality = {}
            max_diff = 0

            for article in self.articles:
                # –°—É–º–º–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Å–µ–¥–µ–π (–≤—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏)
                score = 0.0
                for source in self.articles:
                    if article in self.graph[source]:
                        score += centrality[source]

                new_centrality[article] = score
                max_diff = max(max_diff, abs(new_centrality[article] - centrality[article]))

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (L2 norm)
            total = math.sqrt(sum(v * v for v in new_centrality.values()))
            if total > 0:
                new_centrality = {k: v / total for k, v in new_centrality.items()}

            centrality = new_centrality

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if max_diff < tolerance:
                break

        return centrality

    def calculate_katz_centrality(self, alpha=0.1, beta=1.0, max_iterations=100):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å Katz centrality

        Katz centrality —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –ø—É—Ç–∏ –≤ –≥—Ä–∞—Ñ–µ, –≤–∑–≤–µ—à–∏–≤–∞—è –∏—Ö –ø–æ –¥–ª–∏–Ω–µ.
        –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—É—Ç–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å, —á–µ–º –¥–ª–∏–Ω–Ω—ã–µ.

        Formula: C_katz(i) = Œ£_k Œ£_j Œ±^k A^k_ji Œ≤
        –≥–¥–µ Œ± - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è, Œ≤ - –±–∞–∑–æ–≤–∞—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å

        Args:
            alpha: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å < 1/Œª_max)
            beta: –±–∞–∑–æ–≤–∞—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞
            max_iterations: –º–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π

        Returns:
            dict: {article: katz_score}
        """
        centrality = {article: beta for article in self.articles}

        for iteration in range(max_iterations):
            new_centrality = {}

            for article in self.articles:
                # –ë–∞–∑–æ–≤–∞—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å + –≤–∫–ª–∞–¥ –æ—Ç —Å–æ—Å–µ–¥–µ–π
                score = beta

                for source in self.articles:
                    if article in self.graph[source]:
                        score += alpha * centrality[source]

                new_centrality[article] = score

            centrality = new_centrality

        return centrality

    def calculate_harmonic_centrality(self):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å harmonic centrality

        Harmonic centrality - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ closeness centrality,
        –∫–æ—Ç–æ—Ä–∞—è –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤.

        Formula: H(i) = Œ£_{j‚â†i} 1/d(i,j)
        –≥–¥–µ d(i,j) - —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É i –∏ j

        Returns:
            dict: {article: harmonic_score}
        """
        harmonic = {}

        for article in self.articles:
            # BFS –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
            distances = {article: 0}
            queue = deque([article])

            while queue:
                node = queue.popleft()

                for neighbor in self.undirected_graph[node]:
                    if neighbor not in distances:
                        distances[neighbor] = distances[node] + 1
                        queue.append(neighbor)

            # Harmonic centrality = —Å—É–º–º–∞ 1/—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
            score = sum(1.0 / d for d in distances.values() if d > 0)
            harmonic[article] = score

        return harmonic

    def compare_centrality_measures(self, pagerank, betweenness, closeness):
        """
        –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏

        Args:
            pagerank: dict —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ PageRank
            betweenness: dict —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ betweenness centrality
            closeness: dict —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ closeness centrality

        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ —Ä–∞–∑–ª–∏—á–∏–π
        """
        eigenvector = self.calculate_eigenvector_centrality()
        katz = self.calculate_katz_centrality()
        harmonic = self.calculate_harmonic_centrality()

        # –ù–∞–π—Ç–∏ —Ç–æ–ø-10 –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ä—ã
        measures = {
            'PageRank': pagerank,
            'Betweenness': betweenness,
            'Closeness': closeness,
            'Eigenvector': eigenvector,
            'Katz': katz,
            'Harmonic': harmonic
        }

        top_10 = {}
        for name, scores in measures.items():
            sorted_scores = sorted(scores.items(), key=lambda x: -x[1])
            top_10[name] = {article for article, _ in sorted_scores[:10]}

        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Ç–æ–ø-10
        overlaps = {}
        measure_names = list(measures.keys())

        for i, name1 in enumerate(measure_names):
            for name2 in measure_names[i+1:]:
                overlap = len(top_10[name1] & top_10[name2])
                overlaps[f"{name1} ‚à© {name2}"] = overlap

        return {
            'measures': measures,
            'top_10': top_10,
            'overlaps': overlaps
        }


class CommunityDetector:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤"""

    def __init__(self, graph, undirected_graph, articles):
        self.graph = graph
        self.undirected_graph = undirected_graph
        self.articles = articles

    def calculate_modularity(self, communities):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å modularity –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞

        Modularity Q ‚àà [-1, 1] –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è.
        Q > 0.3 —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º.

        Formula: Q = 1/(2m) Œ£_ij [A_ij - k_i*k_j/(2m)] Œ¥(c_i, c_j)
        –≥–¥–µ m - —á–∏—Å–ª–æ —Ä—ë–±–µ—Ä, k_i - —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ i, c_i - —Å–æ–æ–±—â–µ—Å—Ç–≤–æ —É–∑–ª–∞ i

        Args:
            communities: list of sets (–∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤)

        Returns:
            float: modularity score
        """
        # –°–æ–∑–¥–∞—Ç—å mapping: —É–∑–µ–ª -> —Å–æ–æ–±—â–µ—Å—Ç–≤–æ
        node_to_community = {}
        for comm_id, community in enumerate(communities):
            for node in community:
                node_to_community[node] = comm_id

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—ë–±–µ—Ä (–Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ)
        m = sum(len(neighbors) for neighbors in self.undirected_graph.values()) / 2

        if m == 0:
            return 0.0

        modularity = 0.0

        for node_i in self.articles:
            for node_j in self.articles:
                # A_ij - –µ—Å—Ç—å –ª–∏ —Ä–µ–±—Ä–æ –º–µ–∂–¥—É i –∏ j
                A_ij = 1 if node_j in self.undirected_graph[node_i] else 0

                # –°—Ç–µ–ø–µ–Ω–∏ —É–∑–ª–æ–≤
                k_i = len(self.undirected_graph[node_i])
                k_j = len(self.undirected_graph[node_j])

                # Œ¥(c_i, c_j) - –≤ –æ–¥–Ω–æ–º –ª–∏ —Å–æ–æ–±—â–µ—Å—Ç–≤–µ
                same_community = 1 if node_to_community[node_i] == node_to_community[node_j] else 0

                modularity += (A_ij - (k_i * k_j) / (2 * m)) * same_community

        return modularity / (2 * m)

    def louvain_method(self, max_iterations=100):
        """
        –ú–µ—Ç–æ–¥ Louvain –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ—Å—Ç–≤

        –ñ–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ modularity.
        –†–∞–±–æ—Ç–∞–µ—Ç –≤ –¥–≤–∞ —ç—Ç–∞–ø–∞:
        1. –õ–æ–∫–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∫–∞–∂–¥—ã–π —É–∑–µ–ª –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ,
           –∫–æ—Ç–æ—Ä–æ–µ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç modularity
        2. –ê–≥—Ä–µ–≥–∞—Ü–∏—è: —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ —Å—É–ø–µ—Ä-—É–∑–ª—ã

        Returns:
            list of sets: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –∫–∞–∂–¥—ã–π —É–∑–µ–ª - —Å–≤–æ—ë —Å–æ–æ–±—â–µ—Å—Ç–≤–æ
        communities = {article: {article} for article in self.articles}
        node_to_community = {article: article for article in self.articles}

        improved = True
        iteration = 0

        while improved and iteration < max_iterations:
            improved = False
            iteration += 1

            for node in self.articles:
                current_comm = node_to_community[node]
                best_comm = current_comm
                best_delta = 0.0

                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —É–∑–µ–ª –≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å–µ–¥–∞
                neighbor_communities = set()
                for neighbor in self.undirected_graph[node]:
                    neighbor_communities.add(node_to_community[neighbor])

                for test_comm in neighbor_communities:
                    if test_comm == current_comm:
                        continue

                    # –í—ã—á–∏—Å–ª–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ modularity
                    delta = self._calculate_modularity_delta(
                        node, current_comm, test_comm, communities, node_to_community
                    )

                    if delta > best_delta:
                        best_delta = delta
                        best_comm = test_comm

                # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —É–∑–µ–ª –≤ –ª—É—á—à–µ–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ
                if best_comm != current_comm:
                    communities[current_comm].remove(node)
                    communities[best_comm].add(node)
                    node_to_community[node] = best_comm
                    improved = True

        # –í–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
        final_communities = [comm for comm in communities.values() if comm]

        # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞)
        unique_communities = []
        seen = set()

        for comm in final_communities:
            comm_tuple = tuple(sorted(comm))
            if comm_tuple not in seen:
                seen.add(comm_tuple)
                unique_communities.append(comm)

        return unique_communities

    def _calculate_modularity_delta(self, node, from_comm, to_comm, communities, node_to_community):
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ modularity –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–∏ —É–∑–ª–∞"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤—è–∑–µ–π
        links_to_from = sum(1 for n in communities[from_comm] if n in self.undirected_graph[node])
        links_to_to = sum(1 for n in communities[to_comm] if n in self.undirected_graph[node])

        return links_to_to - links_to_from

    def label_propagation(self, max_iterations=100):
        """
        Label Propagation Algorithm –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ—Å—Ç–≤

        –ü—Ä–æ—Å—Ç–æ–π –∏ –±—ã—Å—Ç—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º:
        1. –ö–∞–∂–¥–æ–º—É —É–∑–ª—É –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω–∞—è –º–µ—Ç–∫–∞
        2. –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ: –∫–∞–∂–¥—ã–π —É–∑–µ–ª –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –º–µ—Ç–∫—É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π
        3. –°—Ö–æ–¥–∏—Ç—Å—è, –∫–æ–≥–¥–∞ –º–µ—Ç–∫–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—Ç—Å—è

        Returns:
            list of sets: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –∫–∞–∂–¥—ã–π —É–∑–µ–ª - —Å–≤–æ—è –º–µ—Ç–∫–∞
        labels = {article: i for i, article in enumerate(self.articles)}

        for iteration in range(max_iterations):
            changed = False

            # –ü–µ—Ä–µ–º–µ—à–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–∑–ª–æ–≤ (–≤–∞–∂–Ω–æ –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
            nodes_list = list(self.articles)

            for node in nodes_list:
                # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç–∫–∏ —Å–æ—Å–µ–¥–µ–π
                neighbor_labels = defaultdict(int)

                for neighbor in self.undirected_graph[node]:
                    neighbor_labels[labels[neighbor]] += 1

                if not neighbor_labels:
                    continue

                # –í—ã–±—Ä–∞—Ç—å —Å–∞–º—É—é —á–∞—Å—Ç—É—é –º–µ—Ç–∫—É
                most_common_label = max(neighbor_labels.items(), key=lambda x: x[1])[0]

                if labels[node] != most_common_label:
                    labels[node] = most_common_label
                    changed = True

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if not changed:
                break

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏ –≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
        communities_dict = defaultdict(set)
        for node, label in labels.items():
            communities_dict[label].add(node)

        return list(communities_dict.values())

    def analyze_communities(self, communities, article_titles):
        """
        –ê–Ω–∞–ª–∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤

        Args:
            communities: list of sets
            article_titles: dict {article: title}

        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤
        """
        analysis = {
            'num_communities': len(communities),
            'modularity': self.calculate_modularity(communities),
            'communities': []
        }

        for i, community in enumerate(sorted(communities, key=len, reverse=True)):
            # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∏ –≤–Ω–µ—à–Ω–∏–µ —Å–≤—è–∑–∏
            internal_edges = 0
            external_edges = 0

            for node in community:
                for neighbor in self.undirected_graph[node]:
                    if neighbor in community:
                        internal_edges += 1
                    else:
                        external_edges += 1

            internal_edges //= 2  # –ö–∞–∂–¥–æ–µ —Ä–µ–±—Ä–æ –ø–æ—Å—á–∏—Ç–∞–Ω–æ –¥–≤–∞–∂–¥—ã

            # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
            n = len(community)
            max_edges = n * (n - 1) // 2
            density = internal_edges / max_edges if max_edges > 0 else 0.0

            community_info = {
                'id': i + 1,
                'size': n,
                'internal_edges': internal_edges,
                'external_edges': external_edges,
                'density': density,
                'members': [article_titles.get(article, Path(article).stem) for article in list(community)[:10]]
            }

            analysis['communities'].append(community_info)

        return analysis


class PathAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π –≤ –≥—Ä–∞—Ñ–µ"""

    def __init__(self, graph, undirected_graph, articles):
        self.graph = graph
        self.undirected_graph = undirected_graph
        self.articles = articles

    def find_shortest_path(self, source, target):
        """
        –ù–∞–π—Ç–∏ –∫—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —É–∑–ª–∞–º–∏ (BFS)

        Args:
            source: –∏—Å—Ö–æ–¥–Ω—ã–π —É–∑–µ–ª
            target: —Ü–µ–ª–µ–≤–æ–π —É–∑–µ–ª

        Returns:
            list: –ø—É—Ç—å [source, ..., target] –∏–ª–∏ None –µ—Å–ª–∏ –ø—É—Ç–∏ –Ω–µ—Ç
        """
        if source not in self.articles or target not in self.articles:
            return None

        if source == target:
            return [source]

        # BFS —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —Ä–æ–¥–∏—Ç–µ–ª–µ–π
        visited = {source}
        queue = deque([(source, [source])])

        while queue:
            node, path = queue.popleft()

            for neighbor in self.undirected_graph[node]:
                if neighbor == target:
                    return path + [neighbor]

                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, path + [neighbor]))

        return None  # –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω

    def find_all_paths(self, source, target, max_length=5):
        """
        –ù–∞–π—Ç–∏ –≤—Å–µ –ø—Ä–æ—Å—Ç—ã–µ –ø—É—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —É–∑–ª–∞–º–∏ (DFS)

        Args:
            source: –∏—Å—Ö–æ–¥–Ω—ã–π —É–∑–µ–ª
            target: —Ü–µ–ª–µ–≤–æ–π —É–∑–µ–ª
            max_length: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏

        Returns:
            list of lists: –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—É—Ç–∏
        """
        if source not in self.articles or target not in self.articles:
            return []

        all_paths = []

        def dfs(node, path):
            if len(path) > max_length:
                return

            if node == target:
                all_paths.append(path[:])
                return

            for neighbor in self.undirected_graph[node]:
                if neighbor not in path:
                    path.append(neighbor)
                    dfs(neighbor, path)
                    path.pop()

        dfs(source, [source])
        return all_paths

    def find_bottlenecks(self, betweenness_centrality, threshold=0.1):
        """
        –ù–∞–π—Ç–∏ —É–∑–ª—ã-bottlenecks (—É–∑–∫–∏–µ –º–µ—Å—Ç–∞) –≤ —Å–µ—Ç–∏

        Bottleneck - —É–∑–µ–ª, —á–µ—Ä–µ–∑ –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ—Ö–æ–¥–∏—Ç –º–Ω–æ–≥–æ –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π.
        –£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–∫–æ–≥–æ —É–∑–ª–∞ —Å–∏–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø—É—Ç–∏.

        Args:
            betweenness_centrality: dict —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ betweenness centrality
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è bottleneck

        Returns:
            list: —É–∑–ª—ã-bottlenecks —Å –∏—Ö –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        bottlenecks = []

        for article, bc_score in betweenness_centrality.items():
            if bc_score >= threshold:
                # –í—ã—á–∏—Å–ª–∏—Ç—å impact: –Ω–∞—Å–∫–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–∏—Ç—Å—è —Å–µ—Ç—å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —É–∑–ª–∞
                impact = self._calculate_removal_impact(article)

                bottlenecks.append({
                    'article': article,
                    'betweenness': bc_score,
                    'impact': impact
                })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ betweenness
        bottlenecks.sort(key=lambda x: -x['betweenness'])

        return bottlenecks

    def _calculate_removal_impact(self, node):
        """–í—ã—á–∏—Å–ª–∏—Ç—å impact –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è —É–∑–ª–∞"""
        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–∞—Ä—ã —É–∑–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç–µ—Ä—è—é—Ç —Å–≤—è–∑–Ω–æ—Å—Ç—å
        disconnected_pairs = 0

        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø–æ—Å—á–∏—Ç–∞—Ç—å —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞
        degree = len(self.undirected_graph[node])

        # Impact ~ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã—Ö –ø—É—Ç–µ–π
        # –î–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å –≤—Å–µ –∫—Ä–∞—Ç—á–∞–π—à–∏–µ –ø—É—Ç–∏
        return degree * degree  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

    def find_critical_paths(self, top_n=10):
        """
        –ù–∞–π—Ç–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏ –≤ —Å–µ—Ç–∏

        –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å - –ø—É—Ç—å –º–µ–∂–¥—É –≤–∞–∂–Ω—ã–º–∏ —É–∑–ª–∞–º–∏ (high PageRank),
        –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ bottleneck —É–∑–ª—ã.

        Args:
            top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            list: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏ —Å –∏—Ö –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –ù–∞–π—Ç–∏ —É–∑–ª—ã —Å –≤—ã—Å–æ–∫–æ–π —Å—Ç–µ–ø–µ–Ω—å—é (hubs)
        hubs = sorted(
            self.articles,
            key=lambda a: len(self.undirected_graph[a]),
            reverse=True
        )[:10]

        critical_paths = []

        # –ù–∞–π—Ç–∏ –ø—É—Ç–∏ –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø–∞—Ä–∞–º–∏ hubs
        for i, hub1 in enumerate(hubs):
            for hub2 in hubs[i+1:]:
                path = self.find_shortest_path(hub1, hub2)

                if path and len(path) > 2:
                    # –í—ã—á–∏—Å–ª–∏—Ç—å "–∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å" –ø—É—Ç–∏
                    path_length = len(path)
                    intermediate_nodes = path[1:-1]
                    avg_degree = sum(len(self.undirected_graph[n]) for n in intermediate_nodes) / len(intermediate_nodes)

                    critical_paths.append({
                        'path': path,
                        'length': path_length,
                        'avg_intermediate_degree': avg_degree
                    })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–ª–∏–Ω—ã –∏ —Å—Ç–µ–ø–µ–Ω–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —É–∑–ª–æ–≤
        critical_paths.sort(key=lambda x: x['avg_intermediate_degree'])

        return critical_paths[:top_n]

    def calculate_path_diversity(self, source, target):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—É—Ç–µ–π –º–µ–∂–¥—É –¥–≤—É–º—è —É–∑–ª–∞–º–∏

        Args:
            source: –∏—Å—Ö–æ–¥–Ω—ã–π —É–∑–µ–ª
            target: —Ü–µ–ª–µ–≤–æ–π —É–∑–µ–ª

        Returns:
            dict: –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—É—Ç–µ–π
        """
        all_paths = self.find_all_paths(source, target, max_length=6)

        if not all_paths:
            return {
                'num_paths': 0,
                'shortest_length': None,
                'longest_length': None,
                'avg_length': None,
                'unique_nodes': 0
            }

        lengths = [len(path) for path in all_paths]
        unique_nodes = set()
        for path in all_paths:
            unique_nodes.update(path)

        return {
            'num_paths': len(all_paths),
            'shortest_length': min(lengths),
            'longest_length': max(lengths),
            'avg_length': sum(lengths) / len(lengths),
            'unique_nodes': len(unique_nodes)
        }


class NetworkVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏"""

    def __init__(self, graph, undirected_graph, articles, article_titles):
        self.graph = graph
        self.undirected_graph = undirected_graph
        self.articles = articles
        self.article_titles = article_titles

    def generate_html_graph(self, pagerank=None, communities=None):
        """
        –°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π HTML –≥—Ä–∞—Ñ —Å D3.js

        Args:
            pagerank: dict —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ PageRank (–¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ —É–∑–ª–æ–≤)
            communities: list of sets (–¥–ª—è —Ü–≤–µ—Ç–∞ —É–∑–ª–æ–≤)

        Returns:
            str: –ø—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É HTML —Ñ–∞–π–ª—É
        """
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è D3.js
        nodes = []
        node_to_community = {}

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞–º
        if communities:
            for comm_id, community in enumerate(communities):
                for node in community:
                    node_to_community[node] = comm_id

        for article in self.articles:
            title = self.article_titles.get(article, Path(article).stem)
            pr_score = pagerank.get(article, 0) if pagerank else 0

            nodes.append({
                'id': article,
                'title': title,
                'pagerank': pr_score,
                'community': node_to_community.get(article, 0),
                'degree': len(self.undirected_graph[article])
            })

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä—ë–±—Ä–∞
        links = []
        seen_pairs = set()

        for source in self.articles:
            for target in self.graph[source]:
                if target in self.articles:
                    # –ò–∑–±–µ–≥–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è (A->B –∏ B->A)
                    pair = tuple(sorted([source, target]))
                    if pair not in seen_pairs:
                        seen_pairs.add(pair)
                        links.append({
                            'source': source,
                            'target': target
                        })

        # –°–æ–∑–¥–∞—Ç—å HTML —Å D3.js
        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Ç—å –∑–Ω–∞–Ω–∏–π</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}

        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}

        h1 {{
            color: white;
            text-align: center;
            margin-bottom: 20px;
            font-size: 2.5em;
            text-shadow: 0 2px 10px rgba(0,0,0,0.3);
        }}

        .controls {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            margin-bottom: 20px;
        }}

        .controls label {{
            margin-right: 10px;
            font-weight: 600;
        }}

        .controls input, .controls select {{
            margin-right: 20px;
            padding: 5px 10px;
            border: 2px solid #667eea;
            border-radius: 5px;
        }}

        #graph {{
            background: white;
            border-radius: 10px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }}

        .node {{
            cursor: pointer;
            stroke: white;
            stroke-width: 2px;
        }}

        .node:hover {{
            stroke: #667eea;
            stroke-width: 3px;
        }}

        .link {{
            stroke: #999;
            stroke-opacity: 0.6;
            stroke-width: 1px;
        }}

        .node-label {{
            font-size: 12px;
            pointer-events: none;
            text-shadow: 0 1px 2px white, 1px 0 2px white, -1px 0 2px white, 0 -1px 2px white;
        }}

        .tooltip {{
            position: absolute;
            background: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 10px;
            border-radius: 5px;
            pointer-events: none;
            display: none;
            font-size: 14px;
            max-width: 300px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üï∏Ô∏è –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Ç—å –∑–Ω–∞–Ω–∏–π</h1>

        <div class="controls">
            <label>–ü–æ–∏—Å–∫:</label>
            <input type="text" id="search" placeholder="–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏...">

            <label>–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –º–µ—Ç–∫–∏:</label>
            <input type="checkbox" id="showLabels" checked>

            <label>–°–∏–ª–∞ –ø—Ä–∏—Ç—è–∂–µ–Ω–∏—è:</label>
            <input type="range" id="chargeStrength" min="-500" max="-50" value="-200" step="10">

            <label>–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å–≤—è–∑–µ–π:</label>
            <input type="range" id="linkDistance" min="30" max="200" value="100" step="10">
        </div>

        <div id="graph"></div>
        <div class="tooltip" id="tooltip"></div>
    </div>

    <script>
        // –î–∞–Ω–Ω—ã–µ
        const nodes = {json.dumps(nodes, ensure_ascii=False)};
        const links = {json.dumps(links, ensure_ascii=False)};

        // –†–∞–∑–º–µ—Ä—ã
        const width = 1400;
        const height = 800;

        // –¶–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –¥–ª—è —Å–æ–æ–±—â–µ—Å—Ç–≤
        const color = d3.scaleOrdinal(d3.schemeCategory10);

        // SVG
        const svg = d3.select('#graph')
            .append('svg')
            .attr('width', width)
            .attr('height', height)
            .call(d3.zoom().on('zoom', (event) => {{
                g.attr('transform', event.transform);
            }}));

        const g = svg.append('g');

        // Tooltip
        const tooltip = d3.select('#tooltip');

        // –°–∏–ª–∞ —Å–∏–º—É–ª—è—Ü–∏–∏
        let chargeStrength = -200;
        let linkDistance = 100;

        const simulation = d3.forceSimulation(nodes)
            .force('link', d3.forceLink(links).id(d => d.id).distance(linkDistance))
            .force('charge', d3.forceManyBody().strength(chargeStrength))
            .force('center', d3.forceCenter(width / 2, height / 2))
            .force('collision', d3.forceCollide().radius(d => Math.sqrt(d.pagerank * 50000) + 5));

        // –õ–∏–Ω–∏–∏ (—Å–≤—è–∑–∏)
        const link = g.append('g')
            .selectAll('line')
            .data(links)
            .join('line')
            .attr('class', 'link');

        // –£–∑–ª—ã
        const node = g.append('g')
            .selectAll('circle')
            .data(nodes)
            .join('circle')
            .attr('class', 'node')
            .attr('r', d => Math.max(5, Math.sqrt(d.pagerank * 50000)))
            .attr('fill', d => color(d.community))
            .call(drag(simulation))
            .on('mouseover', (event, d) => {{
                tooltip
                    .style('display', 'block')
                    .html(`
                        <strong>${{d.title}}</strong><br>
                        PageRank: ${{d.pagerank.toFixed(6)}}<br>
                        –°—Ç–µ–ø–µ–Ω—å: ${{d.degree}}<br>
                        –°–æ–æ–±—â–µ—Å—Ç–≤–æ: ${{d.community + 1}}
                    `)
                    .style('left', (event.pageX + 10) + 'px')
                    .style('top', (event.pageY - 10) + 'px');
            }})
            .on('mouseout', () => {{
                tooltip.style('display', 'none');
            }});

        // –ú–µ—Ç–∫–∏
        const labels = g.append('g')
            .selectAll('text')
            .data(nodes)
            .join('text')
            .attr('class', 'node-label')
            .text(d => d.title.length > 30 ? d.title.substring(0, 30) + '...' : d.title)
            .attr('text-anchor', 'middle')
            .attr('dy', -10);

        // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π
        simulation.on('tick', () => {{
            link
                .attr('x1', d => d.source.x)
                .attr('y1', d => d.source.y)
                .attr('x2', d => d.target.x)
                .attr('y2', d => d.target.y);

            node
                .attr('cx', d => d.x)
                .attr('cy', d => d.y);

            labels
                .attr('x', d => d.x)
                .attr('y', d => d.y);
        }});

        // Drag & drop
        function drag(simulation) {{
            function dragstarted(event) {{
                if (!event.active) simulation.alphaTarget(0.3).restart();
                event.subject.fx = event.subject.x;
                event.subject.fy = event.subject.y;
            }}

            function dragged(event) {{
                event.subject.fx = event.x;
                event.subject.fy = event.y;
            }}

            function dragended(event) {{
                if (!event.active) simulation.alphaTarget(0);
                event.subject.fx = null;
                event.subject.fy = null;
            }}

            return d3.drag()
                .on('start', dragstarted)
                .on('drag', dragged)
                .on('end', dragended);
        }}

        // –ü–æ–∏—Å–∫
        d3.select('#search').on('input', function() {{
            const searchTerm = this.value.toLowerCase();

            node.attr('opacity', d => {{
                if (searchTerm === '' || d.title.toLowerCase().includes(searchTerm)) {{
                    return 1;
                }} else {{
                    return 0.2;
                }}
            }});

            labels.attr('opacity', d => {{
                if (searchTerm === '' || d.title.toLowerCase().includes(searchTerm)) {{
                    return 1;
                }} else {{
                    return 0.2;
                }}
            }});
        }});

        // –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å/—Å–∫—Ä—ã–≤–∞—Ç—å –º–µ—Ç–∫–∏
        d3.select('#showLabels').on('change', function() {{
            labels.attr('display', this.checked ? 'block' : 'none');
        }});

        // –°–∏–ª–∞ –ø—Ä–∏—Ç—è–∂–µ–Ω–∏—è
        d3.select('#chargeStrength').on('input', function() {{
            chargeStrength = +this.value;
            simulation.force('charge', d3.forceManyBody().strength(chargeStrength));
            simulation.alpha(0.3).restart();
        }});

        // –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å–≤—è–∑–µ–π
        d3.select('#linkDistance').on('input', function() {{
            linkDistance = +this.value;
            simulation.force('link', d3.forceLink(links).id(d => d.id).distance(linkDistance));
            simulation.alpha(0.3).restart();
        }});
    </script>
</body>
</html>"""

        return html

    def generate_graphml(self, output_file):
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ –≤ —Ñ–æ—Ä–º–∞—Ç GraphML (–¥–ª—è Gephi, Cytoscape)

        GraphML - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π XML —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –≥—Ä–∞—Ñ–æ–≤.

        Args:
            output_file: –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É

        Returns:
            str: –ø—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        lines = []
        lines.append('<?xml version="1.0" encoding="UTF-8"?>')
        lines.append('<graphml xmlns="http://graphml.graphdrawing.org/xmlns">')
        lines.append('  <key id="title" for="node" attr.name="title" attr.type="string"/>')
        lines.append('  <key id="degree" for="node" attr.name="degree" attr.type="int"/>')
        lines.append('  <graph id="G" edgedefault="directed">')

        # –£–∑–ª—ã
        for article in self.articles:
            title = self.article_titles.get(article, Path(article).stem)
            degree = len(self.undirected_graph[article])

            # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å XML
            title_escaped = title.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            article_escaped = article.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

            lines.append(f'    <node id="{article_escaped}">')
            lines.append(f'      <data key="title">{title_escaped}</data>')
            lines.append(f'      <data key="degree">{degree}</data>')
            lines.append('    </node>')

        # –†—ë–±—Ä–∞
        edge_id = 0
        for source in self.articles:
            for target in self.graph[source]:
                if target in self.articles:
                    source_escaped = source.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                    target_escaped = target.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

                    lines.append(f'    <edge id="e{edge_id}" source="{source_escaped}" target="{target_escaped}"/>')
                    edge_id += 1

        lines.append('  </graph>')
        lines.append('</graphml>')

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        return str(output_file)

    def generate_gexf(self, output_file):
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ –≤ —Ñ–æ—Ä–º–∞—Ç GEXF (–¥–ª—è Gephi)

        GEXF - Graph Exchange XML Format, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è Gephi.

        Args:
            output_file: –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É

        Returns:
            str: –ø—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        lines = []
        lines.append('<?xml version="1.0" encoding="UTF-8"?>')
        lines.append('<gexf xmlns="http://www.gexf.net/1.2draft" version="1.2">')
        lines.append('  <meta>')
        lines.append('    <creator>Network Analyzer</creator>')
        lines.append('    <description>Knowledge Graph Export</description>')
        lines.append('  </meta>')
        lines.append('  <graph mode="static" defaultedgetype="directed">')
        lines.append('    <attributes class="node">')
        lines.append('      <attribute id="0" title="title" type="string"/>')
        lines.append('      <attribute id="1" title="degree" type="integer"/>')
        lines.append('    </attributes>')

        # –£–∑–ª—ã
        lines.append('    <nodes>')
        for i, article in enumerate(self.articles):
            title = self.article_titles.get(article, Path(article).stem)
            degree = len(self.undirected_graph[article])

            title_escaped = title.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

            lines.append(f'      <node id="{i}" label="{title_escaped}">')
            lines.append('        <attvalues>')
            lines.append(f'          <attvalue for="0" value="{title_escaped}"/>')
            lines.append(f'          <attvalue for="1" value="{degree}"/>')
            lines.append('        </attvalues>')
            lines.append('      </node>')

        lines.append('    </nodes>')

        # –†—ë–±—Ä–∞
        lines.append('    <edges>')
        article_to_id = {article: i for i, article in enumerate(self.articles)}
        edge_id = 0

        for source in self.articles:
            for target in self.graph[source]:
                if target in self.articles:
                    source_id = article_to_id[source]
                    target_id = article_to_id[target]

                    lines.append(f'      <edge id="{edge_id}" source="{source_id}" target="{target_id}"/>')
                    edge_id += 1

        lines.append('    </edges>')
        lines.append('  </graph>')
        lines.append('</gexf>')

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        return str(output_file)


class AdvancedNetworkAnalyzer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–µ—Ç–∏"""

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"
        self.graph = defaultdict(set)  # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ
        self.undirected_graph = defaultdict(set)  # –ù–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫
        self.articles = set()
        self.article_titles = {}

    def extract_frontmatter_and_content(self, file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                return yaml.safe_load(match.group(1)), match.group(2)
        except:
            pass
        return None, None

    def build_network(self):
        print("üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–µ—Ç–∏...\n")

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            frontmatter, content = self.extract_frontmatter_and_content(md_file)
            if not content:
                continue

            source = str(md_file.relative_to(self.root_dir))
            self.articles.add(source)

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = frontmatter.get('title', md_file.stem) if frontmatter else md_file.stem
            self.article_titles[source] = title

            # –ò–∑–≤–ª–µ—á—å —Å—Å—ã–ª–∫–∏
            links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
            for text, link in links:
                if not link.startswith('http'):
                    try:
                        target = (md_file.parent / link.split('#')[0]).resolve()
                        if target.exists() and target.is_relative_to(self.root_dir):
                            target_path = str(target.relative_to(self.root_dir))
                            self.graph[source].add(target_path)
                            self.undirected_graph[source].add(target_path)
                            self.undirected_graph[target_path].add(source)
                            self.articles.add(target_path)
                    except:
                        pass

        print(f"   Nodes: {len(self.articles)}")
        print(f"   Edges: {sum(len(v) for v in self.graph.values())}\n")

    def calculate_degree_centrality(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å degree centrality"""
        centrality = {}

        for article in self.articles:
            out_degree = len(self.graph[article])
            in_degree = sum(1 for neighbors in self.graph.values() if article in neighbors)

            centrality[article] = {
                'out_degree': out_degree,
                'in_degree': in_degree,
                'total_degree': out_degree + in_degree
            }

        return centrality

    def bfs_shortest_paths(self, start):
        """BFS –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π"""
        distances = {start: 0}
        paths_through = defaultdict(int)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π —á–µ—Ä–µ–∑ —É–∑–µ–ª
        queue = deque([start])
        predecessors = defaultdict(list)

        while queue:
            node = queue.popleft()

            for neighbor in self.undirected_graph[node]:
                if neighbor not in distances:
                    distances[neighbor] = distances[node] + 1
                    queue.append(neighbor)
                    predecessors[neighbor].append(node)
                elif distances[neighbor] == distances[node] + 1:
                    predecessors[neighbor].append(node)

        return distances, predecessors

    def calculate_betweenness_centrality(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å betweenness centrality (–∞–ª–≥–æ—Ä–∏—Ç–º Brandes)"""
        betweenness = {article: 0.0 for article in self.articles}

        for source in self.articles:
            # BFS –æ—Ç source
            distances = {source: 0}
            paths_count = {source: 1}
            stack = []
            predecessors = defaultdict(list)
            queue = deque([source])

            while queue:
                node = queue.popleft()
                stack.append(node)

                for neighbor in self.undirected_graph[node]:
                    # –ü–µ—Ä–≤–æ–µ –ø–æ—Å–µ—â–µ–Ω–∏–µ neighbor
                    if neighbor not in distances:
                        distances[neighbor] = distances[node] + 1
                        queue.append(neighbor)

                    # –ö—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –∫ neighbor —á–µ—Ä–µ–∑ node
                    if distances[neighbor] == distances[node] + 1:
                        paths_count[neighbor] = paths_count.get(neighbor, 0) + paths_count[node]
                        predecessors[neighbor].append(node)

            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            dependency = {article: 0.0 for article in self.articles}

            while stack:
                node = stack.pop()

                for pred in predecessors[node]:
                    dependency[pred] += (paths_count[pred] / paths_count[node]) * (1 + dependency[node])

                if node != source:
                    betweenness[node] += dependency[node]

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        n = len(self.articles)
        if n > 2:
            normalization = 1.0 / ((n - 1) * (n - 2))
            betweenness = {k: v * normalization for k, v in betweenness.items()}

        return betweenness

    def calculate_closeness_centrality(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å closeness centrality"""
        closeness = {}

        for article in self.articles:
            distances, _ = self.bfs_shortest_paths(article)

            # –°—É–º–º–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ –≤—Å–µ—Ö –¥–æ—Å—Ç–∏–∂–∏–º—ã—Ö —É–∑–ª–æ–≤
            total_distance = sum(distances.values())

            # Closeness = (n-1) / sum(distances)
            if total_distance > 0:
                closeness[article] = (len(distances) - 1) / total_distance
            else:
                closeness[article] = 0.0

        return closeness

    def calculate_pagerank(self, damping=0.85, max_iterations=100, tolerance=1e-6):
        """–í—ã—á–∏—Å–ª–∏—Ç—å PageRank"""
        n = len(self.articles)
        pagerank = {article: 1.0 / n for article in self.articles}

        for iteration in range(max_iterations):
            new_pagerank = {}
            max_diff = 0

            for article in self.articles:
                # –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                rank = (1 - damping) / n

                # –í–∫–ª–∞–¥ –æ—Ç –≤—Ö–æ–¥—è—â–∏—Ö —Å—Å—ã–ª–æ–∫
                for source in self.articles:
                    if article in self.graph[source]:
                        out_degree = len(self.graph[source])
                        if out_degree > 0:
                            rank += damping * pagerank[source] / out_degree

                new_pagerank[article] = rank
                max_diff = max(max_diff, abs(new_pagerank[article] - pagerank[article]))

            pagerank = new_pagerank

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if max_diff < tolerance:
                break

        return pagerank

    def calculate_clustering_coefficient(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å clustering coefficient (–ª–æ–∫–∞–ª—å–Ω—ã–π –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–π)"""
        clustering = {}

        for article in self.articles:
            neighbors = self.undirected_graph[article]
            k = len(neighbors)

            if k < 2:
                clustering[article] = 0.0
                continue

            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–æ—Å–µ–¥—è–º–∏
            links_between_neighbors = 0

            for n1 in neighbors:
                for n2 in neighbors:
                    if n1 != n2 and n2 in self.undirected_graph[n1]:
                        links_between_neighbors += 1

            # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            max_links = k * (k - 1)
            clustering[article] = links_between_neighbors / max_links if max_links > 0 else 0.0

        # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
        global_clustering = sum(clustering.values()) / len(clustering) if clustering else 0.0

        return clustering, global_clustering

    def detect_communities_simple(self):
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤ (connected components)"""
        visited = set()
        communities = []

        def dfs(node, community):
            visited.add(node)
            community.add(node)

            for neighbor in self.undirected_graph[node]:
                if neighbor not in visited:
                    dfs(neighbor, community)

        for article in self.articles:
            if article not in visited:
                community = set()
                dfs(article, community)
                communities.append(community)

        return communities

    def calculate_graph_properties(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ –≥—Ä–∞—Ñ–∞"""
        n = len(self.articles)
        m = sum(len(v) for v in self.graph.values())

        # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å
        max_edges = n * (n - 1)
        density = m / max_edges if max_edges > 0 else 0.0

        # –î–∏–∞–º–µ—Ç—Ä –∏ —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏
        all_distances = []

        for article in self.articles:
            distances, _ = self.bfs_shortest_paths(article)
            all_distances.extend(distances.values())

        diameter = max(all_distances) if all_distances else 0
        avg_path_length = sum(all_distances) / len(all_distances) if all_distances else 0

        # Connected components
        communities = self.detect_communities_simple()

        return {
            'nodes': n,
            'edges': m,
            'density': density,
            'diameter': diameter,
            'avg_path_length': avg_path_length,
            'connected_components': len(communities),
            'largest_component': max(len(c) for c in communities) if communities else 0
        }

    def generate_report(self, all_metrics):
        """–°–æ–∑–¥–∞—Ç—å Markdown –æ—Ç—á—ë—Ç"""
        lines = []
        lines.append("# üìä –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑\n\n")
        lines.append("> –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π\n\n")

        # –°–≤–æ–π—Å—Ç–≤–∞ –≥—Ä–∞—Ñ–∞
        props = all_metrics['graph_properties']

        lines.append("## –°–≤–æ–π—Å—Ç–≤–∞ –≥—Ä–∞—Ñ–∞\n\n")
        lines.append(f"- **–£–∑–ª–æ–≤ (nodes)**: {props['nodes']}\n")
        lines.append(f"- **–†—ë–±–µ—Ä (edges)**: {props['edges']}\n")
        lines.append(f"- **–ü–ª–æ—Ç–Ω–æ—Å—Ç—å (density)**: {props['density']:.4f}\n")
        lines.append(f"- **–î–∏–∞–º–µ—Ç—Ä (diameter)**: {props['diameter']}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏**: {props['avg_path_length']:.2f}\n")
        lines.append(f"- **Connected components**: {props['connected_components']}\n")
        lines.append(f"- **Largest component**: {props['largest_component']}\n\n")

        # –¢–æ–ø –ø–æ PageRank
        lines.append("## –¢–æ–ø-10 –ø–æ PageRank\n\n")
        sorted_pr = sorted(all_metrics['pagerank'].items(), key=lambda x: -x[1])

        for article, score in sorted_pr[:10]:
            title = self.article_titles.get(article, Path(article).stem)
            lines.append(f"1. **{title}**: {score:.6f}\n")

        # –¢–æ–ø –ø–æ Betweenness
        lines.append("\n## –¢–æ–ø-10 –ø–æ Betweenness Centrality\n\n")
        lines.append("> –°—Ç–∞—Ç—å–∏, –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –Ω–∞ –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç—è—Ö –º–µ–∂–¥—É –¥—Ä—É–≥–∏–º–∏\n\n")

        sorted_bt = sorted(all_metrics['betweenness'].items(), key=lambda x: -x[1])

        for article, score in sorted_bt[:10]:
            title = self.article_titles.get(article, Path(article).stem)
            lines.append(f"1. **{title}**: {score:.6f}\n")

        # –¢–æ–ø –ø–æ Closeness
        lines.append("\n## –¢–æ–ø-10 –ø–æ Closeness Centrality\n\n")
        lines.append("> –°—Ç–∞—Ç—å–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Å—Ä–µ–¥–Ω–∏–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º –¥–æ –¥—Ä—É–≥–∏—Ö\n\n")

        sorted_cl = sorted(all_metrics['closeness'].items(), key=lambda x: -x[1])

        for article, score in sorted_cl[:10]:
            title = self.article_titles.get(article, Path(article).stem)
            lines.append(f"1. **{title}**: {score:.6f}\n")

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        lines.append("\n## –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è\n\n")
        lines.append(f"- **–ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏**: {all_metrics['global_clustering']:.4f}\n\n")

        lines.append("### –¢–æ–ø-10 –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n\n")
        sorted_clust = sorted(all_metrics['clustering'].items(), key=lambda x: -x[1])

        for article, score in sorted_clust[:10]:
            title = self.article_titles.get(article, Path(article).stem)
            lines.append(f"1. **{title}**: {score:.4f}\n")

        # Degree centrality
        lines.append("\n## –¢–æ–ø-10 –ø–æ Degree Centrality\n\n")
        sorted_deg = sorted(all_metrics['degree'].items(), key=lambda x: -x[1]['total_degree'])

        for article, metrics in sorted_deg[:10]:
            title = self.article_titles.get(article, Path(article).stem)
            lines.append(f"1. **{title}**: {metrics['total_degree']} ")
            lines.append(f"(in: {metrics['in_degree']}, out: {metrics['out_degree']})\n")

        output_file = self.root_dir / "ADVANCED_NETWORK_ANALYSIS.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑: {output_file}")

    def save_json(self, all_metrics):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON"""
        data = {
            'graph_properties': all_metrics['graph_properties'],
            'nodes': {}
        }

        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞
        for article in self.articles:
            title = self.article_titles.get(article, Path(article).stem)

            data['nodes'][article] = {
                'title': title,
                'pagerank': all_metrics['pagerank'].get(article, 0),
                'betweenness': all_metrics['betweenness'].get(article, 0),
                'closeness': all_metrics['closeness'].get(article, 0),
                'clustering': all_metrics['clustering'].get(article, 0),
                'degree': all_metrics['degree'].get(article, {})
            }

        output_file = self.root_dir / "network_metrics.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON –º–µ—Ç—Ä–∏–∫–∏: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='üìä –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ—Ç–∏',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ (Markdown + JSON)
  %(prog)s

  # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
  %(prog)s --html

  # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏
  %(prog)s --centrality

  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤ (Louvain)
  %(prog)s --communities

  # –ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π –∏ bottlenecks
  %(prog)s --paths

  # –≠–∫—Å–ø–æ—Ä—Ç –≤ GraphML (–¥–ª—è Gephi)
  %(prog)s --graphml

  # –≠–∫—Å–ø–æ—Ä—Ç –≤ GEXF (–¥–ª—è Gephi)
  %(prog)s --gexf

  # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ + HTML)
  %(prog)s --all

  # –ü–æ–∏—Å–∫ –ø—É—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç–∞—Ç—å—è–º–∏
  %(prog)s --find-path "knowledge/foo.md" "knowledge/bar.md"

  # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ä —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏
  %(prog)s --compare-centrality

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: NetworkX, Gephi, igraph, Neo4j
        '''
    )

    parser.add_argument('--html', action='store_true',
                        help='–°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å D3.js')
    parser.add_argument('--centrality', action='store_true',
                        help='–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ (eigenvector, Katz, harmonic)')
    parser.add_argument('--communities', action='store_true',
                        help='–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤ (Louvain method)')
    parser.add_argument('--paths', action='store_true',
                        help='–ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π –∏ bottlenecks')
    parser.add_argument('--graphml', action='store_true',
                        help='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç GraphML')
    parser.add_argument('--gexf', action='store_true',
                        help='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç GEXF')
    parser.add_argument('--compare-centrality', action='store_true',
                        help='–°—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏')
    parser.add_argument('--find-path', nargs=2, metavar=('SOURCE', 'TARGET'),
                        help='–ù–∞–π—Ç–∏ –∫—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç–∞—Ç—å—è–º–∏')
    parser.add_argument('--all', action='store_true',
                        help='–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ –æ–ø—Ü–∏–∏)')
    parser.add_argument('--json', action='store_true',
                        help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON –º–µ—Ç—Ä–∏–∫–∏')

    args = parser.parse_args()

    # --all –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –æ–ø—Ü–∏–∏
    if args.all:
        args.html = True
        args.centrality = True
        args.communities = True
        args.paths = True
        args.graphml = True
        args.gexf = True
        args.compare_centrality = True
        args.json = True

    # –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø—Ü–∏–π, –ø–æ–∫–∞–∑–∞—Ç—å –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    if not any([args.html, args.centrality, args.communities, args.paths,
                args.graphml, args.gexf, args.compare_centrality, args.find_path,
                args.json]):
        args.json = True

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent

    analyzer = AdvancedNetworkAnalyzer(root_dir)
    analyzer.build_network()

    print("üìà –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫...\n")

    # –í—ã—á–∏—Å–ª–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    degree = analyzer.calculate_degree_centrality()
    print("   ‚úì Degree centrality")

    pagerank = analyzer.calculate_pagerank()
    print("   ‚úì PageRank")

    betweenness = analyzer.calculate_betweenness_centrality()
    print("   ‚úì Betweenness centrality")

    closeness = analyzer.calculate_closeness_centrality()
    print("   ‚úì Closeness centrality")

    clustering, global_clustering = analyzer.calculate_clustering_coefficient()
    print("   ‚úì Clustering coefficient")

    graph_properties = analyzer.calculate_graph_properties()
    print("   ‚úì Graph properties\n")

    # –°–æ–±—Ä–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    all_metrics = {
        'degree': degree,
        'pagerank': pagerank,
        'betweenness': betweenness,
        'closeness': closeness,
        'clustering': clustering,
        'global_clustering': global_clustering,
        'graph_properties': graph_properties
    }

    # –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –æ—Ç—á—ë—Ç
    analyzer.generate_report(all_metrics)

    # JSON —ç–∫—Å–ø–æ—Ä—Ç
    if args.json:
        analyzer.save_json(all_metrics)

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏
    if args.centrality or args.compare_centrality:
        print("üéØ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏...\n")

        centrality_analyzer = CentralityAnalyzer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles
        )

        eigenvector = centrality_analyzer.calculate_eigenvector_centrality()
        print("   ‚úì Eigenvector centrality")

        katz = centrality_analyzer.calculate_katz_centrality()
        print("   ‚úì Katz centrality")

        harmonic = centrality_analyzer.calculate_harmonic_centrality()
        print("   ‚úì Harmonic centrality\n")

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ø-10 –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ä–µ
        centrality_report = []
        centrality_report.append("# üéØ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏\n\n")

        # Eigenvector
        centrality_report.append("## Eigenvector Centrality\n\n")
        centrality_report.append("> –ú–µ—Ä–∞ –≤–ª–∏—è–Ω–∏—è —É–∑–ª–∞: —Å–≤—è–∑—å —Å –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã–º–∏ —É–∑–ª–∞–º–∏\n\n")
        sorted_eig = sorted(eigenvector.items(), key=lambda x: -x[1])
        for article, score in sorted_eig[:10]:
            title = analyzer.article_titles.get(article, Path(article).stem)
            centrality_report.append(f"1. **{title}**: {score:.6f}\n")

        # Katz
        centrality_report.append("\n## Katz Centrality\n\n")
        centrality_report.append("> –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –ø—É—Ç–∏ –≤ –≥—Ä–∞—Ñ–µ, –≤–∑–≤–µ—à–∏–≤–∞—è –∏—Ö –ø–æ –¥–ª–∏–Ω–µ\n\n")
        sorted_katz = sorted(katz.items(), key=lambda x: -x[1])
        for article, score in sorted_katz[:10]:
            title = analyzer.article_titles.get(article, Path(article).stem)
            centrality_report.append(f"1. **{title}**: {score:.4f}\n")

        # Harmonic
        centrality_report.append("\n## Harmonic Centrality\n\n")
        centrality_report.append("> –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ closeness, –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤\n\n")
        sorted_harm = sorted(harmonic.items(), key=lambda x: -x[1])
        for article, score in sorted_harm[:10]:
            title = analyzer.article_titles.get(article, Path(article).stem)
            centrality_report.append(f"1. **{title}**: {score:.2f}\n")

        output_file = root_dir / "CENTRALITY_ANALYSIS.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(centrality_report)
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏: {output_file}")

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ä —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏
    if args.compare_centrality:
        print("\nüîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ä —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏...\n")

        centrality_analyzer = CentralityAnalyzer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles
        )

        comparison = centrality_analyzer.compare_centrality_measures(
            pagerank, betweenness, closeness
        )

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        comparison_report = []
        comparison_report.append("# üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ä —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏\n\n")
        comparison_report.append("## –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Ç–æ–ø-10\n\n")
        comparison_report.append("> –°–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –≤—Ö–æ–¥—è—Ç –≤ —Ç–æ–ø-10 –ø–æ –æ–±–µ–∏–º –º–µ—Ä–∞–º\n\n")

        for pair, overlap in sorted(comparison['overlaps'].items(), key=lambda x: -x[1]):
            comparison_report.append(f"- **{pair}**: {overlap}/10 —Å—Ç–∞—Ç–µ–π\n")

        output_file = root_dir / "CENTRALITY_COMPARISON.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(comparison_report)
        print(f"‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏: {output_file}\n")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤
    if args.communities:
        print("üë• –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤...\n")

        community_detector = CommunityDetector(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles
        )

        communities_louvain = community_detector.louvain_method()
        print(f"   ‚úì Louvain method: {len(communities_louvain)} —Å–æ–æ–±—â–µ—Å—Ç–≤")

        communities_label = community_detector.label_propagation()
        print(f"   ‚úì Label propagation: {len(communities_label)} —Å–æ–æ–±—â–µ—Å—Ç–≤\n")

        # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤ Louvain
        analysis = community_detector.analyze_communities(
            communities_louvain,
            analyzer.article_titles
        )

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç
        community_report = []
        community_report.append("# üë• –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤\n\n")
        community_report.append(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ—Å—Ç–≤**: {analysis['num_communities']}\n\n")
        community_report.append(f"**Modularity**: {analysis['modularity']:.4f}\n\n")
        community_report.append("> Modularity > 0.3 —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º\n\n")

        community_report.append("## –¢–æ–ø-10 —Å–æ–æ–±—â–µ—Å—Ç–≤\n\n")

        for comm in analysis['communities'][:10]:
            community_report.append(f"### –°–æ–æ–±—â–µ—Å—Ç–≤–æ {comm['id']}\n\n")
            community_report.append(f"- **–†–∞–∑–º–µ—Ä**: {comm['size']} —Å—Ç–∞—Ç–µ–π\n")
            community_report.append(f"- **–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å–≤—è–∑–∏**: {comm['internal_edges']}\n")
            community_report.append(f"- **–í–Ω–µ—à–Ω–∏–µ —Å–≤—è–∑–∏**: {comm['external_edges']}\n")
            community_report.append(f"- **–ü–ª–æ—Ç–Ω–æ—Å—Ç—å**: {comm['density']:.4f}\n\n")

            if comm['members']:
                community_report.append("**–ß–ª–µ–Ω—ã —Å–æ–æ–±—â–µ—Å—Ç–≤–∞** (–¥–æ 10):\n\n")
                for member in comm['members']:
                    community_report.append(f"- {member}\n")
                community_report.append("\n")

        output_file = root_dir / "COMMUNITY_ANALYSIS.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(community_report)
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤: {output_file}")

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–ª—è HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        communities_for_html = communities_louvain

    # –ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π
    if args.paths:
        print("\nüõ§Ô∏è  –ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π –∏ bottlenecks...\n")

        path_analyzer = PathAnalyzer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles
        )

        bottlenecks = path_analyzer.find_bottlenecks(betweenness, threshold=0.01)
        print(f"   ‚úì –ù–∞–π–¥–µ–Ω–æ {len(bottlenecks)} bottlenecks")

        critical_paths = path_analyzer.find_critical_paths(top_n=10)
        print(f"   ‚úì –ù–∞–π–¥–µ–Ω–æ {len(critical_paths)} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ–π\n")

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç
        path_report = []
        path_report.append("# üõ§Ô∏è  –ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π\n\n")

        path_report.append("## –£–∑–ª—ã-Bottlenecks\n\n")
        path_report.append("> –£–∑–ª—ã, —á–µ—Ä–µ–∑ –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –º–Ω–æ–≥–æ –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π\n\n")

        for bn in bottlenecks[:10]:
            title = analyzer.article_titles.get(bn['article'], Path(bn['article']).stem)
            path_report.append(f"1. **{title}**\n")
            path_report.append(f"   - Betweenness: {bn['betweenness']:.6f}\n")
            path_report.append(f"   - Impact: {bn['impact']}\n")

        path_report.append("\n## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏\n\n")
        path_report.append("> –ü—É—Ç–∏ –º–µ–∂–¥—É –≤–∞–∂–Ω—ã–º–∏ —É–∑–ª–∞–º–∏ (hubs)\n\n")

        for i, cp in enumerate(critical_paths, 1):
            path_report.append(f"### –ü—É—Ç—å {i}\n\n")
            path_report.append(f"- **–î–ª–∏–Ω–∞**: {cp['length']}\n")
            path_report.append(f"- **–°—Ä–µ–¥–Ω—è—è —Å—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —É–∑–ª–æ–≤**: {cp['avg_intermediate_degree']:.2f}\n\n")

            path_report.append("**–ú–∞—Ä—à—Ä—É—Ç**:\n\n")
            for node in cp['path']:
                title = analyzer.article_titles.get(node, Path(node).stem)
                path_report.append(f"‚Üí {title}\n")
            path_report.append("\n")

        output_file = root_dir / "PATH_ANALYSIS.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(path_report)
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –ø—É—Ç–µ–π: {output_file}")

    # –ü–æ–∏—Å–∫ –ø—É—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç–∞—Ç—å—è–º–∏
    if args.find_path:
        source, target = args.find_path

        path_analyzer = PathAnalyzer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles
        )

        path = path_analyzer.find_shortest_path(source, target)

        if path:
            print(f"\nüîç –ö—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –Ω–∞–π–¥–µ–Ω ({len(path)} —à–∞–≥–æ–≤):\n")
            for node in path:
                title = analyzer.article_titles.get(node, Path(node).stem)
                print(f"   ‚Üí {title}")

            # –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—É—Ç–µ–π
            diversity = path_analyzer.calculate_path_diversity(source, target)
            print(f"\nüìä –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—É—Ç–µ–π:")
            print(f"   –í—Å–µ–≥–æ –ø—É—Ç–µ–π: {diversity['num_paths']}")
            if diversity['num_paths'] > 0:
                print(f"   –ö—Ä–∞—Ç—á–∞–π—à–∏–π: {diversity['shortest_length']} —à–∞–≥–æ–≤")
                print(f"   –î–ª–∏–Ω–Ω–µ–π—à–∏–π: {diversity['longest_length']} —à–∞–≥–æ–≤")
                print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {diversity['avg_length']:.2f} —à–∞–≥–æ–≤")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤: {diversity['unique_nodes']}")
        else:
            print(f"\n‚ùå –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω –º–µ–∂–¥—É {source} –∏ {target}")

    # GraphML —ç–∫—Å–ø–æ—Ä—Ç
    if args.graphml:
        print("\nüì¶ –≠–∫—Å–ø–æ—Ä—Ç –≤ GraphML...\n")

        visualizer = NetworkVisualizer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles,
            analyzer.article_titles
        )

        output_file = root_dir / "network.graphml"
        visualizer.generate_graphml(output_file)
        print(f"‚úÖ GraphML: {output_file}")

    # GEXF —ç–∫—Å–ø–æ—Ä—Ç
    if args.gexf:
        print("\nüì¶ –≠–∫—Å–ø–æ—Ä—Ç –≤ GEXF...\n")

        visualizer = NetworkVisualizer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles,
            analyzer.article_titles
        )

        output_file = root_dir / "network.gexf"
        visualizer.generate_gexf(output_file)
        print(f"‚úÖ GEXF: {output_file}")

    # HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if args.html:
        print("\nüé® –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...\n")

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –µ—Å–ª–∏ –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
        if not args.communities:
            community_detector = CommunityDetector(
                analyzer.graph,
                analyzer.undirected_graph,
                analyzer.articles
            )
            communities_for_html = community_detector.louvain_method()
        else:
            communities_for_html = communities_louvain

        visualizer = NetworkVisualizer(
            analyzer.graph,
            analyzer.undirected_graph,
            analyzer.articles,
            analyzer.article_titles
        )

        html_content = visualizer.generate_html_graph(
            pagerank=pagerank,
            communities=communities_for_html
        )

        output_file = root_dir / "network_graph.html"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {output_file}")
        print(f"   –û—Ç–∫—Ä–æ–π—Ç–µ {output_file} –≤ –±—Ä–∞—É–∑–µ—Ä–µ")

    print("\n‚ú® –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")


if __name__ == "__main__":
    main()
