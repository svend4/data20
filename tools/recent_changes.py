#!/usr/bin/env python3
"""
Advanced Recent Changes - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
–§—É–Ω–∫—Ü–∏–∏:
- Contributor statistics (–∫—Ç–æ –∞–∫—Ç–∏–≤–Ω–µ–µ, –º–µ—Ç—Ä–∏–∫–∏)
- Change frequency heatmap (–∫–æ–≥–¥–∞ –±–æ–ª—å—à–µ –∫–æ–º–º–∏—Ç–æ–≤)
- Diff stats (insertions/deletions per file)
- Change categories (docs vs code vs tools)
- RSS feed generation (–¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤)
- Velocity metrics (—Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π)
- Most active files/directories
- Impact analysis (—Å—Ç—Ä–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–æ)
- GitHub-style activity graph
- Export to JSON/CSV

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ: GitHub Insights, GitStats, git-stats, RSS/Atom feeds
"""

from pathlib import Path
import subprocess
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import json
import xml.etree.ElementTree as ET
import re


class ContributorAnalyzer:
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤"""

    def __init__(self, contributors, changes):
        self.contributors = contributors
        self.changes = changes

    def analyze_contributor_patterns(self, author):
        """
        –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ä–∞–±–æ—Ç—ã –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–∞

        Args:
            author: –∏–º—è –∞–≤—Ç–æ—Ä–∞

        Returns:
            dict: –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–±–æ—Ç—ã
        """
        if author not in self.contributors:
            return None

        stats = self.contributors[author]
        author_commits = [c for c in self.changes if c['author'] == author]

        if not author_commits:
            return None

        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
        hours = [c['hour'] for c in author_commits]
        most_active_hour = Counter(hours).most_common(1)[0][0] if hours else 12

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å "—Ç–∏–ø" –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–∞
        avg_commit_size = (stats['insertions'] + stats['deletions']) / stats['commits'] if stats['commits'] > 0 else 0

        if avg_commit_size > 500:
            contributor_type = 'major_refactorer'  # –ë–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        elif avg_commit_size > 100:
            contributor_type = 'feature_developer'  # –°—Ä–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        else:
            contributor_type = 'bug_fixer'  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è

        # –ß–∞—Å—Ç–æ—Ç–∞ –∫–æ–º–º–∏—Ç–æ–≤
        unique_dates = len(set(stats['dates']))
        commit_frequency = stats['commits'] / unique_dates if unique_dates > 0 else 0

        return {
            'author': author,
            'most_active_hour': most_active_hour,
            'contributor_type': contributor_type,
            'avg_commit_size': int(avg_commit_size),
            'commit_frequency': round(commit_frequency, 2),
            'unique_days': unique_dates,
            'commits_per_day': round(stats['commits'] / unique_dates, 2) if unique_dates > 0 else 0
        }

    def calculate_specialization(self, author):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤

        Args:
            author: –∏–º—è –∞–≤—Ç–æ—Ä–∞

        Returns:
            dict: —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        author_commits = [c for c in self.changes if c['author'] == author]
        category_changes = defaultdict(int)

        for commit in author_commits:
            for file_info in commit['files']:
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
                path = Path(file_info['path'])
                if path.suffix == '.py':
                    category_changes['python'] += 1
                elif path.suffix == '.md':
                    category_changes['docs'] += 1
                elif path.suffix in ['.json', '.yaml', '.yml']:
                    category_changes['config'] += 1
                elif path.suffix in ['.sh', '.bash']:
                    category_changes['scripts'] += 1
                else:
                    category_changes['other'] += 1

        total = sum(category_changes.values())
        if total == 0:
            return {}

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        specialization = {
            category: round((count / total) * 100, 1)
            for category, count in category_changes.items()
        }

        return dict(sorted(specialization.items(), key=lambda x: -x[1]))

    def find_collaboration_pairs(self):
        """
        –ù–∞–π—Ç–∏ –ø–∞—Ä—ã –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤, —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –Ω–∞–¥ –æ–¥–Ω–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏

        Returns:
            list: –ø–∞—Ä—ã —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞
        """
        # –§–∞–π–ª—ã, –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–º –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–º
        contributor_files = defaultdict(set)

        for commit in self.changes:
            author = commit['author']
            for file_info in commit['files']:
                contributor_files[author].add(file_info['path'])

        # –ù–∞–π—Ç–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        collaborations = []
        authors = list(contributor_files.keys())

        for i, author1 in enumerate(authors):
            for author2 in authors[i+1:]:
                common_files = contributor_files[author1] & contributor_files[author2]
                if common_files:
                    collaboration_score = len(common_files)
                    collaborations.append({
                        'authors': (author1, author2),
                        'common_files': len(common_files),
                        'collaboration_score': collaboration_score
                    })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ score
        collaborations.sort(key=lambda x: -x['collaboration_score'])

        return collaborations[:10]

    def calculate_bus_factor(self):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å bus factor (—Å–∫–æ–ª—å–∫–æ –ª—é–¥–µ–π –Ω—É–∂–Ω–æ –ø–æ—Ç–µ—Ä—è—Ç—å, —á—Ç–æ–±—ã –ø—Ä–æ–µ–∫—Ç –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è)

        –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–º–º–∏—Ç–æ–≤.

        Returns:
            dict: bus factor –º–µ—Ç—Ä–∏–∫–∏
        """
        total_commits = sum(stats['commits'] for stats in self.contributors.values())

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–æ–º–º–∏—Ç–æ–≤
        sorted_contributors = sorted(
            self.contributors.items(),
            key=lambda x: -x[1]['commits']
        )

        # –ù–∞–π—Ç–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤, –¥–µ–ª–∞—é—â–∏—Ö 50% –∫–æ–º–º–∏—Ç–æ–≤
        cumulative_commits = 0
        bus_factor = 0

        for author, stats in sorted_contributors:
            cumulative_commits += stats['commits']
            bus_factor += 1

            if cumulative_commits >= total_commits * 0.5:
                break

        # Bus factor < 3 - –∫—Ä–∏—Ç–∏—á–Ω–æ!
        risk_level = 'critical' if bus_factor < 3 else 'medium' if bus_factor < 5 else 'healthy'

        return {
            'bus_factor': bus_factor,
            'risk_level': risk_level,
            'top_contributors_percentage': round((cumulative_commits / total_commits) * 100, 1) if total_commits > 0 else 0
        }


class ChangeImpactAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π"""

    def __init__(self, changes, file_activity):
        self.changes = changes
        self.file_activity = file_activity

    def calculate_risk_score(self, commit):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å risk score –¥–ª—è –∫–æ–º–º–∏—Ç–∞

        –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞:
        - –ú–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        - –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ core —Ñ–∞–π–ª–∞—Ö
        - –ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª–æ–≤
        - –ë–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤

        Args:
            commit: –¥–∞–Ω–Ω—ã–µ –∫–æ–º–º–∏—Ç–∞

        Returns:
            dict: risk score –∏ –ø—Ä–∏—á–∏–Ω—ã
        """
        risk_score = 0
        risk_factors = []

        # –†–∞–∑–º–µ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π
        total_changes = commit['stats']['insertions'] + commit['stats']['deletions']

        if total_changes > 1000:
            risk_score += 40
            risk_factors.append('–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (>1000 —Å—Ç—Ä–æ–∫)')
        elif total_changes > 500:
            risk_score += 25
            risk_factors.append('–ë–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (>500 —Å—Ç—Ä–æ–∫)')
        elif total_changes > 200:
            risk_score += 10
            risk_factors.append('–°—Ä–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (>200 —Å—Ç—Ä–æ–∫)')

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        files_count = len(commit['files'])

        if files_count > 20:
            risk_score += 30
            risk_factors.append(f'–ú–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ ({files_count})')
        elif files_count > 10:
            risk_score += 15
            risk_factors.append(f'–£–º–µ—Ä–µ–Ω–Ω–æ –º–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ ({files_count})')

        # –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª–∞—Ö
        config_files = [f for f in commit['files'] if Path(f['path']).suffix in ['.json', '.yaml', '.yml', '.toml']]
        if config_files:
            risk_score += 20
            risk_factors.append(f'–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª–∞—Ö ({len(config_files)})')

        # –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ —á–∞—Å—Ç–æ –∏–∑–º–µ–Ω—è–µ–º—ã—Ö —Ñ–∞–π–ª–∞—Ö (core)
        core_files = [f for f in commit['files'] if self.file_activity.get(f['path'], 0) > 10]
        if core_files:
            risk_score += 15
            risk_factors.append(f'–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ core —Ñ–∞–π–ª–∞—Ö ({len(core_files)})')

        # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        deletions = [f for f in commit['files'] if f['status'] == 'D']
        if deletions:
            risk_score += 25
            risk_factors.append(f'–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ ({len(deletions)})')

        # Risk level
        if risk_score >= 80:
            risk_level = 'critical'
        elif risk_score >= 50:
            risk_level = 'high'
        elif risk_score >= 25:
            risk_level = 'medium'
        else:
            risk_level = 'low'

        return {
            'risk_score': min(risk_score, 100),
            'risk_level': risk_level,
            'risk_factors': risk_factors
        }

    def identify_hotspots(self, top_n=10):
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å hotspots (—Ñ–∞–π–ª—ã —Å —á–∞—Å—Ç—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏)

        Args:
            top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ hotspots

        Returns:
            list: hotspots —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        hotspots = []

        for file_path, change_count in sorted(self.file_activity.items(), key=lambda x: -x[1])[:top_n]:
            # –í—ã—á–∏—Å–ª–∏—Ç—å churn (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–æ –≤–æ –≤—Å–µ—Ö –∫–æ–º–º–∏—Ç–∞—Ö)
            total_churn = 0

            for commit in self.changes:
                for file_info in commit['files']:
                    if file_info['path'] == file_path:
                        total_churn += commit['stats']['insertions'] + commit['stats']['deletions']

            avg_churn = total_churn / change_count if change_count > 0 else 0

            hotspots.append({
                'file': file_path,
                'changes': change_count,
                'total_churn': total_churn,
                'avg_churn': round(avg_churn, 1)
            })

        return hotspots

    def analyze_change_velocity(self):
        """
        –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏

        Returns:
            dict: velocity —Ç—Ä–µ–Ω–¥—ã
        """
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –¥–∞—Ç–∞–º
        daily_stats = defaultdict(lambda: {'commits': 0, 'changes': 0})

        for commit in self.changes:
            date = commit['date']
            daily_stats[date]['commits'] += 1
            daily_stats[date]['changes'] += commit['stats']['insertions'] + commit['stats']['deletions']

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–∞—Ç–µ
        sorted_dates = sorted(daily_stats.keys())

        if len(sorted_dates) < 2:
            return {'trend': 'insufficient_data'}

        # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –ø–µ—Ä–≤—É—é –∏ –≤—Ç–æ—Ä—É—é –ø–æ–ª–æ–≤–∏–Ω—É
        mid_point = len(sorted_dates) // 2
        first_half = sorted_dates[:mid_point]
        second_half = sorted_dates[mid_point:]

        first_avg = sum(daily_stats[d]['commits'] for d in first_half) / len(first_half)
        second_avg = sum(daily_stats[d]['commits'] for d in second_half) / len(second_half)

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—Ä–µ–Ω–¥
        if second_avg > first_avg * 1.2:
            trend = 'accelerating'
        elif second_avg < first_avg * 0.8:
            trend = 'decelerating'
        else:
            trend = 'stable'

        return {
            'trend': trend,
            'first_half_avg': round(first_avg, 2),
            'second_half_avg': round(second_avg, 2),
            'change_percentage': round(((second_avg - first_avg) / first_avg * 100), 1) if first_avg > 0 else 0
        }


class CommitPatternAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–º–º–∏—Ç–æ–≤"""

    def __init__(self, changes):
        self.changes = changes

    def categorize_commit_message(self, message):
        """
        –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–∏—Ç –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç conventional commits pattern.

        Args:
            message: —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ–º–º–∏—Ç–∞

        Returns:
            str: –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        """
        message_lower = message.lower()

        # Conventional commits patterns
        patterns = {
            'feat': r'^(feat|feature|‚ú®)',
            'fix': r'^(fix|bugfix|üêõ)',
            'docs': r'^(docs|documentation|üìù)',
            'style': r'^(style|üíÑ)',
            'refactor': r'^(refactor|‚ôªÔ∏è)',
            'perf': r'^(perf|performance|‚ö°)',
            'test': r'^(test|‚úÖ)',
            'build': r'^(build|üë∑)',
            'ci': r'^(ci|üíö)',
            'chore': r'^(chore|üîß)',
        }

        for category, pattern in patterns.items():
            if re.search(pattern, message_lower):
                return category

        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –Ω–µ–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤
        if any(word in message_lower for word in ['add', 'create', 'implement']):
            return 'feat'
        elif any(word in message_lower for word in ['fix', 'resolve', 'correct']):
            return 'fix'
        elif any(word in message_lower for word in ['update', 'improve', 'enhance']):
            return 'improvement'
        elif any(word in message_lower for word in ['remove', 'delete', 'clean']):
            return 'cleanup'
        else:
            return 'other'

    def analyze_commit_types(self):
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –∫–æ–º–º–∏—Ç–æ–≤

        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        """
        type_stats = defaultdict(int)

        for commit in self.changes:
            commit_type = self.categorize_commit_message(commit['message'])
            type_stats[commit_type] += 1

        return dict(sorted(type_stats.items(), key=lambda x: -x[1]))

    def analyze_commit_sizes(self):
        """
        –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–æ–º–º–∏—Ç–æ–≤

        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        """
        sizes = {
            'tiny': 0,      # < 10 —Å—Ç—Ä–æ–∫
            'small': 0,     # 10-50 —Å—Ç—Ä–æ–∫
            'medium': 0,    # 50-200 —Å—Ç—Ä–æ–∫
            'large': 0,     # 200-500 —Å—Ç—Ä–æ–∫
            'huge': 0       # > 500 —Å—Ç—Ä–æ–∫
        }

        for commit in self.changes:
            total = commit['stats']['insertions'] + commit['stats']['deletions']

            if total < 10:
                sizes['tiny'] += 1
            elif total < 50:
                sizes['small'] += 1
            elif total < 200:
                sizes['medium'] += 1
            elif total < 500:
                sizes['large'] += 1
            else:
                sizes['huge'] += 1

        return sizes

    def find_message_patterns(self):
        """
        –ù–∞–π—Ç–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å–ª–æ–≤–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –∫–æ–º–º–∏—Ç–æ–≤

        Returns:
            list: —Ç–æ–ø —Å–ª–æ–≤
        """
        all_words = []

        stop_words = {
            'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can',
            'to', 'in', 'is', 'a', 'of', 'with', 'from', 'by'
        }

        for commit in self.changes:
            message = commit['message'].lower()
            # –£–¥–∞–ª–∏—Ç—å emoji –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
            message = re.sub(r'[^\w\s]', ' ', message)
            words = message.split()

            for word in words:
                if len(word) > 2 and word not in stop_words:
                    all_words.append(word)

        word_freq = Counter(all_words)
        return word_freq.most_common(15)

    def calculate_message_quality_score(self, message):
        """
        –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–æ–º–º–∏—Ç–∞

        Args:
            message: —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ–º–º–∏—Ç–∞

        Returns:
            int: score 0-100
        """
        score = 0

        # –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ 20-100 —Å–∏–º–≤–æ–ª–æ–≤)
        length = len(message)
        if 20 <= length <= 100:
            score += 30
        elif 10 <= length < 20 or 100 < length <= 150:
            score += 15

        # –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
        if message and message[0].isupper():
            score += 10

        # –°–æ–¥–µ—Ä–∂–∏—Ç –≥–ª–∞–≥–æ–ª –¥–µ–π—Å—Ç–≤–∏—è
        action_verbs = ['add', 'fix', 'update', 'remove', 'refactor', 'implement', 'improve', 'enhance']
        if any(verb in message.lower() for verb in action_verbs):
            score += 20

        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç conventional commits
        if re.match(r'^(feat|fix|docs|style|refactor|test|chore)(\(.+\))?: ', message.lower()):
            score += 30

        # –ù–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π (best practice)
        if message and message[-1] != '.':
            score += 10

        return min(score, 100)


class ActivityVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""

    def __init__(self, changes, contributors, hourly_activity, daily_activity):
        self.changes = changes
        self.contributors = contributors
        self.hourly_activity = hourly_activity
        self.daily_activity = daily_activity

    def generate_html_dashboard(self):
        """
        –°–æ–∑–¥–∞—Ç—å HTML dashboard —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

        Returns:
            str: HTML –∫–æ–Ω—Ç–µ–Ω—Ç
        """
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        total_commits = len(self.changes)
        total_contributors = len(self.contributors)

        # –¢–æ–ø –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä—ã
        top_contributors = sorted(
            self.contributors.items(),
            key=lambda x: -x[1]['commits']
        )[:10]

        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º
        hours = list(range(24))
        hourly_commits = [self.hourly_activity.get(h, 0) for h in hours]

        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30)
        sorted_dates = sorted(self.daily_activity.keys(), reverse=True)[:30]
        daily_commits = [self.daily_activity[d] for d in reversed(sorted_dates)]
        daily_labels = list(reversed(sorted_dates))

        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üìä Activity Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}

        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}

        h1 {{
            color: white;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 0 2px 10px rgba(0,0,0,0.3);
        }}

        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}

        .stat-card {{
            background: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            text-align: center;
        }}

        .stat-value {{
            font-size: 3em;
            font-weight: bold;
            color: #667eea;
            margin-bottom: 10px;
        }}

        .stat-label {{
            color: #666;
            font-size: 1.1em;
        }}

        .chart-container {{
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            margin-bottom: 20px;
        }}

        .chart-title {{
            font-size: 1.5em;
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
        }}

        .contributors-list {{
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }}

        .contributor-item {{
            padding: 15px;
            border-bottom: 1px solid #eee;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}

        .contributor-item:last-child {{
            border-bottom: none;
        }}

        .contributor-name {{
            font-weight: 600;
            font-size: 1.1em;
        }}

        .contributor-stats {{
            color: #666;
            font-size: 0.95em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üìä Activity Dashboard</h1>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{total_commits}</div>
                <div class="stat-label">–ö–æ–º–º–∏—Ç–æ–≤</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{total_contributors}</div>
                <div class="stat-label">–ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{sum(c['stats']['insertions'] for c in self.changes):,}</div>
                <div class="stat-label">–î–æ–±–∞–≤–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{sum(c['stats']['deletions'] for c in self.changes):,}</div>
                <div class="stat-label">–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫</div>
            </div>
        </div>

        <div class="chart-container">
            <div class="chart-title">üìà –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º</div>
            <canvas id="dailyChart"></canvas>
        </div>

        <div class="chart-container">
            <div class="chart-title">‚è∞ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º</div>
            <canvas id="hourlyChart"></canvas>
        </div>

        <div class="contributors-list">
            <div class="chart-title">üë• –¢–æ–ø –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤</div>
            {"".join(f'''
            <div class="contributor-item">
                <div class="contributor-name">{i}. {author}</div>
                <div class="contributor-stats">
                    {stats['commits']} –∫–æ–º–º–∏—Ç–æ–≤ | +{stats['insertions']:,} / -{stats['deletions']:,} —Å—Ç—Ä–æ–∫
                </div>
            </div>
            ''' for i, (author, stats) in enumerate(top_contributors, 1))}
        </div>
    </div>

    <script>
        // Daily activity chart
        const dailyCtx = document.getElementById('dailyChart').getContext('2d');
        new Chart(dailyCtx, {{
            type: 'line',
            data: {{
                labels: {json.dumps(daily_labels)},
                datasets: [{{
                    label: '–ö–æ–º–º–∏—Ç–æ–≤',
                    data: {daily_commits},
                    borderColor: '#667eea',
                    backgroundColor: 'rgba(102, 126, 234, 0.1)',
                    tension: 0.4,
                    fill: true
                }}]
            }},
            options: {{
                responsive: true,
                plugins: {{
                    legend: {{
                        display: false
                    }}
                }},
                scales: {{
                    y: {{
                        beginAtZero: true
                    }}
                }}
            }}
        }});

        // Hourly activity chart
        const hourlyCtx = document.getElementById('hourlyChart').getContext('2d');
        new Chart(hourlyCtx, {{
            type: 'bar',
            data: {{
                labels: {json.dumps([f"{h:02d}:00" for h in hours])},
                datasets: [{{
                    label: '–ö–æ–º–º–∏—Ç–æ–≤',
                    data: {hourly_commits},
                    backgroundColor: '#764ba2'
                }}]
            }},
            options: {{
                responsive: true,
                plugins: {{
                    legend: {{
                        display: false
                    }}
                }},
                scales: {{
                    y: {{
                        beginAtZero: true
                    }}
                }}
            }}
        }});
    </script>
</body>
</html>"""

        return html


class AdvancedRecentChanges:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π"""

    def __init__(self, root_dir=".", days=30):
        self.root_dir = Path(root_dir)
        self.days = days

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.changes = []
        self.contributors = defaultdict(lambda: {
            'commits': 0,
            'files_changed': 0,
            'insertions': 0,
            'deletions': 0,
            'dates': []
        })
        self.file_activity = defaultdict(int)
        self.hourly_activity = defaultdict(int)
        self.daily_activity = defaultdict(int)

    def get_git_log(self):
        """–ü–æ–ª—É—á–∏—Ç—å git –ª–æ–≥ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        since_date = (datetime.now() - timedelta(days=self.days)).strftime('%Y-%m-%d')

        try:
            result = subprocess.run(
                ['git', 'log', f'--since={since_date}', '--name-status', '--numstat',
                 '--pretty=format:%H|%an|%ae|%ad|%s|%ai', '--date=short'],
                cwd=self.root_dir,
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                return result.stdout
        except:
            pass

        return None

    def parse_log(self, log_output):
        """–ü–∞—Ä—Å–∏–Ω–≥ git –ª–æ–≥–∞ —Å numstat"""
        changes = []
        current_commit = None

        for line in log_output.split('\n'):
            if '|' in line and not line.startswith(('A\t', 'M\t', 'D\t')) and not '\t' in line[:5]:
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–º–∏—Ç–µ
                parts = line.split('|')
                if len(parts) == 6:
                    commit_hash = parts[0]
                    author = parts[1]
                    email = parts[2]
                    date = parts[3]
                    message = parts[4]
                    full_date = parts[5]

                    # –ò–∑–≤–ª–µ—á—å —á–∞—Å –∏–∑ full_date
                    try:
                        dt = datetime.fromisoformat(full_date.replace(' ', 'T').split('+')[0].split('-')[0].strip())
                        hour = dt.hour
                    except:
                        hour = 12

                    current_commit = {
                        'hash': commit_hash,
                        'author': author,
                        'email': email,
                        'date': date,
                        'hour': hour,
                        'message': message,
                        'files': [],
                        'stats': {'insertions': 0, 'deletions': 0}
                    }
                    changes.append(current_commit)

                    # Contributor stats
                    self.contributors[author]['commits'] += 1
                    self.contributors[author]['dates'].append(date)

                    # Time stats
                    self.hourly_activity[hour] += 1
                    self.daily_activity[date] += 1

            elif current_commit:
                # numstat format: insertions deletions filename
                if '\t' in line:
                    parts = line.split('\t')

                    if len(parts) == 3:
                        ins, dels, filename = parts

                        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ numstat
                        try:
                            insertions = int(ins) if ins != '-' else 0
                            deletions = int(dels) if dels != '-' else 0

                            current_commit['stats']['insertions'] += insertions
                            current_commit['stats']['deletions'] += deletions

                            self.contributors[current_commit['author']]['insertions'] += insertions
                            self.contributors[current_commit['author']]['deletions'] += deletions

                            # File activity
                            self.file_activity[filename] += 1
                            self.contributors[current_commit['author']]['files_changed'] += 1

                        except ValueError:
                            pass

                # name-status format
                if line.startswith(('A\t', 'M\t', 'D\t')):
                    status, file_path = line.split('\t', 1)
                    current_commit['files'].append({
                        'status': status,
                        'path': file_path
                    })

        return changes

    def categorize_file(self, file_path):
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª"""
        path = Path(file_path)

        if path.suffix == '.md':
            if 'knowledge' in path.parts:
                return 'docs'
            else:
                return 'meta'

        elif path.suffix == '.py':
            if 'tools' in path.parts:
                return 'tools'
            else:
                return 'code'

        elif path.suffix in ['.json', '.yaml', '.yml']:
            return 'config'

        elif path.suffix in ['.sh', '.bash']:
            return 'scripts'

        else:
            return 'other'

    def analyze_categories(self):
        """–ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        category_stats = defaultdict(lambda: {
            'commits': 0,
            'files': 0,
            'insertions': 0,
            'deletions': 0
        })

        for change in self.changes:
            for file_info in change['files']:
                category = self.categorize_file(file_info['path'])

                category_stats[category]['files'] += 1

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å stats –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (—É–ø—Ä–æ—â—ë–Ω–Ω–æ - –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–º–º–∏—Ç–∞)
            if change['files']:
                main_category = self.categorize_file(change['files'][0]['path'])
                category_stats[main_category]['commits'] += 1
                category_stats[main_category]['insertions'] += change['stats']['insertions']
                category_stats[main_category]['deletions'] += change['stats']['deletions']

        return dict(category_stats)

    def calculate_velocity(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å velocity metrics"""
        if not self.changes:
            return {}

        total_commits = len(self.changes)
        total_insertions = sum(c['stats']['insertions'] for c in self.changes)
        total_deletions = sum(c['stats']['deletions'] for c in self.changes)
        total_changes = total_insertions + total_deletions

        avg_commits_per_day = total_commits / self.days if self.days > 0 else 0
        avg_changes_per_day = total_changes / self.days if self.days > 0 else 0

        return {
            'total_commits': total_commits,
            'total_insertions': total_insertions,
            'total_deletions': total_deletions,
            'total_changes': total_changes,
            'avg_commits_per_day': round(avg_commits_per_day, 2),
            'avg_changes_per_day': round(avg_changes_per_day, 1),
            'contributors_count': len(self.contributors)
        }

    def generate_activity_heatmap(self):
        """–°–æ–∑–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è heatmap (–¥–µ–Ω—å x —á–∞—Å)"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - —Ç–æ–ª—å–∫–æ —á–∞—Å—ã
        hours = list(range(24))
        activity = [self.hourly_activity.get(h, 0) for h in hours]

        return {
            'hours': hours,
            'activity': activity
        }

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç"""
        lines = []
        lines.append(f"# üìÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–∑–∞ {self.days} –¥–Ω–µ–π)\n\n")

        # Velocity metrics
        velocity = self.calculate_velocity()

        lines.append("## üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        lines.append(f"- **–ö–æ–º–º–∏—Ç–æ–≤**: {velocity['total_commits']}\n")
        lines.append(f"- **–í—Å—Ç–∞–≤–æ–∫ (insertions)**: +{velocity['total_insertions']:,}\n")
        lines.append(f"- **–£–¥–∞–ª–µ–Ω–∏–π (deletions)**: -{velocity['total_deletions']:,}\n")
        lines.append(f"- **–í—Å–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π**: {velocity['total_changes']:,}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω–µ–µ –∫–æ–º–º–∏—Ç–æ–≤/–¥–µ–Ω—å**: {velocity['avg_commits_per_day']}\n")
        lines.append(f"- **–°—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π/–¥–µ–Ω—å**: {velocity['avg_changes_per_day']:,.0f}\n")
        lines.append(f"- **–ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤**: {velocity['contributors_count']}\n\n")

        # Contributors ranking
        lines.append("## üë• –¢–æ–ø –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤\n\n")

        sorted_contributors = sorted(
            self.contributors.items(),
            key=lambda x: -(x[1]['commits'] + x[1]['insertions'] / 10)
        )

        for i, (author, stats) in enumerate(sorted_contributors[:10], 1):
            total_lines = stats['insertions'] + stats['deletions']

            lines.append(f"### {i}. {author}\n\n")
            lines.append(f"- **–ö–æ–º–º–∏—Ç–æ–≤**: {stats['commits']}\n")
            lines.append(f"- **–§–∞–π–ª–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–æ**: {stats['files_changed']}\n")
            lines.append(f"- **–°—Ç—Ä–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–æ**: +{stats['insertions']:,}\n")
            lines.append(f"- **–°—Ç—Ä–æ–∫ —É–¥–∞–ª–µ–Ω–æ**: -{stats['deletions']:,}\n")
            lines.append(f"- **–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫**: {total_lines:,}\n\n")

        # Most active files
        lines.append("## üìÅ –°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n")

        top_files = sorted(self.file_activity.items(), key=lambda x: -x[1])[:15]

        for file_path, count in top_files:
            category = self.categorize_file(file_path)
            lines.append(f"- **{file_path}**: {count} –∏–∑–º–µ–Ω–µ–Ω–∏–π ({category})\n")

        lines.append("\n")

        # Categories
        category_stats = self.analyze_categories()

        if category_stats:
            lines.append("## üóÇÔ∏è –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n")

            for category, stats in sorted(category_stats.items(), key=lambda x: -x[1]['commits']):
                lines.append(f"### {category.title()}\n\n")
                lines.append(f"- –ö–æ–º–º–∏—Ç–æ–≤: {stats['commits']}\n")
                lines.append(f"- –§–∞–π–ª–æ–≤: {stats['files']}\n")
                lines.append(f"- –ò–∑–º–µ–Ω–µ–Ω–∏–π: +{stats['insertions']:,} / -{stats['deletions']:,}\n\n")

        # Activity heatmap (text representation)
        heatmap = self.generate_activity_heatmap()

        lines.append("## ‚è∞ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º\n\n")
        lines.append("```\n")

        max_activity = max(heatmap['activity']) if heatmap['activity'] else 1

        for hour, count in zip(heatmap['hours'], heatmap['activity']):
            bar_length = int((count / max_activity * 20)) if max_activity > 0 else 0
            bar = '‚ñà' * bar_length
            lines.append(f"{hour:02d}:00 {bar} {count}\n")

        lines.append("```\n\n")

        # Recent commits (grouped by date)
        lines.append("## üìù –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∫–æ–º–º–∏—Ç—ã\n\n")

        by_date = defaultdict(list)
        for change in self.changes:
            by_date[change['date']].append(change)

        for date in sorted(by_date.keys(), reverse=True)[:7]:
            commits = by_date[date]
            total_changes = sum(c['stats']['insertions'] + c['stats']['deletions'] for c in commits)

            lines.append(f"### {date} ({len(commits)} –∫–æ–º–º–∏—Ç–æ–≤, {total_changes:,} –∏–∑–º–µ–Ω–µ–Ω–∏–π)\n\n")

            for commit in commits[:5]:
                lines.append(f"#### {commit['message']}\n\n")
                lines.append(f"- **–ê–≤—Ç–æ—Ä**: {commit['author']}\n")
                lines.append(f"- **–•—ç—à**: `{commit['hash'][:7]}`\n")
                lines.append(f"- **–ò–∑–º–µ–Ω–µ–Ω–∏—è**: +{commit['stats']['insertions']} / -{commit['stats']['deletions']}\n")

                if commit['files']:
                    lines.append(f"- **–§–∞–π–ª–æ–≤**: {len(commit['files'])}\n")

                lines.append("\n")

            if len(commits) > 5:
                lines.append(f"_...–∏ –µ—â—ë {len(commits) - 5} –∫–æ–º–º–∏—Ç–æ–≤_\n\n")

        output_file = self.root_dir / "ADVANCED_RECENT_CHANGES.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        print(f"‚úÖ –û—Ç—á—ë—Ç: {output_file}")

    def generate_rss_feed(self):
        """–°–æ–∑–¥–∞—Ç—å RSS feed"""
        rss = ET.Element('rss', version='2.0')
        channel = ET.SubElement(rss, 'channel')

        ET.SubElement(channel, 'title').text = 'Knowledge Base - Recent Changes'
        ET.SubElement(channel, 'link').text = 'https://example.com'
        ET.SubElement(channel, 'description').text = f'Last {self.days} days of changes'
        ET.SubElement(channel, 'language').text = 'ru'

        # –î–æ–±–∞–≤–∏—Ç—å items (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –∫–æ–º–º–∏—Ç–æ–≤)
        for change in self.changes[:20]:
            item = ET.SubElement(channel, 'item')

            title = f"{change['message']} by {change['author']}"
            ET.SubElement(item, 'title').text = title

            description = f"Author: {change['author']}<br/>"
            description += f"Files: {len(change['files'])}<br/>"
            description += f"Changes: +{change['stats']['insertions']} -{change['stats']['deletions']}"

            ET.SubElement(item, 'description').text = description
            ET.SubElement(item, 'author').text = change['email']
            ET.SubElement(item, 'pubDate').text = change['date']
            ET.SubElement(item, 'guid').text = change['hash']

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
        tree = ET.ElementTree(rss)
        output_file = self.root_dir / "recent_changes.rss"

        tree.write(output_file, encoding='utf-8', xml_declaration=True)

        print(f"‚úÖ RSS feed: {output_file}")

    def export_json(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON"""
        data = {
            'period_days': self.days,
            'generated_at': datetime.now().isoformat(),
            'velocity': self.calculate_velocity(),
            'contributors': {
                author: {
                    **stats,
                    'dates': list(set(stats['dates']))  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–∞—Ç—ã
                }
                for author, stats in self.contributors.items()
            },
            'category_stats': self.analyze_categories(),
            'activity_heatmap': self.generate_activity_heatmap(),
            'recent_commits': [
                {
                    'hash': c['hash'],
                    'author': c['author'],
                    'date': c['date'],
                    'message': c['message'],
                    'stats': c['stats'],
                    'files_count': len(c['files'])
                }
                for c in self.changes[:50]
            ]
        }

        output_file = self.root_dir / "recent_changes.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='üîç Advanced Recent Changes - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s --days 30                     # –ë–∞–∑–æ–≤—ã–π –æ—Ç—á—ë—Ç –∑–∞ 30 –¥–Ω–µ–π
  %(prog)s --html                        # HTML dashboard —Å Chart.js
  %(prog)s --contributors                # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤
  %(prog)s --impact                      # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∏ —Ä–∏—Å–∫-—Å–∫–æ—Ä–∏–Ω–≥
  %(prog)s --patterns                    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–º–º–∏—Ç–æ–≤
  %(prog)s --bus-factor                  # –í—ã—á–∏—Å–ª–∏—Ç—å bus factor
  %(prog)s --hotspots 15                 # –¢–æ–ø 15 hotspots
  %(prog)s --velocity                    # –ê–Ω–∞–ª–∏–∑ velocity —Ç—Ä–µ–Ω–¥–∞
  %(prog)s --all --days 60               # –í—Å–µ –∞–Ω–∞–ª–∏–∑—ã –∑–∞ 60 –¥–Ω–µ–π
  %(prog)s --json --rss                  # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON –∏ RSS

–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
  ‚Ä¢ Contributor Analysis: –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–±–æ—Ç—ã, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è
  ‚Ä¢ Impact Analysis: risk scoring, hotspots, velocity
  ‚Ä¢ Pattern Analysis: conventional commits, message quality
  ‚Ä¢ Activity Visualization: –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π HTML dashboard —Å Chart.js
        """
    )

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('-d', '--days', type=int, default=30,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)')
    parser.add_argument('--path', type=str, default='.',
                       help='–ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)')

    # –ù–æ–≤—ã–µ –∞–Ω–∞–ª–∏–∑—ã
    parser.add_argument('--html', action='store_true',
                       help='üé® –°–æ–∑–¥–∞—Ç—å HTML dashboard —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏')
    parser.add_argument('--contributors', action='store_true',
                       help='üë• –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ (–ø–∞—Ç—Ç–µ—Ä–Ω—ã, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)')
    parser.add_argument('--impact', action='store_true',
                       help='üí• –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π (risk scoring, hotspots)')
    parser.add_argument('--patterns', action='store_true',
                       help='üìã –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–º–º–∏—Ç–æ–≤ (conventional commits, quality)')
    parser.add_argument('--bus-factor', action='store_true',
                       help='üöå –í—ã—á–∏—Å–ª–∏—Ç—å bus factor –∏ —Ä–∏—Å–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞')
    parser.add_argument('--hotspots', type=int, metavar='N',
                       help='üî• –ù–∞–π—Ç–∏ —Ç–æ–ø N hotspots (—á–∞—Å—Ç–æ –∏–∑–º–µ–Ω—è–µ–º—ã–µ —Ñ–∞–π–ª—ã)')
    parser.add_argument('--velocity', action='store_true',
                       help='üìà –ê–Ω–∞–ª–∏–∑ velocity (—Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏)')
    parser.add_argument('--author', type=str, metavar='NAME',
                       help='üîé –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–∞')

    # –≠–∫—Å–ø–æ—Ä—Ç
    parser.add_argument('--json', action='store_true',
                       help='üíæ –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON')
    parser.add_argument('--rss', action='store_true',
                       help='üì° –°–æ–∑–¥–∞—Ç—å RSS feed')
    parser.add_argument('--csv', action='store_true',
                       help='üìä –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ CSV')

    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ
    parser.add_argument('--all', action='store_true',
                       help='üéØ –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã')

    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å root_dir
    if args.path == '.':
        script_dir = Path(__file__).parent
        root_dir = script_dir.parent
    else:
        root_dir = Path(args.path)

    # –°–æ–∑–¥–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π analyzer
    analyzer = AdvancedRecentChanges(root_dir, days=args.days)

    print(f"üìÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {args.days} –¥–Ω–µ–π...")
    print(f"üìÇ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {root_dir}\n")

    # –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    log_output = analyzer.get_git_log()

    if not log_output:
        print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å git –ª–æ–≥")
        return

    analyzer.changes = analyzer.parse_log(log_output)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–º–∏—Ç–æ–≤: {len(analyzer.changes)}")
    print(f"‚úÖ –ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤: {len(analyzer.contributors)}")
    print(f"‚úÖ –§–∞–π–ª–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–æ: {len(analyzer.file_activity)}\n")

    # –ë–∞–∑–æ–≤—ã–π –æ—Ç—á—ë—Ç –≤—Å–µ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è
    analyzer.generate_report()

    # --all –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã
    if args.all:
        args.html = True
        args.contributors = True
        args.impact = True
        args.patterns = True
        args.bus_factor = True
        args.hotspots = 15
        args.velocity = True
        args.json = True
        args.rss = True
        args.csv = True

    # HTML Dashboard
    if args.html:
        print("\nüé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML dashboard...")
        visualizer = ActivityVisualizer(
            analyzer.changes,
            dict(analyzer.contributors),
            dict(analyzer.hourly_activity),
            dict(analyzer.daily_activity)
        )
        html_content = visualizer.generate_html_dashboard()

        html_file = root_dir / "activity_dashboard.html"
        html_file.write_text(html_content, encoding='utf-8')
        print(f"‚úÖ HTML dashboard: {html_file}")

    # Contributor Analysis
    if args.contributors or args.author:
        print("\nüë• –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤...")
        contributor_analyzer = ContributorAnalyzer(
            dict(analyzer.contributors),
            analyzer.changes
        )

        if args.author:
            # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
            pattern = contributor_analyzer.analyze_contributor_patterns(args.author)
            spec = contributor_analyzer.calculate_specialization(args.author)

            if pattern:
                print(f"\nüìä –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–±–æ—Ç—ã: {args.author}")
                print(f"   –¢–∏–ø –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–∞: {pattern['contributor_type']}")
                print(f"   –°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Å: {pattern['most_active_hour']}:00")
                print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–º–∏—Ç–∞: {pattern['avg_commit_size']} —Å—Ç—Ä–æ–∫")
                print(f"   –ß–∞—Å—Ç–æ—Ç–∞ –∫–æ–º–º–∏—Ç–æ–≤: {pattern['commit_frequency']:.2f} –∫–æ–º–º–∏—Ç–æ–≤/–¥–µ–Ω—å")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {pattern['unique_days']}")

                if spec:
                    print(f"\nüéØ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:")
                    for category, percentage in spec.items():
                        print(f"   {category}: {percentage}%")
            else:
                print(f"‚ùå –ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä '{args.author}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        else:
            # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑
            print("\nüîç –¢–æ–ø –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏:")
            top_contributors = sorted(
                analyzer.contributors.items(),
                key=lambda x: -x[1]['commits']
            )[:5]

            for author, stats in top_contributors:
                pattern = contributor_analyzer.analyze_contributor_patterns(author)
                if pattern:
                    print(f"\n   {author}:")
                    print(f"   - –ö–æ–º–º–∏—Ç–æ–≤: {stats['commits']}")
                    print(f"   - –¢–∏–ø: {pattern['contributor_type']}")
                    print(f"   - –ê–∫—Ç–∏–≤–µ–Ω –≤: {pattern['most_active_hour']}:00")

            # –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è
            collaborations = contributor_analyzer.find_collaboration_pairs()
            if collaborations:
                print(f"\nü§ù –¢–æ–ø –ø–∞—Ä –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–æ–≤:")
                for collab in collaborations[:5]:
                    print(f"   {collab['authors'][0]} ‚Üî {collab['authors'][1]}: {collab['common_files']} –æ–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤")

    # Bus Factor
    if args.bus_factor:
        print("\nüöå Bus Factor Analysis...")
        contributor_analyzer = ContributorAnalyzer(
            dict(analyzer.contributors),
            analyzer.changes
        )
        bus_factor = contributor_analyzer.calculate_bus_factor()

        print(f"   Bus Factor: {bus_factor['bus_factor']}")
        print(f"   Risk Level: {bus_factor['risk_level'].upper()}")
        print(f"   –¢–æ–ø {bus_factor['bus_factor']} –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ –¥–µ–ª–∞—é—Ç {bus_factor['top_contributors_percentage']}% –∫–æ–º–º–∏—Ç–æ–≤")

        if bus_factor['risk_level'] == 'critical':
            print("   ‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ò–°–ö: –ü—Ä–æ–µ–∫—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ–≥–æ —á–∏—Å–ª–∞ –ª—é–¥–µ–π!")
        elif bus_factor['risk_level'] == 'medium':
            print("   ‚ö° –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∏—Å–∫: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∫–æ–º–∞–Ω–¥—É")
        else:
            print("   ‚úÖ –ó–¥–æ—Ä–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")

    # Impact Analysis
    if args.impact:
        print("\nüí• Impact Analysis...")
        impact_analyzer = ChangeImpactAnalyzer(
            analyzer.changes,
            dict(analyzer.file_activity)
        )

        # Risky commits
        risky_commits = []
        for commit in analyzer.changes:
            risk = impact_analyzer.calculate_risk_score(commit)
            if risk['risk_level'] in ['high', 'critical']:
                risky_commits.append((commit, risk))

        if risky_commits:
            print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(risky_commits)} –∫–æ–º–º–∏—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º:")
            for commit, risk in sorted(risky_commits, key=lambda x: -x[1]['risk_score'])[:5]:
                print(f"\n   [{commit['hash'][:7]}] {commit['message'][:60]}")
                print(f"   Risk Score: {risk['risk_score']}/100 ({risk['risk_level'].upper()})")
                print(f"   –§–∞–∫—Ç–æ—Ä—ã: {', '.join(risk['risk_factors'][:3])}")

        # Hotspots
        if args.hotspots:
            hotspots = impact_analyzer.identify_hotspots(args.hotspots)
            print(f"\nüî• –¢–æ–ø {len(hotspots)} hotspots:")
            for spot in hotspots:
                print(f"   {spot['file']}")
                print(f"      –ò–∑–º–µ–Ω–µ–Ω–∏–π: {spot['changes']}, Churn: {spot['total_churn']:,} —Å—Ç—Ä–æ–∫ (avg: {spot['avg_churn']:.1f})")

    # Hotspots (–æ—Ç–¥–µ–ª—å–Ω–æ)
    if args.hotspots and not args.impact:
        print(f"\nüî• Hotspot Analysis (—Ç–æ–ø {args.hotspots})...")
        impact_analyzer = ChangeImpactAnalyzer(
            analyzer.changes,
            dict(analyzer.file_activity)
        )
        hotspots = impact_analyzer.identify_hotspots(args.hotspots)

        for i, spot in enumerate(hotspots, 1):
            print(f"{i}. {spot['file']}")
            print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–π: {spot['changes']}, Total churn: {spot['total_churn']:,}, Avg: {spot['avg_churn']:.1f}")

    # Velocity Analysis
    if args.velocity:
        print("\nüìà Velocity Analysis...")
        impact_analyzer = ChangeImpactAnalyzer(
            analyzer.changes,
            dict(analyzer.file_activity)
        )
        velocity_trend = impact_analyzer.analyze_change_velocity()

        if velocity_trend['trend'] != 'insufficient_data':
            print(f"   –¢—Ä–µ–Ω–¥: {velocity_trend['trend'].upper()}")
            print(f"   –ü–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –ø–µ—Ä–∏–æ–¥–∞: {velocity_trend['first_half_avg']:.2f} –∫–æ–º–º–∏—Ç–æ–≤/–¥–µ–Ω—å")
            print(f"   –í—Ç–æ—Ä–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –ø–µ—Ä–∏–æ–¥–∞: {velocity_trend['second_half_avg']:.2f} –∫–æ–º–º–∏—Ç–æ–≤/–¥–µ–Ω—å")
            print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {velocity_trend['change_percentage']:+.1f}%")

            if velocity_trend['trend'] == 'accelerating':
                print("   üìà –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞—Å—Ç—ë—Ç!")
            elif velocity_trend['trend'] == 'decelerating':
                print("   üìâ –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å–Ω–∏–∂–∞–µ—Ç—Å—è")
            else:
                print("   ‚û°Ô∏è  –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏")
        else:
            print("   ‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞")

    # Pattern Analysis
    if args.patterns:
        print("\nüìã Commit Pattern Analysis...")
        pattern_analyzer = CommitPatternAnalyzer(analyzer.changes)

        # –¢–∏–ø—ã –∫–æ–º–º–∏—Ç–æ–≤
        commit_types = pattern_analyzer.analyze_commit_types()
        print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –∫–æ–º–º–∏—Ç–æ–≤:")
        for commit_type, count in list(commit_types.items())[:8]:
            percentage = (count / len(analyzer.changes)) * 100
            print(f"   {commit_type}: {count} ({percentage:.1f}%)")

        # –†–∞–∑–º–µ—Ä—ã –∫–æ–º–º–∏—Ç–æ–≤
        commit_sizes = pattern_analyzer.analyze_commit_sizes()
        print("\nüìè –†–∞–∑–º–µ—Ä—ã –∫–æ–º–º–∏—Ç–æ–≤:")
        for size_cat, count in commit_sizes.items():
            percentage = (count / len(analyzer.changes)) * 100
            print(f"   {size_cat}: {count} ({percentage:.1f}%)")

        # –ß–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        top_words = pattern_analyzer.find_message_patterns()
        print("\nüî§ –¢–æ–ø —Å–ª–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –∫–æ–º–º–∏—Ç–æ–≤:")
        for word, freq in top_words[:10]:
            print(f"   {word}: {freq}")

        # Quality scoring (sample)
        quality_scores = [
            pattern_analyzer.calculate_message_quality_score(c['message'])
            for c in analyzer.changes
        ]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        print(f"\n‚ú® –°—Ä–µ–¥–Ω–∏–π quality score —Å–æ–æ–±—â–µ–Ω–∏–π: {avg_quality:.1f}/100")

    # Export JSON
    if args.json:
        analyzer.export_json()

    # Export RSS
    if args.rss:
        analyzer.generate_rss_feed()

    # Export CSV
    if args.csv:
        print("\nüìä –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV...")
        csv_file = root_dir / "recent_changes.csv"

        with open(csv_file, 'w', encoding='utf-8') as f:
            f.write("Author,Commits,Files Changed,Insertions,Deletions,Total Changes\n")
            for author, stats in sorted(analyzer.contributors.items(), key=lambda x: -x[1]['commits']):
                f.write(f"{author},{stats['commits']},{stats['files_changed']},{stats['insertions']},{stats['deletions']},{stats['insertions'] + stats['deletions']}\n")

        print(f"‚úÖ CSV: {csv_file}")

    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")


if __name__ == "__main__":
    main()
