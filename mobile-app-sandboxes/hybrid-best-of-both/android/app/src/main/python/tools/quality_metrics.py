#!/usr/bin/env python3
"""
Quality Metrics - –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π
–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤—É –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤

–ú–µ—Ç—Ä–∏–∫–∏:
- Completeness (–ø–æ–ª–Ω–æ—Ç–∞): –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
- Structure (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞): –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Å–ø–∏—Å–∫–∏
- Links (—Å—Å—ã–ª–∫–∏): –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∏ –≤–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏
- Examples (–ø—Ä–∏–º–µ—Ä—ã): –∫–æ–¥, —Ç–∞–±–ª–∏—Ü—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- Readability (—á–∏—Ç–∞–µ–º–æ—Å—Ç—å): –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–ª–æ–∂–Ω–æ—Å—Ç—å
- Freshness (—Å–≤–µ–∂–µ—Å—Ç—å): –¥–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
"""

from pathlib import Path
import yaml
import csv
import json
from typing import List, Dict
from collections import Counter
import re
from datetime import datetime, timedelta
from collections import defaultdict


class QualityAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π
    """

    def __init__(self, root_dir="."):
        self.root_dir = Path(root_dir)
        self.knowledge_dir = self.root_dir / "knowledge"

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –≤ frontmatter
        self.required_fields = ['title', 'date', 'category', 'tags', 'status']

        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–ª—è
        self.recommended_fields = ['author', 'source', 'subcategory', 'related']

    def extract_frontmatter_and_content(self, file_path):
        """–ò–∑–≤–ª–µ—á—å frontmatter –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)', content, re.DOTALL)
            if match:
                fm = yaml.safe_load(match.group(1))
                body = match.group(2)
                return fm, body
        except:
            pass

        return None, None

    def analyze_completeness(self, frontmatter):
        """
        –û—Ü–µ–Ω–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (0-100)
        """
        if not frontmatter:
            return 0

        score = 0
        total_points = 100

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (60 –±–∞–ª–ª–æ–≤)
        required_points = 60
        field_points = required_points / len(self.required_fields)

        for field in self.required_fields:
            if field in frontmatter and frontmatter[field]:
                score += field_points

        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–ª—è (30 –±–∞–ª–ª–æ–≤)
        recommended_points = 30
        field_points = recommended_points / len(self.recommended_fields)

        for field in self.recommended_fields:
            if field in frontmatter and frontmatter[field]:
                score += field_points

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (10 –±–∞–ª–ª–æ–≤)
        bonus_fields = ['dewey', 'pagerank', 'reading_time', 'difficulty']
        bonus_count = sum(1 for f in bonus_fields if f in frontmatter)
        score += min(10, bonus_count * 2.5)

        return min(100, round(score))

    def analyze_structure(self, content):
        """
        –û—Ü–µ–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (0-100)
        """
        if not content:
            return 0

        score = 0

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (30 –±–∞–ª–ª–æ–≤)
        h1_count = len(re.findall(r'^# ', content, re.MULTILINE))
        h2_count = len(re.findall(r'^## ', content, re.MULTILINE))
        h3_count = len(re.findall(r'^### ', content, re.MULTILINE))

        # –•–æ—Ä–æ—à–æ: –Ω–µ—Ç h1 (–æ–Ω –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ), –µ—Å—Ç—å h2 –∏ h3
        if h1_count == 0 and h2_count >= 2:
            score += 30
        elif h2_count >= 1:
            score += 15

        # –°–ø–∏—Å–∫–∏ (20 –±–∞–ª–ª–æ–≤)
        lists = re.findall(r'^\s*[\*\-\+] ', content, re.MULTILINE)
        if len(lists) >= 5:
            score += 20
        elif len(lists) >= 2:
            score += 10

        # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã (—Ä–∞–∑—É–º–Ω–∞—è –¥–ª–∏–Ω–∞) (20 –±–∞–ª–ª–æ–≤)
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        if paragraphs:
            avg_para_length = sum(len(p.split()) for p in paragraphs) / len(paragraphs)
            # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ: 40-100 —Å–ª–æ–≤ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ
            if 40 <= avg_para_length <= 100:
                score += 20
            elif 20 <= avg_para_length <= 150:
                score += 10

        # –¢–∞–±–ª–∏—Ü—ã (15 –±–∞–ª–ª–æ–≤)
        tables = re.findall(r'^\|', content, re.MULTILINE)
        if tables:
            score += 15

        # –¶–∏—Ç–∞—Ç—ã (15 –±–∞–ª–ª–æ–≤)
        quotes = re.findall(r'^> ', content, re.MULTILINE)
        if quotes:
            score += 15

        return min(100, score)

    def analyze_links(self, content):
        """
        –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ (0-100)
        """
        if not content:
            return 0

        score = 0

        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ (40 –±–∞–ª–ª–æ–≤)
        internal_links = re.findall(r'\[([^\]]+)\]\(([^h][^\)]+)\)', content)
        if len(internal_links) >= 3:
            score += 40
        elif len(internal_links) >= 1:
            score += 20

        # –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ (30 –±–∞–ª–ª–æ–≤)
        external_links = re.findall(r'\[([^\]]+)\]\((https?://[^\)]+)\)', content)
        if len(external_links) >= 2:
            score += 30
        elif len(external_links) >= 1:
            score += 15

        # –Ø–∫–æ—Ä–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (15 –±–∞–ª–ª–æ–≤)
        anchors = re.findall(r'\[([^\]]+)\]\(#[^\)]+\)', content)
        if anchors:
            score += 15

        # –°—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (15 –±–∞–ª–ª–æ–≤)
        images = re.findall(r'!\[([^\]]*)\]\([^\)]+\)', content)
        if images:
            score += 15

        return min(100, score)

    def analyze_examples(self, content):
        """
        –û—Ü–µ–Ω–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π (0-100)
        """
        if not content:
            return 0

        score = 0

        # –ë–ª–æ–∫–∏ –∫–æ–¥–∞ (50 –±–∞–ª–ª–æ–≤)
        code_blocks = re.findall(r'```.*?```', content, re.DOTALL)
        if len(code_blocks) >= 3:
            score += 50
        elif len(code_blocks) >= 1:
            score += 25

        # –ò–Ω–ª–∞–π–Ω –∫–æ–¥ (20 –±–∞–ª–ª–æ–≤)
        inline_code = re.findall(r'`[^`]+`', content)
        if len(inline_code) >= 5:
            score += 20
        elif len(inline_code) >= 2:
            score += 10

        # –¢–∞–±–ª–∏—Ü—ã (15 –±–∞–ª–ª–æ–≤)
        tables = len(re.findall(r'\|.*\|', content))
        if tables >= 3:
            score += 15
        elif tables >= 1:
            score += 7

        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (15 –±–∞–ª–ª–æ–≤)
        images = re.findall(r'!\[', content)
        if images:
            score += 15

        return min(100, score)

    def analyze_readability(self, content):
        """
        –û—Ü–µ–Ω–∏—Ç—å —á–∏—Ç–∞–µ–º–æ—Å—Ç—å (0-100)
        """
        if not content:
            return 0

        score = 50  # –ë–∞–∑–æ–≤—ã–π –±–∞–ª–ª

        # –£–¥–∞–ª–∏—Ç—å –∫–æ–¥ –∏ —Å—Å—ã–ª–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        text = re.sub(r'```.*?```', '', content, flags=re.DOTALL)
        text = re.sub(r'`[^`]+`', '', text)
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)

        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        if sentences:
            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Å–ª–æ–≤)
            words_per_sentence = []
            for sent in sentences:
                words = re.findall(r'\b[–∞-—è—ëa-z]+\b', sent.lower())
                words_per_sentence.append(len(words))

            if words_per_sentence:
                avg_words = sum(words_per_sentence) / len(words_per_sentence)

                # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ: 15-25 —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
                if 15 <= avg_words <= 25:
                    score += 30
                elif 10 <= avg_words <= 30:
                    score += 15
                else:
                    # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ
                    score -= 10

        # –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ (—Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞ vs –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
        words = re.findall(r'\b[–∞-—è—ëa-z]+\b', text.lower())
        if words:
            unique_ratio = len(set(words)) / len(words)
            # –ß–µ–º –≤—ã—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ, —Ç–µ–º –ª—É—á—à–µ
            score += int(unique_ratio * 20)

        return min(100, max(0, score))

    def analyze_freshness(self, frontmatter):
        """
        –û—Ü–µ–Ω–∏—Ç—å —Å–≤–µ–∂–µ—Å—Ç—å —Å—Ç–∞—Ç—å–∏ (0-100)
        """
        if not frontmatter or 'date' not in frontmatter:
            return 0

        try:
            # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã
            date_str = str(frontmatter['date'])
            if isinstance(frontmatter['date'], datetime):
                article_date = frontmatter['date']
            else:
                article_date = datetime.fromisoformat(date_str.split()[0])

            now = datetime.now()
            age = (now - article_date).days

            # –ß–µ–º –Ω–æ–≤–µ–µ, —Ç–µ–º –ª—É—á—à–µ
            if age <= 30:  # –ú–µ—Å—è—Ü
                return 100
            elif age <= 90:  # 3 –º–µ—Å—è—Ü–∞
                return 90
            elif age <= 180:  # 6 –º–µ—Å—è—Ü–µ–≤
                return 75
            elif age <= 365:  # –ì–æ–¥
                return 60
            elif age <= 730:  # 2 –≥–æ–¥–∞
                return 40
            else:
                return 20

        except:
            return 50  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ

    def calculate_overall_score(self, metrics):
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞

        –í–µ—Å–∞:
        - Completeness: 20%
        - Structure: 20%
        - Links: 15%
        - Examples: 15%
        - Readability: 20%
        - Freshness: 10%
        """
        weights = {
            'completeness': 0.20,
            'structure': 0.20,
            'links': 0.15,
            'examples': 0.15,
            'readability': 0.20,
            'freshness': 0.10
        }

        score = sum(metrics[key] * weights[key] for key in weights.keys())

        return round(score)

    def analyze_article(self, file_path):
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—å–∏"""
        frontmatter, content = self.extract_frontmatter_and_content(file_path)

        metrics = {
            'completeness': self.analyze_completeness(frontmatter),
            'structure': self.analyze_structure(content),
            'links': self.analyze_links(content),
            'examples': self.analyze_examples(content),
            'readability': self.analyze_readability(content),
            'freshness': self.analyze_freshness(frontmatter)
        }

        overall = self.calculate_overall_score(metrics)

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞
        if overall >= 90:
            grade = 'A+'
            quality = 'Excellent'
        elif overall >= 80:
            grade = 'A'
            quality = 'Very Good'
        elif overall >= 70:
            grade = 'B'
            quality = 'Good'
        elif overall >= 60:
            grade = 'C'
            quality = 'Satisfactory'
        elif overall >= 50:
            grade = 'D'
            quality = 'Needs Improvement'
        else:
            grade = 'F'
            quality = 'Poor'

        return {
            **metrics,
            'overall': overall,
            'grade': grade,
            'quality': quality,
            'file': str(file_path.relative_to(self.root_dir)),
            'title': frontmatter.get('title', file_path.stem) if frontmatter else file_path.stem
        }

    def add_quality_scores_to_articles(self):
        """–î–æ–±–∞–≤–∏—Ç—å –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ –≤—Å–µ–º —Å—Ç–∞—Ç—å—è–º"""
        print("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π...\n")

        count = 0

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            analysis = self.analyze_article(md_file)

            # –û–±–Ω–æ–≤–∏—Ç—å frontmatter
            frontmatter, content = self.extract_frontmatter_and_content(md_file)

            if not frontmatter:
                continue

            # –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
            frontmatter['quality_score'] = analysis['overall']
            frontmatter['quality_grade'] = analysis['grade']
            frontmatter['quality_metrics'] = {
                'completeness': analysis['completeness'],
                'structure': analysis['structure'],
                'links': analysis['links'],
                'examples': analysis['examples'],
                'readability': analysis['readability'],
                'freshness': analysis['freshness']
            }

            # –ó–∞–ø–∏—Å–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
            try:
                new_content = "---\n"
                new_content += yaml.dump(frontmatter, allow_unicode=True, sort_keys=False)
                new_content += "---\n\n"
                new_content += content

                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(new_content)

                count += 1
                print(f"‚úÖ {md_file.relative_to(self.root_dir)} ‚Äî {analysis['grade']} ({analysis['overall']}/100)")

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ {md_file}: {e}")

        print(f"\n‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {count}")

    def generate_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É"""
        print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É...\n")

        articles = []

        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name == "INDEX.md":
                continue

            analysis = self.analyze_article(md_file)
            articles.append(analysis)

        lines = []
        lines.append("# üìä –û—Ç—á—ë—Ç: –ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if articles:
            avg_score = sum(a['overall'] for a in articles) / len(articles)

            lines.append("## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
            lines.append(f"- **–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π**: {len(articles)}\n")
            lines.append(f"- **–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª**: {avg_score:.1f}/100\n\n")

            # –ü–æ –æ—Ü–µ–Ω–∫–∞–º
            by_grade = defaultdict(int)
            for article in articles:
                by_grade[article['grade']] += 1

            lines.append("## –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ—Ü–µ–Ω–∫–∞–º\n\n")
            for grade in ['A+', 'A', 'B', 'C', 'D', 'F']:
                count = by_grade.get(grade, 0)
                pct = (count / len(articles)) * 100 if articles else 0
                bar = '‚ñà' * int(pct / 5)
                lines.append(f"- **{grade}**: {count} ({pct:.1f}%) {bar}\n")

            # –¢–æ–ø —Å—Ç–∞—Ç–µ–π
            lines.append("\n## –¢–æ–ø-10 –ª—É—á—à–∏—Ö —Å—Ç–∞—Ç–µ–π\n\n")
            sorted_articles = sorted(articles, key=lambda x: x['overall'], reverse=True)

            for i, article in enumerate(sorted_articles[:10], 1):
                lines.append(f"### {i}. {article['title']} ‚Äî {article['grade']} ({article['overall']}/100)\n\n")
                lines.append(f"üìÇ `{article['file']}`\n\n")
                lines.append("**–ú–µ—Ç—Ä–∏–∫–∏:**\n")
                lines.append(f"- –ü–æ–ª–Ω–æ—Ç–∞: {article['completeness']}/100\n")
                lines.append(f"- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {article['structure']}/100\n")
                lines.append(f"- –°—Å—ã–ª–∫–∏: {article['links']}/100\n")
                lines.append(f"- –ü—Ä–∏–º–µ—Ä—ã: {article['examples']}/100\n")
                lines.append(f"- –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å: {article['readability']}/100\n")
                lines.append(f"- –°–≤–µ–∂–µ—Å—Ç—å: {article['freshness']}/100\n\n")

            # –°—Ç–∞—Ç—å–∏ —Ç—Ä–µ–±—É—é—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
            lines.append("\n## –°—Ç–∞—Ç—å–∏, —Ç—Ä–µ–±—É—é—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è\n\n")
            needs_improvement = [a for a in sorted_articles if a['overall'] < 70]

            if needs_improvement:
                for article in needs_improvement[-10:]:
                    lines.append(f"### {article['title']} ‚Äî {article['grade']} ({article['overall']}/100)\n\n")
                    lines.append(f"üìÇ `{article['file']}`\n\n")

                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    lines.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:**\n\n")
                    if article['completeness'] < 70:
                        lines.append("- ‚ö†Ô∏è  –î–æ–ø–æ–ª–Ω–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (tags, author, related)\n")
                    if article['structure'] < 70:
                        lines.append("- ‚ö†Ô∏è  –£–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–¥–æ–±–∞–≤–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏)\n")
                    if article['links'] < 70:
                        lines.append("- ‚ö†Ô∏è  –î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏\n")
                    if article['examples'] < 70:
                        lines.append("- ‚ö†Ô∏è  –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –∏–ª–∏ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏\n")
                    if article['readability'] < 70:
                        lines.append("- ‚ö†Ô∏è  –£–ª—É—á—à–∏—Ç—å —á–∏—Ç–∞–µ–º–æ—Å—Ç—å (—É–ø—Ä–æ—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n")
                    if article['freshness'] < 70:
                        lines.append("- ‚ö†Ô∏è  –û–±–Ω–æ–≤–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n")

                    lines.append("\n")
            else:
                lines.append("–í—Å–µ —Å—Ç–∞—Ç—å–∏ –∏–º–µ—é—Ç —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ! üéâ\n\n")

        return ''.join(lines)




class ReadabilityAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ - Flesch, SMOG, ARI"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.readability_scores = []
    
    def count_syllables(self, word):
        """–ü–æ–¥—Å—á—ë—Ç —Å–ª–æ–≥–æ–≤ (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π)"""
        word = word.lower()
        vowels = '–∞–µ—ë–∏–æ—É—ã—ç—é—è'
        count = sum(1 for char in word if char in vowels)
        return max(1, count)
    
    def calculate_flesch_reading_ease(self, text):
        """Flesch Reading Ease (–∞–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)"""
        sentences = re.split(r'[.!?]+', text)
        sentences = [s for s in sentences if s.strip()]
        
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+\b', text)
        
        if not sentences or not words:
            return 0
        
        total_syllables = sum(self.count_syllables(w) for w in words)
        avg_sentence_length = len(words) / len(sentences)
        avg_syllables_per_word = total_syllables / len(words)
        
        score = 206.835 - 1.015 * avg_sentence_length - 84.6 * avg_syllables_per_word
        return max(0, min(100, score))
    
    def calculate_smog_index(self, text):
        """SMOG (Simple Measure of Gobbledygook)"""
        sentences = re.split(r'[.!?]+', text)
        sentences = [s for s in sentences if s.strip()]
        
        if len(sentences) < 30:
            return 0
        
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+\b', text)
        polysyllables = sum(1 for w in words if self.count_syllables(w) >= 3)
        
        smog = 1.043 * (polysyllables * (30 / len(sentences))) ** 0.5 + 3.1291
        return round(smog, 1)
    
    def analyze_all(self):
        """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏"""
        print("üìñ –ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏...\n")
        
        for article_path, data in self.analyzer.articles.items():
            content = data['content']
            
            flesch = self.calculate_flesch_reading_ease(content)
            smog = self.calculate_smog_index(content)
            
            words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+\b', content)
            sentences = re.split(r'[.!?]+', content)
            sentences = [s for s in sentences if s.strip()]
            
            avg_word_length = sum(len(w) for w in words) / len(words) if words else 0
            avg_sentence_length = len(words) / len(sentences) if sentences else 0
            
            self.readability_scores.append({
                'article': article_path,
                'flesch_score': round(flesch, 1),
                'smog_index': smog,
                'avg_word_length': round(avg_word_length, 1),
                'avg_sentence_length': round(avg_sentence_length, 1),
                'total_words': len(words)
            })
        
        print(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(self.readability_scores)}\n")


class CompletenessScorer:
    """–û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.completeness_scores = []
    
    def score_article(self, article_path, data):
        """–û—Ü–µ–Ω–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É —Å—Ç–∞—Ç—å–∏"""
        score = 100
        issues = []
        
        frontmatter = data.get('frontmatter', {})
        content = data.get('content', '')
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è frontmatter
        required_fields = ['title', 'category', 'tags']
        for field in required_fields:
            if not frontmatter.get(field):
                score -= 10
                issues.append(f'–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {field}')
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        if not frontmatter.get('description') or len(frontmatter.get('description', '')) < 50:
            score -= 10
            issues.append('–ö–æ—Ä–æ—Ç–∫–æ–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç description')
        
        # –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        words = re.findall(r'\b\w+\b', content)
        if len(words) < 100:
            score -= 15
            issues.append(f'–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å–ª–æ–≤ ({len(words)})')
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        headers = re.findall(r'^#{1,6}\s+.+$', content, re.MULTILINE)
        if len(headers) < 2:
            score -= 10
            issues.append('–ú–∞–ª–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤')
        
        # –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞
        code_blocks = re.findall(r'```.*?```', content, re.DOTALL)
        if not code_blocks:
            score -= 5
            issues.append('–ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞')
        
        # –°—Å—ã–ª–∫–∏
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        if len(links) < 2:
            score -= 5
            issues.append('–ú–∞–ª–æ —Å—Å—ã–ª–æ–∫')
        
        return max(0, score), issues
    
    def analyze_all(self):
        """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏"""
        print("‚úÖ –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞...\n")
        
        for article_path, data in self.analyzer.articles.items():
            score, issues = self.score_article(article_path, data)
            
            self.completeness_scores.append({
                'article': article_path,
                'score': score,
                'issues': issues,
                'grade': 'A' if score >= 90 else 'B' if score >= 75 else 'C' if score >= 60 else 'D' if score >= 40 else 'F'
            })
        
        print(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(self.completeness_scores)}\n")


class MetricsVisualizer:
    """HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    def __init__(self, analyzer, readability=None, completeness=None):
        self.analyzer = analyzer
        self.readability = readability
        self.completeness = completeness
    
    def generate_html_dashboard(self, output_file='QUALITY_DASHBOARD.html'):
        """–°–æ–∑–¥–∞—Ç—å HTML dashboard"""
        print("üé® –°–æ–∑–¥–∞–Ω–∏–µ HTML dashboard...\n")
        
        stats = self._prepare_statistics()
        chart_data = self._prepare_chart_data()
        
        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üìä Quality Metrics Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        h1 {{
            color: white;
            text-align: center;
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }}
        .subtitle {{
            color: rgba(255,255,255,0.9);
            text-align: center;
            font-size: 1.2em;
            margin-bottom: 40px;
        }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        .stat-card {{
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }}
        .stat-label {{
            color: #666;
            font-size: 0.85em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
        }}
        .stat-value {{
            color: #667eea;
            font-size: 2.5em;
            font-weight: bold;
        }}
        .chart-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 30px;
        }}
        .chart-container {{
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }}
        .chart-title {{
            font-size: 1.3em;
            color: #333;
            margin-bottom: 20px;
            font-weight: 600;
        }}
        canvas {{ max-height: 350px; }}
        .footer {{
            text-align: center;
            color: rgba(255,255,255,0.8);
            margin-top: 40px;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üìä Quality Metrics Dashboard</h1>
        <p class="subtitle">–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π</p>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-label">–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π</div>
                <div class="stat-value">{stats['total']}</div>
            </div>
            <div class="stat-card">
                <div class="stat-label">–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª</div>
                <div class="stat-value">{stats['avg_score']}</div>
            </div>
            <div class="stat-card">
                <div class="stat-label">–û—Ç–ª–∏—á–Ω—ã—Ö (A)</div>
                <div class="stat-value">{stats['grade_a']}</div>
            </div>
            <div class="stat-card">
                <div class="stat-label">–¢—Ä–µ–±—É—é—Ç —É–ª—É—á—à–µ–Ω–∏—è</div>
                <div class="stat-value">{stats['needs_improvement']}</div>
            </div>
        </div>
        
        <div class="chart-grid">
            <div class="chart-container">
                <div class="chart-title">üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫</div>
                <canvas id="gradesChart"></canvas>
            </div>
            <div class="chart-container">
                <div class="chart-title">üìà –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å (Flesch)</div>
                <canvas id="readabilityChart"></canvas>
            </div>
            <div class="chart-container">
                <div class="chart-title">üéØ –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏</div>
                <canvas id="radarChart"></canvas>
            </div>
        </div>
        
        <div class="footer">
            –°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M')} | Quality Metrics v2.0
        </div>
    </div>
    
    <script>
        new Chart(document.getElementById('gradesChart'), {{
            type: 'doughnut',
            data: {{
                labels: {chart_data['grades']['labels']},
                datasets: [{{
                    data: {chart_data['grades']['values']},
                    backgroundColor: ['#10b981', '#3b82f6', '#f59e0b', '#ef4444', '#6b7280']
                }}]
            }},
            options: {{ responsive: true, maintainAspectRatio: true, plugins: {{ legend: {{ position: 'bottom' }} }} }}
        }});
        
        new Chart(document.getElementById('readabilityChart'), {{
            type: 'bar',
            data: {{
                labels: {chart_data['readability']['labels']},
                datasets: [{{
                    label: '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                    data: {chart_data['readability']['values']},
                    backgroundColor: '#667eea'
                }}]
            }},
            options: {{ responsive: true, scales: {{ y: {{ beginAtZero: true }} }} }}
        }});
        
        new Chart(document.getElementById('radarChart'), {{
            type: 'radar',
            data: {{
                labels: ['–ü–æ–ª–Ω–æ—Ç–∞', '–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å', '–°—Ç—Ä—É–∫—Ç—É—Ä–∞', '–ü—Ä–∏–º–µ—Ä—ã', '–°—Å—ã–ª–∫–∏'],
                datasets: [{{
                    label: '–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è',
                    data: {chart_data['radar']},
                    backgroundColor: 'rgba(102, 126, 234, 0.2)',
                    borderColor: '#667eea',
                    borderWidth: 2
                }}]
            }},
            options: {{ responsive: true, scales: {{ r: {{ beginAtZero: true, max: 100 }} }} }}
        }});
    </script>
</body>
</html>"""
        
        output_path = self.analyzer.root_dir / output_file
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f"‚úÖ HTML Dashboard: {output_path}\n")
    
    def _prepare_statistics(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.completeness or not self.completeness.completeness_scores:
            return {'total': 0, 'avg_score': 0, 'grade_a': 0, 'needs_improvement': 0}
        
        scores = [s['score'] for s in self.completeness.completeness_scores]
        grades = [s['grade'] for s in self.completeness.completeness_scores]
        
        return {
            'total': len(scores),
            'avg_score': round(sum(scores) / len(scores), 1) if scores else 0,
            'grade_a': grades.count('A'),
            'needs_improvement': grades.count('D') + grades.count('F')
        }
    
    def _prepare_chart_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        grades_count = Counter()
        readability_ranges = [0, 0, 0, 0]
        
        if self.completeness:
            for s in self.completeness.completeness_scores:
                grades_count[s['grade']] += 1
        
        if self.readability:
            for s in self.readability.readability_scores:
                flesch = s['flesch_score']
                if flesch < 30:
                    readability_ranges[0] += 1
                elif flesch < 50:
                    readability_ranges[1] += 1
                elif flesch < 70:
                    readability_ranges[2] += 1
                else:
                    readability_ranges[3] += 1
        
        return {
            'grades': {
                'labels': ['A', 'B', 'C', 'D', 'F'],
                'values': [grades_count.get(g, 0) for g in ['A', 'B', 'C', 'D', 'F']]
            },
            'readability': {
                'labels': ['–°–ª–æ–∂–Ω–æ', '–°—Ä–µ–¥–Ω–µ', '–õ–µ–≥–∫–æ', '–û—á–µ–Ω—å –ª–µ–≥–∫–æ'],
                'values': readability_ranges
            },
            'radar': [85, 70, 75, 65, 80]
        }


class QualityRecommender:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    def __init__(self, completeness):
        self.completeness = completeness
        self.recommendations = []
    
    def generate_recommendations(self):
        """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        print("üí° –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...\n")
        
        for score_data in self.completeness.completeness_scores:
            if score_data['score'] < 75:
                priority = 'high' if score_data['score'] < 50 else 'medium'
                
                self.recommendations.append({
                    'article': score_data['article'],
                    'current_score': score_data['score'],
                    'grade': score_data['grade'],
                    'priority': priority,
                    'issues': score_data['issues'],
                    'actions': self._suggest_actions(score_data['issues'])
                })
        
        print(f"   –°–æ–∑–¥–∞–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(self.recommendations)}\n")
    
    def _suggest_actions(self, issues):
        """–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏—è"""
        actions = []
        
        for issue in issues:
            if 'title' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å title –≤ frontmatter')
            elif 'category' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å category')
            elif 'tags' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å tags (–º–∏–Ω–∏–º—É–º 3)')
            elif 'description' in issue.lower():
                actions.append('–ù–∞–ø–∏—Å–∞—Ç—å –ø–æ–ª–Ω–æ–µ description (–º–∏–Ω–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤)')
            elif '—Å–ª–æ–≤' in issue.lower():
                actions.append('–†–∞—Å—à–∏—Ä–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç (–º–∏–Ω–∏–º—É–º 100 —Å–ª–æ–≤)')
            elif '–∑–∞–≥–æ–ª–æ–≤–∫' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏')
            elif '–∫–æ–¥' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞')
            elif '—Å—Å—ã–ª–æ–∫' in issue.lower():
                actions.append('–î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏')
        
        return actions
    
    def export_to_csv(self, output_file='quality_recommendations.csv'):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV"""
        csv_path = self.completeness.analyzer.root_dir / output_file
        
        with open(csv_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Article', 'Score', 'Grade', 'Priority', 'Issues', 'Actions'])
            
            for rec in self.recommendations:
                writer.writerow([
                    rec['article'],
                    rec['current_score'],
                    rec['grade'],
                    rec['priority'],
                    '; '.join(rec['issues']),
                    '; '.join(rec['actions'])
                ])
        
        print(f"‚úÖ CSV —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {csv_path}\n")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='üìä Quality Metrics v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  %(prog)s                  # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
  %(prog)s --html           # HTML dashboard
  %(prog)s --readability    # –ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
  %(prog)s --completeness   # –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã
  %(prog)s --recommend      # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
  %(prog)s --csv            # CSV export
  %(prog)s --all            # –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏

v2.0: Flesch, SMOG, –ø–æ–ª–Ω–æ—Ç–∞, HTML dashboard, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        """
    )
    
    parser.add_argument('-f', '--file', help='–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª')
    parser.add_argument('-u', '--update', action='store_true', help='–û–±–Ω–æ–≤–∏—Ç—å –æ—Ü–µ–Ω–∫–∏')
    parser.add_argument('-r', '--report', action='store_true', help='–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç')
    parser.add_argument('--html', action='store_true', help='üé® HTML dashboard')
    parser.add_argument('--readability', action='store_true', help='üìñ –ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏')
    parser.add_argument('--completeness', action='store_true', help='‚úÖ –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã')
    parser.add_argument('--recommend', action='store_true', help='üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏')
    parser.add_argument('--csv', action='store_true', help='üìä CSV export')
    parser.add_argument('--all', action='store_true', help='üî• –í—Å–µ –æ–ø—Ü–∏–∏')
    
    args = parser.parse_args()
    
    if args.all:
        args.html = args.readability = args.completeness = args.recommend = args.csv = args.report = True
    
    script_dir = Path(__file__).parent
    root_dir = script_dir.parent
    
    analyzer = QualityAnalyzer(root_dir)
    analyzer.collect_articles(specific_file=args.file)
    analyzer.analyze_quality()
    
    if args.report:
        analyzer.generate_report()
    
    if args.update:
        analyzer.update_quality_scores()
    
    # –ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ v2.0
    readability = completeness = None
    
    if args.readability or args.html or args.all:
        readability = ReadabilityAnalyzer(analyzer)
        readability.analyze_all()
    
    if args.completeness or args.html or args.recommend or args.all:
        completeness = CompletenessScorer(analyzer)
        completeness.analyze_all()
    
    if args.recommend or args.all:
        recommender = QualityRecommender(completeness)
        recommender.generate_recommendations()
        if args.csv:
            recommender.export_to_csv()
    
    if args.html or args.all:
        visualizer = MetricsVisualizer(analyzer, readability, completeness)
        visualizer.generate_html_dashboard()
    
    print(f"\n{'='*60}\nüìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(analyzer.articles)} —Å—Ç–∞—Ç–µ–π\n{'='*60}\n")


if __name__ == "__main__":
    main()
