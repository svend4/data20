# üöÄ Phase 5 Quick Start Guide

## –ß—Ç–æ –≤ Phase 5.1 (Database Infrastructure)

–°–æ–∑–¥–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

### 1. Database Models (`backend/models.py`)
- ‚úÖ User (–∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è)
- ‚úÖ Job (–∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
- ‚úÖ JobResult (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- ‚úÖ JobLog (–ª–æ–≥–∏)
- ‚úÖ ParameterTemplate (—à–∞–±–ª–æ–Ω—ã)
- ‚úÖ Workflow (–º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã)
- ‚úÖ ToolStats (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤)
- ‚úÖ SystemMetrics (–º–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã)

### 2. Database Connection (`backend/database.py`)
- ‚úÖ SQLAlchemy engine —Å connection pooling
- ‚úÖ Session factory
- ‚úÖ Dependency injection –¥–ª—è FastAPI
- ‚úÖ Context managers
- ‚úÖ Health checks

### 3. Migrations (`backend/alembic/`)
- ‚úÖ Alembic configuration
- ‚úÖ Migration environment
- ‚úÖ Template –¥–ª—è migration —Ñ–∞–π–ª–æ–≤

### 4. Docker Infrastructure
- ‚úÖ PostgreSQL 15 (port 5432)
- ‚úÖ Redis 7 (port 6379)
- ‚úÖ Celery worker (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- ‚úÖ Prometheus + Grafana (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

---

## üìã Quick Start

### –í–∞—Ä–∏–∞–Ω—Ç 1: –¢–æ–ª—å–∫–æ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å PostgreSQL –∏ Redis
docker-compose -f docker-compose.phase5.yml up -d postgres redis

# 2. –ü–æ–¥–æ–∂–¥–∞—Ç—å –ø–æ–∫–∞ –∑–∞–ø—É—Å—Ç—è—Ç—Å—è (health checks)
docker-compose -f docker-compose.phase5.yml ps

# 3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
cd backend
pip install -r requirements.txt

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
python database.py check

# 5. –°–æ–∑–¥–∞—Ç—å —Å—Ö–µ–º—É –ë–î
python database.py init

# 6. –ì–æ—Ç–æ–≤–æ!
```

–¢–µ–ø–µ—Ä—å PostgreSQL –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: `postgresql://data20:data20@localhost:5432/data20_kb`

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (—Å backend –∏ celery)

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å—ë —Å –ø—Ä–æ—Ñ–∏–ª–µ–º 'full'
docker-compose -f docker-compose.phase5.yml --profile full up -d

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å
docker-compose -f docker-compose.phase5.yml ps

# –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω—ã:
# - data20_postgres (PostgreSQL)
# - data20_redis (Redis)
# - data20_backend (Backend API)
# - data20_celery (Celery Worker)

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker-compose -f docker-compose.phase5.yml logs -f backend
```

Backend –¥–æ—Å—Ç—É–ø–µ–Ω: http://localhost:8001

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: –° –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º (Prometheus + Grafana)

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å –ø—Ä–æ—Ñ–∏–ª–µ–º 'monitoring'
docker-compose -f docker-compose.phase5.yml --profile monitoring up -d

# 2. –û—Ç–∫—Ä–æ–π—Ç–µ dashboards
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)
```

---

## üîß –†–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö

### –°–æ–∑–¥–∞—Ç—å migration

```bash
cd backend

# Auto-generate migration –∏–∑ models
alembic revision --autogenerate -m "Add new field to Job"

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å migration
alembic upgrade head

# –û—Ç–∫–∞—Ç–∏—Ç—å migration
alembic downgrade -1
```

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–î

```bash
# Python script
python database.py check

# SQL –Ω–∞–ø—Ä—è–º—É—é
psql postgresql://data20:data20@localhost:5432/data20_kb
```

### –°–±—Ä–æ—Å–∏—Ç—å –ë–î (‚ö†Ô∏è —É–¥–∞–ª–∏—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ!)

```bash
python database.py reset
```

---

## üìä –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö

### Job (–∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)

```python
from database import get_db_context
from models import Job, JobStatus
from datetime import datetime

with get_db_context() as db:
    # –°–æ–∑–¥–∞—Ç—å job
    job = Job(
        tool_name="build_graph",
        user_id=user.id,
        parameters={"depth": 3},
        status=JobStatus.PENDING
    )
    db.add(job)
    db.commit()

    # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å
    job.status = JobStatus.RUNNING
    job.started_at = datetime.utcnow()
    db.commit()

    # –ó–∞–≤–µ—Ä—à–∏—Ç—å
    job.status = JobStatus.COMPLETED
    job.completed_at = datetime.utcnow()
    job.duration = (job.completed_at - job.started_at).total_seconds()
    db.commit()
```

### JobResult (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)

```python
from models import JobResult

with get_db_context() as db:
    result = JobResult(
        job_id=job.id,
        stdout="Tool output...",
        output_files=["graph.html", "graph.json"],
        total_size=1024567
    )
    db.add(result)
```

### Query –ø—Ä–∏–º–µ—Ä—ã

```python
with get_db_context() as db:
    # –ù–∞–π—Ç–∏ –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_jobs = db.query(Job).filter(
        Job.user_id == user.id
    ).all()

    # –ù–∞–π—Ç–∏ failed jobs
    failed = db.query(Job).filter(
        Job.status == JobStatus.FAILED
    ).order_by(Job.created_at.desc()).limit(10).all()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É
    stats = db.query(Job).filter(
        Job.tool_name == "build_graph"
    ).count()

    # Join —Å results
    jobs_with_results = db.query(Job).join(JobResult).filter(
        Job.status == JobStatus.COMPLETED
    ).all()
```

---

## üîå –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FastAPI

### –í server.py

```python
from fastapi import FastAPI, Depends
from sqlalchemy.orm import Session
from database import get_db
from models import Job, JobStatus

app = FastAPI()

@app.post("/api/run")
async def run_tool(
    request: ToolRunRequest,
    db: Session = Depends(get_db)
):
    # –°–æ–∑–¥–∞—Ç—å job –≤ –ë–î
    job = Job(
        tool_name=request.tool_name,
        parameters=request.parameters,
        status=JobStatus.PENDING
    )
    db.add(job)
    db.commit()
    db.refresh(job)

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    await runner.run_tool_async(job.id, ...)

    return {"job_id": str(job.id)}


@app.get("/api/jobs/{job_id}")
async def get_job(
    job_id: str,
    db: Session = Depends(get_db)
):
    job = db.query(Job).filter(Job.id == job_id).first()
    if not job:
        raise HTTPException(404, "Job not found")

    return {
        "job_id": str(job.id),
        "status": job.status.value,
        "progress": calculate_progress(job),
        ...
    }
```

---

## üê≥ Docker –∫–æ–º–∞–Ω–¥—ã

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å
docker-compose -f docker-compose.phase5.yml up -d

# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
docker-compose -f docker-compose.phase5.yml down

# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å + —É–¥–∞–ª–∏—Ç—å volumes (‚ö†Ô∏è –ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö!)
docker-compose -f docker-compose.phase5.yml down -v

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ª–æ–≥–∏
docker-compose -f docker-compose.phase5.yml logs -f postgres
docker-compose -f docker-compose.phase5.yml logs -f redis

# –ó–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker exec -it data20_postgres psql -U data20 -d data20_kb

# Backup –ë–î
docker exec data20_postgres pg_dump -U data20 data20_kb > backup.sql

# Restore –ë–î
cat backup.sql | docker exec -i data20_postgres psql -U data20 data20_kb
```

---

## üì¶ Environment Variables

–°–æ–∑–¥–∞–π—Ç–µ `.env` —Ñ–∞–π–ª:

```bash
# Database
DATABASE_URL=postgresql://data20:data20@localhost:5432/data20_kb

# Redis
REDIS_URL=redis://localhost:6379/0

# Celery
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256

# Development
DEBUG=true
LOG_LEVEL=info
```

---

## üß™ Testing

```bash
# Install test dependencies
pip install pytest pytest-asyncio httpx

# Run tests
pytest backend/tests/

# With coverage
pytest --cov=backend backend/tests/
```

---

## üìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ Phase 5.1 (Database):

1. **Phase 5.2: Authentication**
   - JWT tokens
   - User registration/login
   - Permissions

2. **Phase 5.3: Monitoring**
   - Structured logging
   - Prometheus metrics
   - Grafana dashboards

3. **Phase 5.4: UX Improvements**
   - History viewer
   - Result management
   - Templates

---

## ‚ö†Ô∏è Troubleshooting

### PostgreSQL –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker-compose -f docker-compose.phase5.yml logs postgres

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç
lsof -i :5432

# –£–¥–∞–ª–∏—Ç—å volume –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å
docker-compose -f docker-compose.phase5.yml down -v
docker-compose -f docker-compose.phase5.yml up -d postgres
```

### Alembic –æ—à–∏–±–∫–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å current revision
alembic current

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å history
alembic history

# Downgrade –∏ upgrade –∑–∞–Ω–æ–≤–æ
alembic downgrade base
alembic upgrade head
```

### Connection pool errors

```python
# –í database.py —É–≤–µ–ª–∏—á–∏—Ç—å pool size
engine = create_engine(
    url,
    pool_size=10,  # –±—ã–ª–æ 5
    max_overflow=20  # –±—ã–ª–æ 10
)
```

---

## üìö Resources

- **SQLAlchemy docs**: https://docs.sqlalchemy.org/
- **Alembic docs**: https://alembic.sqlalchemy.org/
- **PostgreSQL docs**: https://www.postgresql.org/docs/
- **Redis docs**: https://redis.io/docs/

---

## ‚úÖ Checklist Phase 5.1

- [x] Models created (`backend/models.py`)
- [x] Database connection (`backend/database.py`)
- [x] Alembic setup (`backend/alembic/`)
- [x] Docker compose (`docker-compose.phase5.yml`)
- [x] Requirements updated
- [ ] Backend integration (Phase 5.1.7)
- [ ] Celery integration (Phase 5.1.9)
- [ ] Testing (Phase 5.5)

**Status**: ‚úÖ 60% complete (infrastructure ready)
